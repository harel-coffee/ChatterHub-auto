{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data= [] \n",
    "y_data= [] \n",
    "\n",
    "with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "    x_data = f.readlines()\n",
    "\n",
    "with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "    y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1272"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max( np.concatenate( x_data ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(  np.concatenate( y_data )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes  = list(np.unique(  np.concatenate( y_data )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kwikset_10-Button_Deadbolt_activity_hubDisconnected',\n",
       " 'Kwikset_10-Button_Deadbolt_activity_online',\n",
       " 'Kwikset_10-Button_Deadbolt_lock_locked',\n",
       " 'Kwikset_10-Button_Deadbolt_lock_unlocked',\n",
       " 'Multipurpose_Sensor_acceleration_active',\n",
       " 'Multipurpose_Sensor_acceleration_inactive',\n",
       " 'Multipurpose_Sensor_activity_hubDisconnected',\n",
       " 'Multipurpose_Sensor_activity_online',\n",
       " 'Multipurpose_Sensor_contact_closed',\n",
       " 'Multipurpose_Sensor_contact_open',\n",
       " 'Multipurpose_Sensor_status_closed',\n",
       " 'Multipurpose_Sensor_status_open',\n",
       " 'Multipurpose_Sensor_temperature_XXX',\n",
       " 'Multipurpose_Sensor_threeAxis_XXX',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch_activity_hubDisconnected',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch_activity_online',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch_button_held',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch_button_pushed',\n",
       " 'SYLVANIA_SMART+_Smart_Plug_switch_off',\n",
       " 'SYLVANIA_SMART+_Smart_Plug_switch_on',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_activity_hubDisconnected',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_activity_offline',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_activity_online',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_colorTemperature_XXX',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_level_XXX',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_switch_off',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW_switch_on']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_categorical = []  \n",
    "\n",
    "for x in y_data:\n",
    "    temp = np.zeros( len(classes) )\n",
    "    for y in x : \n",
    "        temp[ classes.index( y ) ] = 1\n",
    "    y_data_categorical.append( temp )\n",
    "y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "y_data_categorical=y_data_categorical.reshape(y_data_categorical.shape+(1,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_categorical=y_data_categorical.reshape(y_data_categorical.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 27, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_data_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array( x_data) / 1500.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 256, 256, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_temp = [] \n",
    "for x in x_data:\n",
    "    temp = list(x)\n",
    "    while len(temp) < 256*256:\n",
    "        temp.append(0)\n",
    "    \n",
    "    x_data_temp.append(np.array( temp).reshape(256,256))\n",
    "\n",
    "    \n",
    "x_data_temp = np.array( x_data_temp )\n",
    "x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "\n",
    "x_data_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min([ len(x) for x in x_data_temp ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(13,13)),\n",
    "    keras.layers.Dense(320, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(27, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(320, input_dim=160, activation='relu'))\n",
    "#     model.add(Dense(len(classes), activation='softmax'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def unet():\n",
    "    l2_lambda = 0.0002\n",
    "    DropP = 0.3\n",
    "    kernel_size=3\n",
    "\n",
    "    inputs = Input((256,256,1))\n",
    "    #Conv3D(filters,(3,3,3),sjfsjf)\n",
    "    conv1 = Conv2D(16, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda), name='conv1' )(inputs)\n",
    "    conv1 = bn()(conv1)\n",
    "    conv1 = Conv2D(16, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv1)\n",
    "    conv1 = bn()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(DropP)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(32, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda), name='conv2' )(pool1)\n",
    "    conv2 = bn()(conv2)\n",
    "    conv2 = Conv2D(32, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv2)\n",
    "    conv2 = bn()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(DropP)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) , name='conv3')(pool2)\n",
    "    conv3 = bn()(conv3)\n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv3)\n",
    "    conv3 = bn()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(DropP)(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda), name='conv4')(pool3)\n",
    "    conv4 = bn()(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv4)\n",
    "    conv4 = bn()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(DropP)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda), name='conv5' )(pool4)\n",
    "    conv5 = bn()(conv5)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv5)\n",
    "    conv5 = bn()(conv5)\n",
    "    \n",
    "    up6 = concatenate([Conv2DTranspose(256,(2, 2), strides=(2, 2), padding='same')(conv5), conv4],name='up6', axis=3)\n",
    "    up6 = Dropout(DropP)(up6)\n",
    "    output = Conv2D(1, (5, 5), activation='softmax', padding='same', name='output')(up6)\n",
    "       \n",
    "\n",
    "    #output = Dense(27,  activation='softmax',name='output')(conv6)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = baseline_model()\n",
    "#report = model.fit( x=x_data_temp , y=y_data_categorical , batch_size=35, epochs=12000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 256, 256, 16) 160         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 256, 256, 16) 64          conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 256, 256, 16) 2320        batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 256, 256, 16) 64          conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling2D) (None, 128, 128, 16) 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 128, 128, 16) 0           max_pooling2d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 128, 128, 32) 4640        dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 128, 128, 32) 128         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 128, 128, 32) 9248        batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 128, 128, 32) 128         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling2D) (None, 64, 64, 32)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 64, 64, 32)   0           max_pooling2d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 64, 64, 64)   18496       dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 64, 64, 64)   256         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 64, 64, 64)   36928       batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 64, 64, 64)   256         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling2D) (None, 32, 32, 64)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 32, 32, 64)   0           max_pooling2d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 32, 32, 128)  73856       dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 32, 32, 128)  512         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 32, 32, 128)  147584      batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 32, 32, 128)  512         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 16, 16, 128)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 16, 16, 128)  0           max_pooling2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 16, 16, 256)  295168      dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 16, 16, 256)  1024        conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 16, 16, 256)  590080      batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 16, 16, 256)  1024        conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 32, 32, 256)  262400      batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up6 (Concatenate)               (None, 32, 32, 384)  0           conv2d_transpose_22[0][0]        \n",
      "                                                                 batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 32, 32, 384)  0           up6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 32, 32, 1)    9601        dropout_74[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,454,449\n",
      "Trainable params: 1,452,465\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "\n",
    "model2 = unet()\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected output to have shape (32, 32, 1) but got array with shape (27, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-50005ebfb5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreport2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_data_temp\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_data_categorical\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You must compile your model before using it.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_inputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_targets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_sample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                                  \u001b[0;34m'it should have one entry per model outputs. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                                  \u001b[0;34m'The model has '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                                  \u001b[0;34m' outputs, but you passed '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m                                  \u001b[0;34m'sample_weight_mode='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                                  str(sample_weight_mode))\n",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected output to have shape (32, 32, 1) but got array with shape (27, 1, 1)"
     ]
    }
   ],
   "source": [
    "report2 = model2.fit( x=x_data_temp , y=y_data_categorical , batch_size=35, epochs=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 256, 256, 1) (431, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "# x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "print(x_data_temp.shape , y_data_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator, x_data_temp, y_data, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print( i , i**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [1,2,3,4]\n",
    "np.array(a).reshape( 2,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(new_iot)",
   "language": "python",
   "name": "iot_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
