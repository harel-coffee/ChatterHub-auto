{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp, includeDirection = False , TrimAt= 15 ):\n",
    "    if includeDirection:\n",
    "        return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1)  for x in inp ][:15])\n",
    "    else:\n",
    "        return np.array([ int(x[\"packet_length\"])  for x in inp ][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S'):\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "58958 57867\n",
      "loading from test files\n",
      "found files :  4\n",
      "32069 32069\n",
      "19968 19968\n",
      "9109 9109\n",
      "6404 6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57867, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "        \n",
    "#     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "#         y_data = json.load(f)\n",
    "\n",
    "#     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "#         x_data = json.load(f)\n",
    "  \n",
    "    if len( y_data ) != len(x_data) :\n",
    "        print( pick )\n",
    "        \n",
    "    \n",
    "    x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , Mapping=Mapper )\n",
    "    \n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    test_files = sorted(glob.glob( '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' ))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/', fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/', fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "\n",
    "        x_test.append(t_x)\n",
    "        y_test.append(t_y)\n",
    "        y_test_service.append(t_z)\n",
    "            \n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Mittigation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# d_sum = 0\n",
    "# import math\n",
    "# for ii in range(len(x_test)):\n",
    "\n",
    "#     p = x_test[ii]\n",
    "#     for i in p : \n",
    "#         t_sum += math.ceil(np.sum(i) / 2000)\n",
    "#         d_sum+= np.sum( i )\n",
    "# total_fixed  =  t_sum* 2000 / 15\n",
    "\n",
    "# print ( total_fixed , d_sum, d_sum-t_sum*2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sets the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'acceleration'), (1, 'activity'), (2, 'battery'), (3, 'button'), (4, 'colorTemperature'), (5, 'contact'), (6, 'level'), (7, 'lock'), (8, 'motion'), (9, 'ping'), (10, 'status'), (11, 'switch'), (12, 'temperature'), (13, 'threeAxis'), (14, 'unknown'), (15, 'water')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'ping'),\n",
       " (10, 'status'),\n",
       " (11, 'switch'),\n",
       " (12, 'temperature'),\n",
       " (13, 'threeAxis'),\n",
       " (14, 'unknown'),\n",
       " (15, 'water')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section controls wheather the unknown packets are removed or not, this should be tested with and without removed unknowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean_event( inp, return_clean= True  ):\n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'lock-unlocked' not in inp and 'on/off-XXX' not in inp and 'raw-XXX' not in inp and 'read_attr_-_raw-XXX' not in inp\n",
    "    else:\n",
    "        return  'lock-locked' in inp or 'lock-unlocked'  in inp or 'on/off-XXX' in inp or  'raw-XXX' in inp  or 'read_attr_-_raw-XXX' in inp \n",
    "    \n",
    "def is_clean_service( inp, return_clean= True  ):\n",
    "    \n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'unknown' not in inp and 'read_attr_-_raw' not in inp #and 'ping' not in inp \n",
    "    else:\n",
    "        return  'no_logs' in inp or  'unknown' in inp  or 'read_attr_-_raw' in inp #or 'ping' in inp \n",
    "#     return  \"contact-open\" not in inp and 'contact-closed' not in inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "toKeep = [ i for i in range(len(y_train)) if is_clean_event( y_train[i]) ] if Mapper=='SE' else [ i for i in range(len(y_train)) if is_clean_service( y_train[i]) ]\n",
    "x_train= [ x_train[i] for i in toKeep ]\n",
    "y_train= [ y_train[i] for i in toKeep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(x_test)):\n",
    "    toChange= [ i for i in range(len(y_test[j])) if is_clean_service( y_test[j][i], False) ]\n",
    "    y_test[j] = [ (y_test[j][i] if i not in toChange else np.array( ['none'])) for i in range(len(y_test[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.remove('read_attr_-_raw-XXX')\n",
    "# classes.remove('on/off-XXX')\n",
    "# classes.remove('raw-XXX')\n",
    "# classes.remove('lock-unlocked')\n",
    "# classes.remove('lock-locked')\n",
    "\n",
    "\n",
    "# classes.remove('read_attr_-_raw')\n",
    "# classes.remove('on/off')\n",
    "# classes.remove('raw')\n",
    "classes.remove('unknown')\n",
    "\n",
    "# classes.remove('lock')\n",
    "# # classes.remove('lock')\n",
    "\n",
    "\n",
    "# classes.remove('switch-on')\n",
    "\n",
    "\n",
    "\n",
    "service_classes= [\"\",\"\",\"\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== end of unknown packet control====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,classes=None, twoD= False ):\n",
    "#  y data \n",
    "# \"\"\"\n",
    "# this functino is in charge of preprocessing the records , the sourc e json contains a lot of extra stuff, this function tailors\n",
    "# the data and it fixes their lenghth\n",
    "# \"\"\"\n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    for x in y_data:\n",
    "        temp = np.zeros( len(classes) )\n",
    "        for y in x : \n",
    "            if y in classes:\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "        y_data_categorical.append( temp )\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        if twoD:\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size**2 - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size**2:\n",
    "                    temp.append( 0 )\n",
    "\n",
    "                x_data_temp.append(np.array( temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "            x_data_temp = np.array( x_data_temp )\n",
    "            x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "        else: \n",
    "            temp = [] \n",
    "            lst = list(x)\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size:\n",
    "                    temp.append( 0 )\n",
    "                \n",
    "                x_data_temp.append(np.array( temp))\n",
    "            \n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / (np.amax( x_data_temp) + 0.000000000001)\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,_=pre_process_raw( x_train, y_train , 15, zero_pad=True, normalize=True, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999997, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(x), np.amin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[1][1]\n",
    "    tn = inp[0][0]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "#     F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "\n",
    "def acc_match( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    " \n",
    "    return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "\n",
    "\n",
    "# def acc_none_zero ( true, pred ):\n",
    "    \n",
    "\n",
    "def acc_match_wierd( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    "    level = 6 \n",
    "    switch = 11\n",
    "    threeAxis=13\n",
    "    accel = 0 \n",
    "    status=10\n",
    "    contact=5\n",
    "    \n",
    "    counter  = 0 \n",
    "    for i in range( len (true) ):\n",
    "        if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "            counter+=1\n",
    "        else : \n",
    "            t_rec = np.array(list( pred[i]))\n",
    "            \n",
    "            if true[i][level]==1 and true[i][switch]==1 and t_rec[level]==1 :\n",
    "                t_rec[switch]=1\n",
    "            \n",
    "            if true[i][threeAxis]==1 and true[i][accel]==1 and t_rec[threeAxis]==1:\n",
    "                t_rec[accel] =1\n",
    "            \n",
    "            if true[i][status]==1 and true[i][contact]==1 and t_rec[status]==1:\n",
    "                t_rec[contact]=1\n",
    "#             print(t_rec , true[i])    \n",
    "            if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                counter+=1   \n",
    "            \n",
    "             \n",
    "            \n",
    "    \n",
    "    return counter*1.0 / len(true)\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidance=0.5 ):\n",
    "    \n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidance] = 1\n",
    "    pred[pred<confidance] = 0\n",
    "    \n",
    "#     acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %16s\"  %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    \n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn ))\n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "#     print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def make_readable_results ( inp , classes , conffidance=True):\n",
    "    ret = [] \n",
    "    inp =inp.astype(int)\n",
    "    for xx in range(len(inp)) :\n",
    "        u = inp[xx]\n",
    "        temp = []\n",
    "        for j in range(len(u)) : \n",
    "            if u[j] >0:\n",
    "                temp.append(classes[j])\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def makeReadable( model , data, gt, path , classes, x, confidance=0.5):\n",
    "    #collect across multi models\n",
    "    from keras.models import load_model\n",
    "    x=[]\n",
    "    for i in range(0,16):\n",
    "        model=load_model('number'+str(i)+'.h5',custom_objects={'f1_perRow':f1_perRow,'f1_perClass':f1_perClass,'f1_loss_perRow':f1_loss_perRow,'f1_loss_perClass':f1_loss_perClass})\n",
    "        x.append(model.predict(data))\n",
    "    x=np.array(x)\n",
    "    x=np.transpose(x)\n",
    "    x=np.squeeze(x)\n",
    "    print(x.shape)\n",
    "        \n",
    "        \n",
    "    pred_temp  = x\n",
    "    #pred_temp = model.predict(data)\n",
    "    print_info(gt, x, classes , confidance=confidance)\n",
    "#     print( len(classes ), len( pred_temp[0] ) )\n",
    "#     xcc= make_readable_results(pred_temp , classes)\n",
    "#     y_gt = make_readable_results( gt, classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] =  { 'seq': str(data[pick]),\n",
    "#                                'pred': xcc[pick],\n",
    "#                                 'true':y_gt[pick]\n",
    "#                                }   \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)\n",
    "\n",
    "\n",
    "# def makeReadable( model , data, gt, path , classes, confidance=0.7, x):\n",
    "#     pred_temp = model.predict( data)\n",
    "#     print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "#     xcc= make_readable_results( pred_temp , classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] = xcc[pick]  \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "# x_random_forest_test,y_random_forest_test, _ = pre_process_raw( x_test[0], y_test[0] , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "# x,y, classes = pre_process_raw( x_data, y_data , dim_size, zero_pad=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_random_forest_train, y_random_forest_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))\n",
    "# from sklearn import metrics\n",
    "# scores = cross_val_score(clf, x_random_forest_train, y_random_forest_train, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.500     0.750     0.600         6 3/32062/1/3\n",
      "                      activity     0.999      0.729     0.854     0.787        48 35/32015/6/13\n",
      "                       battery     1.000        nan     0.000     0.000         0 0/32067/2/0\n",
      "                        button     1.000      0.857     0.857     0.857         7 6/32061/1/1\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "                       contact     0.999      0.718     0.862     0.783        78 56/31982/9/22\n",
      "                         level     0.995      0.815     0.129     0.222        27 22/31893/149/5\n",
      "                          lock     0.999      0.786     0.234     0.361        14 11/32019/36/3\n",
      "                        motion     0.971      0.183     0.834     0.300      1099 201/30930/40/898\n",
      "                          ping     0.997      0.997     0.992     0.994      6975 6951/25037/57/24\n",
      "                        status     1.000      0.920     0.920     0.920        50 46/32015/4/4\n",
      "                        switch     1.000      0.957     1.000     0.978        23 22/32046/0/1\n",
      "                   temperature     0.955      0.095     0.706     0.168      1512 144/30497/60/1368\n",
      "                     threeAxis     0.999      0.625     0.250     0.357         8 5/32046/15/3\n",
      "                       unknown     0.897      0.984     0.882     0.930     22337 21990/6785/2947/347\n",
      "                         water     1.000        nan     0.000     0.000         0 0/32066/3/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.988      0.573     0.579     0.516     32069 0/0/0/0\n",
      "Exact Match ACC : 0.89304 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 811 (0.025)%\n",
      "Total ZXeros in Test : 173 (0.005)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.298     0.850     0.442        57 17/19908/3/40\n",
      "                      activity     0.999      0.684     0.684     0.684        19 13/19943/6/6\n",
      "                       battery     0.999      0.000     0.000     0.000         7 0/19958/3/7\n",
      "                        button     0.999      0.000     0.000     0.000        14 0/19953/1/14\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         6 4/19962/0/2\n",
      "                       contact     0.997      0.670     0.922     0.776       176 118/19782/10/58\n",
      "                         level     0.986      0.704     0.065     0.119        27 19/19668/273/8\n",
      "                          lock     0.997      0.771     0.386     0.514        35 27/19890/43/8\n",
      "                        motion     0.981      0.186     0.486     0.269       371 69/19524/73/302\n",
      "                          ping     0.997      0.994     0.992     0.993      4842 4814/15087/39/28\n",
      "                        status     0.998      0.723     0.851     0.782       119 86/19834/15/33\n",
      "                        switch     0.999      0.619     0.867     0.722        21 13/19945/2/8\n",
      "                   temperature     0.938      0.054     0.330     0.093      1168 63/18672/128/1105\n",
      "                     threeAxis     0.998      0.460     0.744     0.569        63 29/19895/10/34\n",
      "                       unknown     0.883      0.951     0.883     0.915     13305 12649/4983/1680/656\n",
      "                         water     1.000        nan     0.000     0.000         0 0/19964/4/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.986      0.486     0.566     0.480     19968 0/0/0/0\n",
      "Exact Match ACC : 0.86704 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 396 (0.020)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.200     1.000     0.333        25 5/9084/0/20\n",
      "                      activity     0.998      0.381     0.800     0.516        21 8/9086/2/13\n",
      "                       battery     1.000      0.000       nan     0.000         4 0/9105/0/4\n",
      "                        button     1.000      0.000     0.000     0.000         3 0/9105/1/3\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/9109/0/0\n",
      "                       contact     0.996      0.615     0.923     0.738        78 48/9027/4/30\n",
      "                         level     0.986      0.583     0.053     0.097        12 7/8972/125/5\n",
      "                          lock     0.997      0.545     0.414     0.471        22 12/9070/17/10\n",
      "                        motion     0.976      0.156     0.507     0.239       218 34/8858/33/184\n",
      "                          ping     0.996      0.993     0.989     0.991      2237 2222/6848/24/15\n",
      "                        status     0.996      0.580     0.674     0.624        50 29/9045/14/21\n",
      "                        switch     1.000      0.500     0.750     0.600         6 3/9102/1/3\n",
      "                   temperature     0.929      0.044     0.378     0.080       630 28/8433/46/602\n",
      "                     threeAxis     0.998      0.440     0.786     0.564        25 11/9081/3/14\n",
      "                       unknown     0.873      0.955     0.865     0.908      5948 5679/2276/885/269\n",
      "                         water     1.000        nan     0.000     0.000         0 0/9108/1/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.984      0.375     0.509     0.385      9109 0/0/0/0\n",
      "Exact Match ACC : 0.85772 \n",
      "Total Records : 9109 \n",
      "Total ZXeros in True : 168 (0.018)%\n",
      "Total ZXeros in Test : 158 (0.017)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.300     0.857     0.444        40 12/6362/2/28\n",
      "                      activity     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "                       battery     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                        button     0.991      0.067     1.000     0.125        60 4/6344/0/56\n",
      "              colorTemperature     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                       contact     0.987      0.526     0.989     0.687       175 92/6228/1/83\n",
      "                         level     0.993      0.424     0.757     0.544        66 28/6329/9/38\n",
      "                          lock     0.999        nan     0.000     0.000         0 0/6399/5/0\n",
      "                        motion     0.980      0.248     0.692     0.365       145 36/6243/16/109\n",
      "                          ping     0.998      0.997     0.997     0.997      2307 2300/4089/8/7\n",
      "                        status     0.996      0.786     0.988     0.876       103 81/6300/1/22\n",
      "                        switch     0.997      0.500     0.706     0.585        24 12/6375/5/12\n",
      "                   temperature     0.967      0.064     0.351     0.108       203 13/6177/24/190\n",
      "                     threeAxis     0.996      0.543     0.806     0.649        46 25/6352/6/21\n",
      "                       unknown     0.926      0.984     0.894     0.937      3558 3500/2433/413/58\n",
      "                         water     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.989      0.340     0.565     0.395      6404 0/0/0/0\n",
      "Exact Match ACC : 0.90256 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 80 (0.012)%\n",
      "Total ZXeros in Test : 105 (0.016)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_tests[i][0])\n",
    "    print_info( rf_tests[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeReadable( data=rf_tests[0][0], model=clf, classes=classes, confidance=0.7,gt=rf_tests[0][1], path='sk_home_out.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( \"mean : %f \\nstd: %f\\nmax:%f\" %( scores.mean(), scores.std(), scores.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts  = np.unique(np.array([ len(x) for x  in x_train ]), return_counts=True)\n",
    "# # np.sort( cnts[1] )\n",
    "# cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =15\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32069 32069\n",
      "19968 19968\n",
      "9109 9109\n",
      "6404 6404\n"
     ]
    }
   ],
   "source": [
    "for i in range( len(lstm_tests) ):\n",
    "    print( len( lstm_tests[i][0] ), len( lstm_tests_services[i][0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_lstm_prossed_train,axis=1)\n",
    "\n",
    "for tt  in range( len(lstm_tests) ):\n",
    "    lstm_tests[tt]= (lstm_tests[tt][0].reshape(len(lstm_tests[tt][0]),dim_size,1) , lstm_tests[tt][1],lstm_tests_services[tt][1] )\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_lstm_prossed_train.reshape(len(x_lstm_prossed_train),dim_size,1)\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60562.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_s_lstm_processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 15, 128)      512         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 15, 128)      512         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 128)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 15, 128)      512         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 15, 128)      0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 128)      512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 15, 128)      49280       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 128)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 15, 128)      49280       conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 15, 128)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 128)      512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 15, 128)      49280       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 128)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 15, 100)      91600       conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 15, 128)      0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (None, 15, 100)      40800       input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 15, 128)      12928       lstm_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 15, 128)      49280       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 15, 128)      12928       lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 15, 128)      16512       dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 15, 128)      49280       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 15, 128)      16512       dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 15, 128)      16512       dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 15, 128)      512         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 15, 128)      16512       dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 15, 128)      0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 15, 128)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 15, 128)      0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1920)         0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 15, 128)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1920)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          245888      flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 15, 128)      49280       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          245888      flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 128)          0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 1920)         0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 128)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)         (None, 2176)         0           dropout_23[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 128)          278656      mergerguy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          16512       dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          16512       dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service1 (Dense)             (None, 130)          16770       dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service2 (Dense)             (None, 130)          17030       to_service1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "service_output (Dense)          (None, 16)           2096        to_service2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,362,408\n",
      "Trainable params: 1,361,384\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 8s 142us/step - loss: 43.6971 - f1_perRow: 0.1063 - f1_perClass: 0.2686 - acc: 0.4095\n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 26.4622 - f1_perRow: 0.1756 - f1_perClass: 0.5600 - acc: 0.4668\n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 22.8054 - f1_perRow: 0.2088 - f1_perClass: 0.6177 - acc: 0.4668\n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 21.4111 - f1_perRow: 0.2358 - f1_perClass: 0.6313 - acc: 0.4668\n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 20.6156 - f1_perRow: 0.2643 - f1_perClass: 0.6402 - acc: 0.4668\n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 20.1501 - f1_perRow: 0.2864 - f1_perClass: 0.6498 - acc: 0.4668\n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 19.7205 - f1_perRow: 0.2919 - f1_perClass: 0.6507 - acc: 0.4668\n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 19.3537 - f1_perRow: 0.3191 - f1_perClass: 0.6596 - acc: 0.4668\n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 19.1065 - f1_perRow: 0.3276 - f1_perClass: 0.6619 - acc: 0.4668\n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.9657 - f1_perRow: 0.3374 - f1_perClass: 0.6640 - acc: 0.4668\n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.7443 - f1_perRow: 0.3372 - f1_perClass: 0.6650 - acc: 0.4668\n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.9449 - f1_perRow: 0.3446 - f1_perClass: 0.6653 - acc: 0.4668\n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.9606 - f1_perRow: 0.3470 - f1_perClass: 0.6644 - acc: 0.4668\n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 18.7136 - f1_perRow: 0.3380 - f1_perClass: 0.6656 - acc: 0.4668\n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 18.2103 - f1_perRow: 0.3466 - f1_perClass: 0.6789 - acc: 0.4668\n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 17.8727 - f1_perRow: 0.3567 - f1_perClass: 0.6861 - acc: 0.4668\n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 17.5389 - f1_perRow: 0.3617 - f1_perClass: 0.6902 - acc: 0.4668\n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 17.1680 - f1_perRow: 0.3642 - f1_perClass: 0.6961 - acc: 0.4668\n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.8942 - f1_perRow: 0.3675 - f1_perClass: 0.7006 - acc: 0.4668\n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.6934 - f1_perRow: 0.3763 - f1_perClass: 0.7056 - acc: 0.4668\n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.6418 - f1_perRow: 0.3795 - f1_perClass: 0.7060 - acc: 0.4668\n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.4750 - f1_perRow: 0.3785 - f1_perClass: 0.7070 - acc: 0.4668\n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.7826 - f1_perRow: 0.3826 - f1_perClass: 0.7065 - acc: 0.4668\n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.6849 - f1_perRow: 0.3831 - f1_perClass: 0.7064 - acc: 0.4668\n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.4770 - f1_perRow: 0.3829 - f1_perClass: 0.7051 - acc: 0.4668\n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.3737 - f1_perRow: 0.3915 - f1_perClass: 0.7104 - acc: 0.4668\n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2822 - f1_perRow: 0.3922 - f1_perClass: 0.7124 - acc: 0.4668\n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.1953 - f1_perRow: 0.3939 - f1_perClass: 0.7106 - acc: 0.4668\n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 16.1095 - f1_perRow: 0.4012 - f1_perClass: 0.7112 - acc: 0.4668\n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 16.2865 - f1_perRow: 0.3996 - f1_perClass: 0.7106 - acc: 0.4668\n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.1901 - f1_perRow: 0.3964 - f1_perClass: 0.7120 - acc: 0.4668\n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 16.2784 - f1_perRow: 0.4041 - f1_perClass: 0.7112 - acc: 0.4668\n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.1683 - f1_perRow: 0.3972 - f1_perClass: 0.7082 - acc: 0.4668\n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2135 - f1_perRow: 0.4063 - f1_perClass: 0.7113 - acc: 0.4668\n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.3622 - f1_perRow: 0.4040 - f1_perClass: 0.7142 - acc: 0.4668\n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.2537 - f1_perRow: 0.3961 - f1_perClass: 0.7115 - acc: 0.4668\n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 16.2493 - f1_perRow: 0.4074 - f1_perClass: 0.7093 - acc: 0.4667\n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.1494 - f1_perRow: 0.4021 - f1_perClass: 0.7140 - acc: 0.4668\n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.0783 - f1_perRow: 0.4111 - f1_perClass: 0.7150 - acc: 0.4668\n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2232 - f1_perRow: 0.4068 - f1_perClass: 0.7127 - acc: 0.4668\n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2912 - f1_perRow: 0.4012 - f1_perClass: 0.7118 - acc: 0.4668\n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.1168 - f1_perRow: 0.4040 - f1_perClass: 0.7111 - acc: 0.4668\n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 16.0148 - f1_perRow: 0.4134 - f1_perClass: 0.7135 - acc: 0.4668\n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.9076 - f1_perRow: 0.4161 - f1_perClass: 0.7174 - acc: 0.4668\n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8050 - f1_perRow: 0.4193 - f1_perClass: 0.7149 - acc: 0.4668\n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.9886 - f1_perRow: 0.4173 - f1_perClass: 0.7142 - acc: 0.4667\n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.0075 - f1_perRow: 0.4144 - f1_perClass: 0.7144 - acc: 0.4669\n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.8299 - f1_perRow: 0.4137 - f1_perClass: 0.7147 - acc: 0.4668\n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.9007 - f1_perRow: 0.4193 - f1_perClass: 0.7161 - acc: 0.4669\n",
      "Epoch 50/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7005 - f1_perRow: 0.4253 - f1_perClass: 0.7172 - acc: 0.4668\n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7086 - f1_perRow: 0.4264 - f1_perClass: 0.7163 - acc: 0.4668\n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6868 - f1_perRow: 0.4285 - f1_perClass: 0.7177 - acc: 0.4668\n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.6149 - f1_perRow: 0.4327 - f1_perClass: 0.7182 - acc: 0.4668\n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8317 - f1_perRow: 0.4286 - f1_perClass: 0.7170 - acc: 0.4668\n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.6808 - f1_perRow: 0.4326 - f1_perClass: 0.7185 - acc: 0.4672\n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8240 - f1_perRow: 0.4285 - f1_perClass: 0.7167 - acc: 0.4668\n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8643 - f1_perRow: 0.4266 - f1_perClass: 0.7146 - acc: 0.4670\n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.9413 - f1_perRow: 0.4225 - f1_perClass: 0.7138 - acc: 0.4672\n",
      "Epoch 59/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7736 - f1_perRow: 0.4278 - f1_perClass: 0.7178 - acc: 0.4673\n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7154 - f1_perRow: 0.4320 - f1_perClass: 0.7187 - acc: 0.4670\n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6191 - f1_perRow: 0.4392 - f1_perClass: 0.7198 - acc: 0.4669\n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 15.6912 - f1_perRow: 0.4335 - f1_perClass: 0.7164 - acc: 0.4673\n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.9293 - f1_perRow: 0.4376 - f1_perClass: 0.7169 - acc: 0.4668\n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.1098 - f1_perRow: 0.4238 - f1_perClass: 0.7118 - acc: 0.4692\n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 16.1241 - f1_perRow: 0.4136 - f1_perClass: 0.7153 - acc: 0.4678\n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.0319 - f1_perRow: 0.4219 - f1_perClass: 0.7157 - acc: 0.4668\n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7968 - f1_perRow: 0.4259 - f1_perClass: 0.7177 - acc: 0.4671\n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7002 - f1_perRow: 0.4392 - f1_perClass: 0.7175 - acc: 0.4682\n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.9568 - f1_perRow: 0.4300 - f1_perClass: 0.7157 - acc: 0.4698\n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8351 - f1_perRow: 0.4193 - f1_perClass: 0.7136 - acc: 0.4807\n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.0141 - f1_perRow: 0.4302 - f1_perClass: 0.7160 - acc: 0.4836\n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.7971 - f1_perRow: 0.4267 - f1_perClass: 0.7173 - acc: 0.4786\n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.6511 - f1_perRow: 0.4356 - f1_perClass: 0.7183 - acc: 0.4762\n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.5904 - f1_perRow: 0.4407 - f1_perClass: 0.7178 - acc: 0.4696\n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.5591 - f1_perRow: 0.4433 - f1_perClass: 0.7187 - acc: 0.4692\n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.2002 - f1_perRow: 0.4359 - f1_perClass: 0.7120 - acc: 0.4736\n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.8229 - f1_perRow: 0.4299 - f1_perClass: 0.7187 - acc: 0.4725\n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7039 - f1_perRow: 0.4298 - f1_perClass: 0.7183 - acc: 0.4732\n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5572 - f1_perRow: 0.4458 - f1_perClass: 0.7187 - acc: 0.4722\n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.6370 - f1_perRow: 0.4398 - f1_perClass: 0.7179 - acc: 0.4709\n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6581 - f1_perRow: 0.4419 - f1_perClass: 0.7174 - acc: 0.4735\n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 15.8257 - f1_perRow: 0.4398 - f1_perClass: 0.7186 - acc: 0.4718\n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6923 - f1_perRow: 0.4351 - f1_perClass: 0.7165 - acc: 0.4724\n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6567 - f1_perRow: 0.4406 - f1_perClass: 0.7174 - acc: 0.4724\n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.6021 - f1_perRow: 0.4503 - f1_perClass: 0.7235 - acc: 0.4692\n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5748 - f1_perRow: 0.4445 - f1_perClass: 0.7175 - acc: 0.4690\n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.8605 - f1_perRow: 0.4361 - f1_perClass: 0.7129 - acc: 0.4704\n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.9338 - f1_perRow: 0.4467 - f1_perClass: 0.7180 - acc: 0.4704\n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.7182 - f1_perRow: 0.4348 - f1_perClass: 0.7192 - acc: 0.4701\n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.7255 - f1_perRow: 0.4441 - f1_perClass: 0.7167 - acc: 0.4677\n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.8937 - f1_perRow: 0.4425 - f1_perClass: 0.7166 - acc: 0.4687\n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.8147 - f1_perRow: 0.4342 - f1_perClass: 0.7160 - acc: 0.4697\n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.5519 - f1_perRow: 0.4387 - f1_perClass: 0.7196 - acc: 0.4697\n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.4260 - f1_perRow: 0.4528 - f1_perClass: 0.7204 - acc: 0.4683\n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.4555 - f1_perRow: 0.4553 - f1_perClass: 0.7223 - acc: 0.4696\n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5181 - f1_perRow: 0.4539 - f1_perClass: 0.7178 - acc: 0.4711\n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 15.6191 - f1_perRow: 0.4518 - f1_perClass: 0.7180 - acc: 0.4731\n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6876 - f1_perRow: 0.4580 - f1_perClass: 0.7223 - acc: 0.4706\n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7191 - f1_perRow: 0.4363 - f1_perClass: 0.7134 - acc: 0.4714\n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5555 - f1_perRow: 0.4467 - f1_perClass: 0.7206 - acc: 0.4693\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    " \n",
    "weights = [\n",
    "1.0/(57.0 / len(y_train)),\n",
    "1.0/(19.0 / len(y_train)),\n",
    "1.0/(7.0 / len(y_train)),\n",
    "1.0/(14.0 / len(y_train)),\n",
    "1.0/(6.0 / len(y_train)),\n",
    "1.0/(176.0 / len(y_train)),\n",
    "1.0/(27.0 / len(y_train)),\n",
    "1.0/(35.0 / len(y_train)),\n",
    "1.0/(371.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "1.0/(4842.0 / len(y_train)),\n",
    "1.0/(119.0 / len(y_train)),\n",
    "1.0/(21.0 / len(y_train)),\n",
    "1.0/(1168.0 / len(y_train)),\n",
    "1.0/(63.0 / len(y_train)),\n",
    "1.0/(13305.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dout_2)\n",
    "\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "#model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=1000, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(fl_out_cnn)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 15, 128)      512         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 15, 128)      512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 128)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 128)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 15, 128)      49280       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 15, 128)      49280       conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 128)      512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 15, 128)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 15, 100)      40800       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 15, 128)      49280       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 15, 128)      12928       lstm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 15, 128)      49280       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 15, 128)      16512       dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 128)      512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 15, 128)      16512       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 15, 128)      0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 15, 128)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1920)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 15, 128)      49280       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          245888      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1920)         0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)         (None, 2048)         0           flatten_5[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          262272      mergerguy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 128)          16512       dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          16512       dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "service_output (Dense)          (None, 16)           2064        dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 878,448\n",
      "Trainable params: 877,680\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "12500/57867 [=====>........................] - ETA: 12s - loss: 58.0834 - f1_perRow: 0.0828 - f1_perClass: 0.1178 - acc: 0.0189"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3e8e681da645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m \u001b[0mhist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1)) \n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [ fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(dens_out_3)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perClass ,\n",
    "#     \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "#     \"service_output\": 20\n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=1e-6  ), metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 15, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 15, 32)            4352      \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 15, 32)            8320      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               123136    \n",
      "_________________________________________________________________\n",
      "service_output (Dense)       (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 139,920\n",
      "Trainable params: 139,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 3s 59us/step - loss: 54.3017 - f1_perRow: 0.0879 - f1_perClass: 0.1406 - acc: 0.3632\n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 47.1223 - f1_perRow: 0.0956 - f1_perClass: 0.2038 - acc: 0.4668\n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 39.7733 - f1_perRow: 0.0966 - f1_perClass: 0.3015 - acc: 0.4668\n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 33.0610 - f1_perRow: 0.0932 - f1_perClass: 0.4503 - acc: 0.4668\n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 32.6438 - f1_perRow: 0.0903 - f1_perClass: 0.5036 - acc: 0.4668\n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 32.1282 - f1_perRow: 0.0925 - f1_perClass: 0.4915 - acc: 0.4668\n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.8512 - f1_perRow: 0.0952 - f1_perClass: 0.4680 - acc: 0.4668\n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.4738 - f1_perRow: 0.0958 - f1_perClass: 0.4722 - acc: 0.4668\n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.3429 - f1_perRow: 0.0955 - f1_perClass: 0.4815 - acc: 0.4668\n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.1962 - f1_perRow: 0.0963 - f1_perClass: 0.4835 - acc: 0.4668\n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.9905 - f1_perRow: 0.0981 - f1_perClass: 0.4819 - acc: 0.4668\n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.8031 - f1_perRow: 0.1006 - f1_perClass: 0.4811 - acc: 0.4668\n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.5949 - f1_perRow: 0.1034 - f1_perClass: 0.4844 - acc: 0.4668\n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.3951 - f1_perRow: 0.1065 - f1_perClass: 0.4871 - acc: 0.4668\n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.1728 - f1_perRow: 0.1096 - f1_perClass: 0.4891 - acc: 0.4668\n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 29.9330 - f1_perRow: 0.1128 - f1_perClass: 0.4896 - acc: 0.4668\n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 29.6195 - f1_perRow: 0.1157 - f1_perClass: 0.4937 - acc: 0.4668\n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 29.1599 - f1_perRow: 0.1192 - f1_perClass: 0.4997 - acc: 0.4668\n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 28.5980 - f1_perRow: 0.1217 - f1_perClass: 0.5073 - acc: 0.4668\n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 27.8934 - f1_perRow: 0.1213 - f1_perClass: 0.5159 - acc: 0.4668\n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 27.1718 - f1_perRow: 0.1213 - f1_perClass: 0.5316 - acc: 0.4668\n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 26.2048 - f1_perRow: 0.1297 - f1_perClass: 0.5424 - acc: 0.4668\n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 25.1793 - f1_perRow: 0.1331 - f1_perClass: 0.5678 - acc: 0.4668\n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 24.2777 - f1_perRow: 0.1398 - f1_perClass: 0.5797 - acc: 0.4668\n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 23.6299 - f1_perRow: 0.1451 - f1_perClass: 0.5943 - acc: 0.4668\n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 23.2823 - f1_perRow: 0.1513 - f1_perClass: 0.6024 - acc: 0.4668\n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 23.0039 - f1_perRow: 0.1580 - f1_perClass: 0.6064 - acc: 0.4669\n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.7532 - f1_perRow: 0.1621 - f1_perClass: 0.6110 - acc: 0.4751\n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.5807 - f1_perRow: 0.1665 - f1_perClass: 0.6133 - acc: 0.4993\n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.4469 - f1_perRow: 0.1709 - f1_perClass: 0.6153 - acc: 0.5263\n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.3040 - f1_perRow: 0.1726 - f1_perClass: 0.6186 - acc: 0.5407\n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.1971 - f1_perRow: 0.1759 - f1_perClass: 0.6193 - acc: 0.5559\n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.0964 - f1_perRow: 0.1783 - f1_perClass: 0.6213 - acc: 0.5711\n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.0149 - f1_perRow: 0.1800 - f1_perClass: 0.6207 - acc: 0.5895\n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 21.9273 - f1_perRow: 0.1822 - f1_perClass: 0.6237 - acc: 0.6037\n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.8773 - f1_perRow: 0.1843 - f1_perClass: 0.6246 - acc: 0.6143\n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 21.8034 - f1_perRow: 0.1863 - f1_perClass: 0.6249 - acc: 0.6295\n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.7496 - f1_perRow: 0.1882 - f1_perClass: 0.6257 - acc: 0.6379\n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.6688 - f1_perRow: 0.1897 - f1_perClass: 0.6277 - acc: 0.6502\n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.5968 - f1_perRow: 0.1910 - f1_perClass: 0.6277 - acc: 0.6609\n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.5437 - f1_perRow: 0.1930 - f1_perClass: 0.6277 - acc: 0.6709\n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.3841 - f1_perRow: 0.1937 - f1_perClass: 0.6304 - acc: 0.6785\n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.7072 - f1_perRow: 0.1955 - f1_perClass: 0.6458 - acc: 0.6830\n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.4598 - f1_perRow: 0.1957 - f1_perClass: 0.6494 - acc: 0.6855\n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 20.2493 - f1_perRow: 0.1972 - f1_perClass: 0.6533 - acc: 0.6856\n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.1383 - f1_perRow: 0.2001 - f1_perClass: 0.6546 - acc: 0.6857\n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.0533 - f1_perRow: 0.2018 - f1_perClass: 0.6577 - acc: 0.6865\n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.9764 - f1_perRow: 0.2036 - f1_perClass: 0.6547 - acc: 0.6873\n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.9065 - f1_perRow: 0.2043 - f1_perClass: 0.6606 - acc: 0.6885\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.8210 - f1_perRow: 0.2051 - f1_perClass: 0.6559 - acc: 0.6892\n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.7730 - f1_perRow: 0.2053 - f1_perClass: 0.6598 - acc: 0.6906\n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.6856 - f1_perRow: 0.2065 - f1_perClass: 0.6568 - acc: 0.6915\n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 19.6091 - f1_perRow: 0.2073 - f1_perClass: 0.6582 - acc: 0.6931\n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.4873 - f1_perRow: 0.2075 - f1_perClass: 0.6516 - acc: 0.6972\n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.4158 - f1_perRow: 0.2054 - f1_perClass: 0.6418 - acc: 0.7014\n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.6441 - f1_perRow: 0.2018 - f1_perClass: 0.6230 - acc: 0.6998\n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.6609 - f1_perRow: 0.2042 - f1_perClass: 0.6356 - acc: 0.7044\n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.3766 - f1_perRow: 0.2061 - f1_perClass: 0.6315 - acc: 0.7061\n",
      "Epoch 59/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.2879 - f1_perRow: 0.2043 - f1_perClass: 0.6224 - acc: 0.7080\n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.0608 - f1_perRow: 0.2040 - f1_perClass: 0.6172 - acc: 0.7151\n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.8748 - f1_perRow: 0.2046 - f1_perClass: 0.6088 - acc: 0.7250\n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.7436 - f1_perRow: 0.2022 - f1_perClass: 0.5884 - acc: 0.7304\n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.6658 - f1_perRow: 0.2031 - f1_perClass: 0.5875 - acc: 0.7293\n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.4735 - f1_perRow: 0.2029 - f1_perClass: 0.5822 - acc: 0.7375\n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.3581 - f1_perRow: 0.2033 - f1_perClass: 0.5854 - acc: 0.7411\n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.2633 - f1_perRow: 0.2082 - f1_perClass: 0.5972 - acc: 0.7418\n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.1938 - f1_perRow: 0.2097 - f1_perClass: 0.6079 - acc: 0.7428\n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.0776 - f1_perRow: 0.2137 - f1_perClass: 0.6208 - acc: 0.7441\n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.0133 - f1_perRow: 0.2173 - f1_perClass: 0.6366 - acc: 0.7442\n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.9147 - f1_perRow: 0.2208 - f1_perClass: 0.6380 - acc: 0.7450\n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.8203 - f1_perRow: 0.2233 - f1_perClass: 0.6468 - acc: 0.7452\n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.7141 - f1_perRow: 0.2272 - f1_perClass: 0.6494 - acc: 0.7455\n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.6237 - f1_perRow: 0.2326 - f1_perClass: 0.6557 - acc: 0.7456\n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.5573 - f1_perRow: 0.2346 - f1_perClass: 0.6576 - acc: 0.7454\n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.4716 - f1_perRow: 0.2384 - f1_perClass: 0.6621 - acc: 0.7458\n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.3506 - f1_perRow: 0.2429 - f1_perClass: 0.6660 - acc: 0.7458\n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.2814 - f1_perRow: 0.2469 - f1_perClass: 0.6711 - acc: 0.7457\n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.2063 - f1_perRow: 0.2493 - f1_perClass: 0.6729 - acc: 0.7459\n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.1656 - f1_perRow: 0.2508 - f1_perClass: 0.6687 - acc: 0.7456\n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.0475 - f1_perRow: 0.2524 - f1_perClass: 0.6772 - acc: 0.7459\n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8934 - f1_perRow: 0.2599 - f1_perClass: 0.6786 - acc: 0.7460\n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8809 - f1_perRow: 0.2609 - f1_perClass: 0.6772 - acc: 0.7459\n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8498 - f1_perRow: 0.2615 - f1_perClass: 0.6800 - acc: 0.7457\n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.7646 - f1_perRow: 0.2631 - f1_perClass: 0.6836 - acc: 0.7461\n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.7351 - f1_perRow: 0.2658 - f1_perClass: 0.6847 - acc: 0.7458\n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8061 - f1_perRow: 0.2603 - f1_perClass: 0.6747 - acc: 0.7461\n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.6325 - f1_perRow: 0.2661 - f1_perClass: 0.6704 - acc: 0.7462\n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.5164 - f1_perRow: 0.2646 - f1_perClass: 0.6674 - acc: 0.7470\n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.4678 - f1_perRow: 0.2672 - f1_perClass: 0.6680 - acc: 0.7479\n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.4416 - f1_perRow: 0.2606 - f1_perClass: 0.6619 - acc: 0.7505\n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.3941 - f1_perRow: 0.2596 - f1_perClass: 0.6611 - acc: 0.7536\n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.2971 - f1_perRow: 0.2597 - f1_perClass: 0.6603 - acc: 0.7576\n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.2182 - f1_perRow: 0.2601 - f1_perClass: 0.6533 - acc: 0.7602\n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.0940 - f1_perRow: 0.2519 - f1_perClass: 0.6518 - acc: 0.7625\n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.1122 - f1_perRow: 0.2467 - f1_perClass: 0.6396 - acc: 0.7654\n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.9340 - f1_perRow: 0.2425 - f1_perClass: 0.6342 - acc: 0.7674\n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.8248 - f1_perRow: 0.2365 - f1_perClass: 0.6360 - acc: 0.7705\n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.8781 - f1_perRow: 0.2345 - f1_perClass: 0.6310 - acc: 0.7721\n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.6740 - f1_perRow: 0.2313 - f1_perClass: 0.6307 - acc: 0.7727\n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.7928 - f1_perRow: 0.2253 - f1_perClass: 0.6228 - acc: 0.7733\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
    "lstm_2 = LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(lstm_1)\n",
    "\n",
    "lstm_2=Flatten()(lstm_2)\n",
    "lstm_2 = Dense(256, activation='relu')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 76s 1ms/step - loss: 3.3806 - f1_perRow: 0.0025 - f1_perClass: 5.9415e-04 - acc: 0.9829\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7130 - f1_perRow: 0.0088 - f1_perClass: 1.2165e-04 - acc: 0.9955\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5764 - f1_perRow: 0.0163 - f1_perClass: 1.0032e-04 - acc: 0.9955\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5369 - f1_perRow: 0.0341 - f1_perClass: 3.4393e-04 - acc: 0.9955\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5182 - f1_perRow: 0.0383 - f1_perClass: 2.6856e-04 - acc: 0.9955\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5019 - f1_perRow: 0.0401 - f1_perClass: 3.5495e-04 - acc: 0.9955\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4976 - f1_perRow: 0.0415 - f1_perClass: 3.1677e-04 - acc: 0.9955\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4833 - f1_perRow: 0.0484 - f1_perClass: 3.8441e-04 - acc: 0.9955\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4641 - f1_perRow: 0.0555 - f1_perClass: 4.3469e-04 - acc: 0.9955\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4596 - f1_perRow: 0.0554 - f1_perClass: 4.3543e-04 - acc: 0.9955\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4569 - f1_perRow: 0.0578 - f1_perClass: 4.4778e-04 - acc: 0.9955\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4511 - f1_perRow: 0.0733 - f1_perClass: 5.3020e-04 - acc: 0.9955\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4449 - f1_perRow: 0.0808 - f1_perClass: 5.6431e-04 - acc: 0.9955\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4422 - f1_perRow: 0.0894 - f1_perClass: 6.3066e-04 - acc: 0.9957\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4382 - f1_perRow: 0.1138 - f1_perClass: 7.1121e-04 - acc: 0.9958\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4364 - f1_perRow: 0.1132 - f1_perClass: 7.3645e-04 - acc: 0.9958\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4308 - f1_perRow: 0.1248 - f1_perClass: 7.8393e-04 - acc: 0.9959\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4390 - f1_perRow: 0.1363 - f1_perClass: 8.1154e-04 - acc: 0.9958\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4317 - f1_perRow: 0.1313 - f1_perClass: 7.6289e-04 - acc: 0.9958\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4258 - f1_perRow: 0.1365 - f1_perClass: 8.0540e-04 - acc: 0.9959\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4263 - f1_perRow: 0.1380 - f1_perClass: 8.5432e-04 - acc: 0.9958\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4274 - f1_perRow: 0.1513 - f1_perClass: 8.6720e-04 - acc: 0.9959\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4347 - f1_perRow: 0.1260 - f1_perClass: 7.5975e-04 - acc: 0.9957\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4281 - f1_perRow: 0.1426 - f1_perClass: 8.1248e-04 - acc: 0.9958\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4259 - f1_perRow: 0.1375 - f1_perClass: 8.7724e-04 - acc: 0.9958\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4252 - f1_perRow: 0.1610 - f1_perClass: 8.9078e-04 - acc: 0.9959\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4247 - f1_perRow: 0.1560 - f1_perClass: 8.6202e-04 - acc: 0.9959\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4260 - f1_perRow: 0.1429 - f1_perClass: 9.0212e-04 - acc: 0.9958\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4249 - f1_perRow: 0.1562 - f1_perClass: 9.0758e-04 - acc: 0.9959\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4244 - f1_perRow: 0.1455 - f1_perClass: 8.4292e-04 - acc: 0.9960\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4256 - f1_perRow: 0.1536 - f1_perClass: 9.0459e-04 - acc: 0.9957\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4243 - f1_perRow: 0.1300 - f1_perClass: 8.0137e-04 - acc: 0.9958\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4186 - f1_perRow: 0.1720 - f1_perClass: 9.3763e-04 - acc: 0.9960\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4217 - f1_perRow: 0.1415 - f1_perClass: 8.6438e-04 - acc: 0.9959\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4250 - f1_perRow: 0.1667 - f1_perClass: 9.1717e-04 - acc: 0.9958\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4241 - f1_perRow: 0.1493 - f1_perClass: 8.4141e-04 - acc: 0.9959\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4188 - f1_perRow: 0.1527 - f1_perClass: 9.1499e-04 - acc: 0.9959\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4160 - f1_perRow: 0.1663 - f1_perClass: 9.8615e-04 - acc: 0.9960\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4210 - f1_perRow: 0.1782 - f1_perClass: 9.3551e-04 - acc: 0.9959\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4198 - f1_perRow: 0.1477 - f1_perClass: 8.9088e-04 - acc: 0.9959\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4219 - f1_perRow: 0.1465 - f1_perClass: 8.9896e-04 - acc: 0.9959\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4151 - f1_perRow: 0.1788 - f1_perClass: 9.7979e-04 - acc: 0.9959\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4183 - f1_perRow: 0.1533 - f1_perClass: 8.9158e-04 - acc: 0.9959\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4169 - f1_perRow: 0.1694 - f1_perClass: 9.5766e-04 - acc: 0.9958\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4162 - f1_perRow: 0.1627 - f1_perClass: 9.4031e-04 - acc: 0.9959\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4197 - f1_perRow: 0.1563 - f1_perClass: 8.8701e-04 - acc: 0.9958\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4161 - f1_perRow: 0.1664 - f1_perClass: 9.7158e-04 - acc: 0.9960\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4191 - f1_perRow: 0.1546 - f1_perClass: 9.4208e-04 - acc: 0.9959\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4180 - f1_perRow: 0.1725 - f1_perClass: 8.7025e-04 - acc: 0.9959\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4221 - f1_perRow: 0.1675 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4160 - f1_perRow: 0.1560 - f1_perClass: 9.3453e-04 - acc: 0.9957\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4173 - f1_perRow: 0.1633 - f1_perClass: 9.2027e-04 - acc: 0.9960\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4150 - f1_perRow: 0.1489 - f1_perClass: 9.2979e-04 - acc: 0.9959\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4196 - f1_perRow: 0.1785 - f1_perClass: 9.0909e-04 - acc: 0.9959\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4194 - f1_perRow: 0.1706 - f1_perClass: 0.0010 - acc: 0.9958\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4132 - f1_perRow: 0.1526 - f1_perClass: 9.5672e-04 - acc: 0.9959\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4259 - f1_perRow: 0.1640 - f1_perClass: 9.2709e-04 - acc: 0.9959\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4210 - f1_perRow: 0.1374 - f1_perClass: 7.5757e-04 - acc: 0.9959\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4146 - f1_perRow: 0.1724 - f1_perClass: 9.7247e-04 - acc: 0.9959\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4138 - f1_perRow: 0.1625 - f1_perClass: 9.6750e-04 - acc: 0.9959\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4134 - f1_perRow: 0.1787 - f1_perClass: 9.3718e-04 - acc: 0.9960\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4127 - f1_perRow: 0.1645 - f1_perClass: 9.7653e-04 - acc: 0.9959\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4154 - f1_perRow: 0.1604 - f1_perClass: 9.8216e-04 - acc: 0.9960\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4175 - f1_perRow: 0.1905 - f1_perClass: 9.3674e-04 - acc: 0.9958\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4199 - f1_perRow: 0.1450 - f1_perClass: 9.2193e-04 - acc: 0.9959\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4131 - f1_perRow: 0.1743 - f1_perClass: 9.6398e-04 - acc: 0.9959\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4198 - f1_perRow: 0.1691 - f1_perClass: 9.4851e-04 - acc: 0.9959\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4126 - f1_perRow: 0.1531 - f1_perClass: 9.5305e-04 - acc: 0.9960\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4118 - f1_perRow: 0.1921 - f1_perClass: 9.9165e-04 - acc: 0.9959\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4151 - f1_perRow: 0.1520 - f1_perClass: 9.4885e-04 - acc: 0.9960\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4145 - f1_perRow: 0.1777 - f1_perClass: 9.8473e-04 - acc: 0.9957\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4095 - f1_perRow: 0.1695 - f1_perClass: 9.7835e-04 - acc: 0.9959\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4089 - f1_perRow: 0.1556 - f1_perClass: 9.0695e-04 - acc: 0.9959\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4078 - f1_perRow: 0.1818 - f1_perClass: 9.9602e-04 - acc: 0.9960\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4112 - f1_perRow: 0.1725 - f1_perClass: 9.9306e-04 - acc: 0.9960\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4138 - f1_perRow: 0.1625 - f1_perClass: 9.3981e-04 - acc: 0.9960\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4129 - f1_perRow: 0.1606 - f1_perClass: 9.3988e-04 - acc: 0.9960\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4100 - f1_perRow: 0.1732 - f1_perClass: 9.6000e-04 - acc: 0.9959\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4126 - f1_perRow: 0.1765 - f1_perClass: 0.0010 - acc: 0.9958\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4128 - f1_perRow: 0.1606 - f1_perClass: 8.5371e-04 - acc: 0.9959\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4141 - f1_perRow: 0.1604 - f1_perClass: 9.8002e-04 - acc: 0.9960\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4099 - f1_perRow: 0.1813 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4075 - f1_perRow: 0.1701 - f1_perClass: 9.2274e-04 - acc: 0.9960\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4071 - f1_perRow: 0.1612 - f1_perClass: 9.5629e-04 - acc: 0.9960\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4106 - f1_perRow: 0.1807 - f1_perClass: 0.0010 - acc: 0.9958\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4048 - f1_perRow: 0.1797 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4095 - f1_perRow: 0.1813 - f1_perClass: 9.6565e-04 - acc: 0.9959\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4076 - f1_perRow: 0.1660 - f1_perClass: 9.6754e-04 - acc: 0.9959\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4069 - f1_perRow: 0.1795 - f1_perClass: 9.9473e-04 - acc: 0.9960\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4073 - f1_perRow: 0.1672 - f1_perClass: 9.6600e-04 - acc: 0.9959\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4074 - f1_perRow: 0.1834 - f1_perClass: 9.7564e-04 - acc: 0.9960\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4086 - f1_perRow: 0.1773 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4066 - f1_perRow: 0.1644 - f1_perClass: 9.6162e-04 - acc: 0.9960\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4064 - f1_perRow: 0.1772 - f1_perClass: 9.5619e-04 - acc: 0.9960\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4067 - f1_perRow: 0.1751 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4058 - f1_perRow: 0.1771 - f1_perClass: 9.9210e-04 - acc: 0.9959\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4047 - f1_perRow: 0.1724 - f1_perClass: 9.8504e-04 - acc: 0.9959\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4065 - f1_perRow: 0.1835 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4056 - f1_perRow: 0.1793 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4067 - f1_perRow: 0.1691 - f1_perClass: 9.2586e-04 - acc: 0.9960\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4050 - f1_perRow: 0.1737 - f1_perClass: 9.8329e-04 - acc: 0.9960\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4063 - f1_perRow: 0.1765 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4087 - f1_perRow: 0.1712 - f1_perClass: 9.0521e-04 - acc: 0.9959\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4081 - f1_perRow: 0.1793 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4060 - f1_perRow: 0.1635 - f1_perClass: 9.0776e-04 - acc: 0.9960\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4083 - f1_perRow: 0.1750 - f1_perClass: 9.7886e-04 - acc: 0.9961\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4138 - f1_perRow: 0.1728 - f1_perClass: 0.0011 - acc: 0.9958\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4098 - f1_perRow: 0.1763 - f1_perClass: 9.5722e-04 - acc: 0.9959\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4115 - f1_perRow: 0.1739 - f1_perClass: 9.6075e-04 - acc: 0.9959\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4074 - f1_perRow: 0.1759 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4042 - f1_perRow: 0.1780 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4025 - f1_perRow: 0.1796 - f1_perClass: 9.6760e-04 - acc: 0.9960\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4082 - f1_perRow: 0.1753 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4062 - f1_perRow: 0.1736 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4082 - f1_perRow: 0.1873 - f1_perClass: 9.9352e-04 - acc: 0.9961\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4090 - f1_perRow: 0.1599 - f1_perClass: 9.3501e-04 - acc: 0.9960\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4050 - f1_perRow: 0.1854 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4048 - f1_perRow: 0.1838 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4030 - f1_perRow: 0.1644 - f1_perClass: 9.7409e-04 - acc: 0.9960\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4046 - f1_perRow: 0.1847 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4065 - f1_perRow: 0.1925 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4024 - f1_perRow: 0.1766 - f1_perClass: 9.9862e-04 - acc: 0.9960\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4036 - f1_perRow: 0.1771 - f1_perClass: 9.9642e-04 - acc: 0.9960\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4054 - f1_perRow: 0.1837 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4032 - f1_perRow: 0.1817 - f1_perClass: 9.9882e-04 - acc: 0.9959\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4037 - f1_perRow: 0.1667 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4109 - f1_perRow: 0.1849 - f1_perClass: 9.7082e-04 - acc: 0.9960\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4100 - f1_perRow: 0.1826 - f1_perClass: 9.8841e-04 - acc: 0.9960\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4046 - f1_perRow: 0.1724 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4082 - f1_perRow: 0.1685 - f1_perClass: 9.8564e-04 - acc: 0.9960\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4100 - f1_perRow: 0.1910 - f1_perClass: 0.0010 - acc: 0.9958\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4057 - f1_perRow: 0.1649 - f1_perClass: 9.4777e-04 - acc: 0.9960\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4059 - f1_perRow: 0.1815 - f1_perClass: 9.8787e-04 - acc: 0.9960\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4053 - f1_perRow: 0.1795 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4069 - f1_perRow: 0.1754 - f1_perClass: 9.1624e-04 - acc: 0.9960\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4050 - f1_perRow: 0.1733 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4117 - f1_perRow: 0.1767 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4048 - f1_perRow: 0.1758 - f1_perClass: 9.3338e-04 - acc: 0.9960\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4046 - f1_perRow: 0.1849 - f1_perClass: 9.9994e-04 - acc: 0.9960\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4036 - f1_perRow: 0.1785 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4029 - f1_perRow: 0.1786 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4085 - f1_perRow: 0.1884 - f1_perClass: 9.9076e-04 - acc: 0.9960\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4045 - f1_perRow: 0.1709 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4023 - f1_perRow: 0.1978 - f1_perClass: 0.0011 - acc: 0.9960\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4074 - f1_perRow: 0.1777 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4066 - f1_perRow: 0.1678 - f1_perClass: 9.7068e-04 - acc: 0.9960\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4052 - f1_perRow: 0.2000 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4069 - f1_perRow: 0.1634 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4143 - f1_perRow: 0.1915 - f1_perClass: 9.5795e-04 - acc: 0.9960\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4170 - f1_perRow: 0.1799 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4061 - f1_perRow: 0.1754 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4053 - f1_perRow: 0.1737 - f1_perClass: 9.7714e-04 - acc: 0.9960\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4050 - f1_perRow: 0.1781 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4002 - f1_perRow: 0.1936 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4022 - f1_perRow: 0.1757 - f1_perClass: 9.9376e-04 - acc: 0.9961\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4052 - f1_perRow: 0.1883 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4043 - f1_perRow: 0.1658 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4044 - f1_perRow: 0.1843 - f1_perClass: 9.4914e-04 - acc: 0.9960\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4045 - f1_perRow: 0.1796 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4035 - f1_perRow: 0.1814 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4010 - f1_perRow: 0.1785 - f1_perClass: 9.8106e-04 - acc: 0.9960\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4010 - f1_perRow: 0.1885 - f1_perClass: 9.9541e-04 - acc: 0.9960\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4052 - f1_perRow: 0.1811 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4040 - f1_perRow: 0.1840 - f1_perClass: 9.9617e-04 - acc: 0.9960\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4065 - f1_perRow: 0.1536 - f1_perClass: 9.1640e-04 - acc: 0.9960\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4088 - f1_perRow: 0.1910 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4053 - f1_perRow: 0.1726 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4047 - f1_perRow: 0.1683 - f1_perClass: 9.3166e-04 - acc: 0.9960\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4062 - f1_perRow: 0.1763 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4051 - f1_perRow: 0.1904 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4040 - f1_perRow: 0.1671 - f1_perClass: 9.9027e-04 - acc: 0.9960\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4057 - f1_perRow: 0.1843 - f1_perClass: 9.6309e-04 - acc: 0.9960\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4067 - f1_perRow: 0.1646 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4050 - f1_perRow: 0.1977 - f1_perClass: 9.9200e-04 - acc: 0.9960\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4098 - f1_perRow: 0.1735 - f1_perClass: 0.0011 - acc: 0.9958\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4155 - f1_perRow: 0.1962 - f1_perClass: 9.5694e-04 - acc: 0.9960\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4149 - f1_perRow: 0.1760 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4138 - f1_perRow: 0.1788 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4055 - f1_perRow: 0.1937 - f1_perClass: 9.8635e-04 - acc: 0.9960\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4034 - f1_perRow: 0.1731 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4030 - f1_perRow: 0.1832 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4039 - f1_perRow: 0.1839 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4021 - f1_perRow: 0.1794 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4016 - f1_perRow: 0.1786 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4022 - f1_perRow: 0.1727 - f1_perClass: 9.9068e-04 - acc: 0.9960\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4041 - f1_perRow: 0.1959 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4019 - f1_perRow: 0.1848 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4077 - f1_perRow: 0.1854 - f1_perClass: 9.6080e-04 - acc: 0.9960\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4073 - f1_perRow: 0.1709 - f1_perClass: 9.8934e-04 - acc: 0.9960\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4035 - f1_perRow: 0.1805 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4022 - f1_perRow: 0.1924 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4001 - f1_perRow: 0.1733 - f1_perClass: 9.9084e-04 - acc: 0.9960\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4025 - f1_perRow: 0.1772 - f1_perClass: 9.9036e-04 - acc: 0.9960\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4046 - f1_perRow: 0.1843 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4041 - f1_perRow: 0.1819 - f1_perClass: 0.0010 - acc: 0.9961\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4065 - f1_perRow: 0.1993 - f1_perClass: 9.8266e-04 - acc: 0.9960\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4054 - f1_perRow: 0.1648 - f1_perClass: 0.0011 - acc: 0.9959\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4151 - f1_perRow: 0.1873 - f1_perClass: 9.4538e-04 - acc: 0.9960\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4035 - f1_perRow: 0.1733 - f1_perClass: 0.0010 - acc: 0.9960\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4099 - f1_perRow: 0.2126 - f1_perClass: 0.0010 - acc: 0.9959\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 76s 1ms/step - loss: 4.3950 - f1_perRow: 0.0012 - f1_perClass: 2.2063e-04 - acc: 0.8015\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 7.5737e-10 - f1_perClass: 1.0300e-12 - acc: 0.9988\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3788 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9988\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 75s 1ms/step - loss: 3.6377 - f1_perRow: 2.2325e-04 - f1_perClass: 3.1658e-05 - acc: 0.8750\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.0836 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9997\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 76s 1ms/step - loss: 5.1305 - f1_perRow: 0.0041 - f1_perClass: 0.0011 - acc: 0.7930\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.0498 - f1_perRow: 0.0095 - f1_perClass: 1.8944e-04 - acc: 0.9940\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7800 - f1_perRow: 0.0092 - f1_perClass: 1.1114e-04 - acc: 0.9940\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7156 - f1_perRow: 0.0150 - f1_perClass: 2.1852e-04 - acc: 0.9940\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6902 - f1_perRow: 0.0120 - f1_perClass: 1.3920e-04 - acc: 0.9940\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6618 - f1_perRow: 0.0157 - f1_perClass: 1.9264e-04 - acc: 0.9940\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6379 - f1_perRow: 0.0175 - f1_perClass: 1.9083e-04 - acc: 0.9940\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6037 - f1_perRow: 0.0279 - f1_perClass: 3.4138e-04 - acc: 0.9940\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5906 - f1_perRow: 0.0322 - f1_perClass: 3.7952e-04 - acc: 0.9940\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5470 - f1_perRow: 0.0430 - f1_perClass: 4.6401e-04 - acc: 0.9940\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5088 - f1_perRow: 0.0603 - f1_perClass: 5.9275e-04 - acc: 0.9940\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5091 - f1_perRow: 0.0715 - f1_perClass: 8.0462e-04 - acc: 0.9940\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5700 - f1_perRow: 0.0743 - f1_perClass: 9.2989e-04 - acc: 0.9940\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5222 - f1_perRow: 0.0554 - f1_perClass: 4.7369e-04 - acc: 0.9940\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.8665 - f1_perRow: 0.0245 - f1_perClass: 6.0409e-04 - acc: 0.9940\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5979 - f1_perRow: 0.0314 - f1_perClass: 4.3190e-04 - acc: 0.9940\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6062 - f1_perRow: 0.0325 - f1_perClass: 4.9257e-04 - acc: 0.9940\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5740 - f1_perRow: 0.0269 - f1_perClass: 2.4606e-04 - acc: 0.9940\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5364 - f1_perRow: 0.0460 - f1_perClass: 6.1718e-04 - acc: 0.9940\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5161 - f1_perRow: 0.0412 - f1_perClass: 3.5635e-04 - acc: 0.9940\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5049 - f1_perRow: 0.0661 - f1_perClass: 8.1788e-04 - acc: 0.9940\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4984 - f1_perRow: 0.0601 - f1_perClass: 5.4703e-04 - acc: 0.9940\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4693 - f1_perRow: 0.0930 - f1_perClass: 0.0011 - acc: 0.9940\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5068 - f1_perRow: 0.0805 - f1_perClass: 7.3219e-04 - acc: 0.9940\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4720 - f1_perRow: 0.1135 - f1_perClass: 0.0013 - acc: 0.9940\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4684 - f1_perRow: 0.0880 - f1_perClass: 6.8157e-04 - acc: 0.9940\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4367 - f1_perRow: 0.1340 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4079 - f1_perRow: 0.1506 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4517 - f1_perRow: 0.1278 - f1_perClass: 9.3012e-04 - acc: 0.9940\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6091 - f1_perRow: 0.1030 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6581 - f1_perRow: 0.0355 - f1_perClass: 2.5120e-04 - acc: 0.9940\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6111 - f1_perRow: 0.0941 - f1_perClass: 0.0018 - acc: 0.9940\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5847 - f1_perRow: 0.0328 - f1_perClass: 2.3642e-04 - acc: 0.9940\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5542 - f1_perRow: 0.0531 - f1_perClass: 6.9699e-04 - acc: 0.9940\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4618 - f1_perRow: 0.0962 - f1_perClass: 0.0012 - acc: 0.9940\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4434 - f1_perRow: 0.0934 - f1_perClass: 7.7193e-04 - acc: 0.9940\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4464 - f1_perRow: 0.1091 - f1_perClass: 0.0011 - acc: 0.9940\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4635 - f1_perRow: 0.1326 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4060 - f1_perRow: 0.1454 - f1_perClass: 0.0011 - acc: 0.9940\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4059 - f1_perRow: 0.1820 - f1_perClass: 0.0018 - acc: 0.9940\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4447 - f1_perRow: 0.1375 - f1_perClass: 0.0011 - acc: 0.9940\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3724 - f1_perRow: 0.2051 - f1_perClass: 0.0021 - acc: 0.9940\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3719 - f1_perRow: 0.1907 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3469 - f1_perRow: 0.2232 - f1_perClass: 0.0019 - acc: 0.9940\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4352 - f1_perRow: 0.1725 - f1_perClass: 0.0018 - acc: 0.9940\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5087 - f1_perRow: 0.1639 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4751 - f1_perRow: 0.1145 - f1_perClass: 7.1394e-04 - acc: 0.9940\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4347 - f1_perRow: 0.1504 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3943 - f1_perRow: 0.1610 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4487 - f1_perRow: 0.1200 - f1_perClass: 0.0011 - acc: 0.9940\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3763 - f1_perRow: 0.1834 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4899 - f1_perRow: 0.1265 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4885 - f1_perRow: 0.1261 - f1_perClass: 0.0012 - acc: 0.9940\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3776 - f1_perRow: 0.1750 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4047 - f1_perRow: 0.1606 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4191 - f1_perRow: 0.1570 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4411 - f1_perRow: 0.1639 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4338 - f1_perRow: 0.1515 - f1_perClass: 0.0013 - acc: 0.9940\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3644 - f1_perRow: 0.2018 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3742 - f1_perRow: 0.2005 - f1_perClass: 0.0021 - acc: 0.9940\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3576 - f1_perRow: 0.2215 - f1_perClass: 0.0018 - acc: 0.9940\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3621 - f1_perRow: 0.2368 - f1_perClass: 0.0022 - acc: 0.9940\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4405 - f1_perRow: 0.1672 - f1_perClass: 0.0011 - acc: 0.9940\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3875 - f1_perRow: 0.2226 - f1_perClass: 0.0022 - acc: 0.9940\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3640 - f1_perRow: 0.2209 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4440 - f1_perRow: 0.2249 - f1_perClass: 0.0022 - acc: 0.9940\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3909 - f1_perRow: 0.1920 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3862 - f1_perRow: 0.2022 - f1_perClass: 0.0018 - acc: 0.9940\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3996 - f1_perRow: 0.1813 - f1_perClass: 0.0015 - acc: 0.9940\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3530 - f1_perRow: 0.2139 - f1_perClass: 0.0018 - acc: 0.9940\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3869 - f1_perRow: 0.2180 - f1_perClass: 0.0024 - acc: 0.9940\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4390 - f1_perRow: 0.1551 - f1_perClass: 9.8521e-04 - acc: 0.9940\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3450 - f1_perRow: 0.2210 - f1_perClass: 0.0019 - acc: 0.9940\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5081 - f1_perRow: 0.1811 - f1_perClass: 0.0021 - acc: 0.9940\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4771 - f1_perRow: 0.1311 - f1_perClass: 7.9546e-04 - acc: 0.9940\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3974 - f1_perRow: 0.1892 - f1_perClass: 0.0020 - acc: 0.9940\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3737 - f1_perRow: 0.2267 - f1_perClass: 0.0021 - acc: 0.9940\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4398 - f1_perRow: 0.1773 - f1_perClass: 0.0014 - acc: 0.9940\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4400 - f1_perRow: 0.1682 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3615 - f1_perRow: 0.2107 - f1_perClass: 0.0017 - acc: 0.9940\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3629 - f1_perRow: 0.2190 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3209 - f1_perRow: 0.2534 - f1_perClass: 0.0020 - acc: 0.9940\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3825 - f1_perRow: 0.2329 - f1_perClass: 0.0027 - acc: 0.9940\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4745 - f1_perRow: 0.1466 - f1_perClass: 8.4564e-04 - acc: 0.9940\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4801 - f1_perRow: 0.1930 - f1_perClass: 0.0021 - acc: 0.9940\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4169 - f1_perRow: 0.1798 - f1_perClass: 0.0014 - acc: 0.9945\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3787 - f1_perRow: 0.1877 - f1_perClass: 0.0013 - acc: 0.9943\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3939 - f1_perRow: 0.2146 - f1_perClass: 0.0026 - acc: 0.9957\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3822 - f1_perRow: 0.2110 - f1_perClass: 0.0015 - acc: 0.9947\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3720 - f1_perRow: 0.2146 - f1_perClass: 0.0014 - acc: 0.9945\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3667 - f1_perRow: 0.2695 - f1_perClass: 0.0030 - acc: 0.9964\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3762 - f1_perRow: 0.2653 - f1_perClass: 0.0020 - acc: 0.9953\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3807 - f1_perRow: 0.2239 - f1_perClass: 0.0013 - acc: 0.9948\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3876 - f1_perRow: 0.2686 - f1_perClass: 0.0029 - acc: 0.9951\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3665 - f1_perRow: 0.2733 - f1_perClass: 0.0017 - acc: 0.9951\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3525 - f1_perRow: 0.2831 - f1_perClass: 0.0020 - acc: 0.9954\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4415 - f1_perRow: 0.2434 - f1_perClass: 0.0027 - acc: 0.9942\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4245 - f1_perRow: 0.2098 - f1_perClass: 0.0016 - acc: 0.9950\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3416 - f1_perRow: 0.2320 - f1_perClass: 0.0018 - acc: 0.9948\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3091 - f1_perRow: 0.3061 - f1_perClass: 0.0024 - acc: 0.9957\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3500 - f1_perRow: 0.3355 - f1_perClass: 0.0030 - acc: 0.9952\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5492 - f1_perRow: 0.1814 - f1_perClass: 0.0016 - acc: 0.9940\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5419 - f1_perRow: 0.1227 - f1_perClass: 7.9469e-04 - acc: 0.9943\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3862 - f1_perRow: 0.1902 - f1_perClass: 0.0021 - acc: 0.9945\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3592 - f1_perRow: 0.2313 - f1_perClass: 0.0021 - acc: 0.9946\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3424 - f1_perRow: 0.2699 - f1_perClass: 0.0018 - acc: 0.9946\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3476 - f1_perRow: 0.2861 - f1_perClass: 0.0026 - acc: 0.9954\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5346 - f1_perRow: 0.1992 - f1_perClass: 0.0018 - acc: 0.9950\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4168 - f1_perRow: 0.1951 - f1_perClass: 0.0012 - acc: 0.9945\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6546 - f1_perRow: 0.2239 - f1_perClass: 0.0030 - acc: 0.9886\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5685 - f1_perRow: 0.1268 - f1_perClass: 7.1914e-04 - acc: 0.9943\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4799 - f1_perRow: 0.0942 - f1_perClass: 7.8039e-04 - acc: 0.9942\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4729 - f1_perRow: 0.0996 - f1_perClass: 8.7494e-04 - acc: 0.9942\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4454 - f1_perRow: 0.1081 - f1_perClass: 0.0010 - acc: 0.9942\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4274 - f1_perRow: 0.1412 - f1_perClass: 0.0011 - acc: 0.9942\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3694 - f1_perRow: 0.1927 - f1_perClass: 0.0016 - acc: 0.9943\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4487 - f1_perRow: 0.1698 - f1_perClass: 0.0012 - acc: 0.9945\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3654 - f1_perRow: 0.2399 - f1_perClass: 0.0022 - acc: 0.9950\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5533 - f1_perRow: 0.1697 - f1_perClass: 0.0016 - acc: 0.9949\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4344 - f1_perRow: 0.1630 - f1_perClass: 0.0013 - acc: 0.9943\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3837 - f1_perRow: 0.1697 - f1_perClass: 0.0018 - acc: 0.9943\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4208 - f1_perRow: 0.1774 - f1_perClass: 0.0012 - acc: 0.9942\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3752 - f1_perRow: 0.2140 - f1_perClass: 0.0019 - acc: 0.9943\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3596 - f1_perRow: 0.2271 - f1_perClass: 0.0019 - acc: 0.9946\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3193 - f1_perRow: 0.2741 - f1_perClass: 0.0018 - acc: 0.9945\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3216 - f1_perRow: 0.2932 - f1_perClass: 0.0025 - acc: 0.9954\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2721 - f1_perRow: 0.4022 - f1_perClass: 0.0031 - acc: 0.9963\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3489 - f1_perRow: 0.4038 - f1_perClass: 0.0024 - acc: 0.9960\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3789 - f1_perRow: 0.3393 - f1_perClass: 0.0025 - acc: 0.9942\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3501 - f1_perRow: 0.2984 - f1_perClass: 0.0025 - acc: 0.9952\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3093 - f1_perRow: 0.3005 - f1_perClass: 0.0023 - acc: 0.9951\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4130 - f1_perRow: 0.2545 - f1_perClass: 0.0023 - acc: 0.9947\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3483 - f1_perRow: 0.2589 - f1_perClass: 0.0016 - acc: 0.9947\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3386 - f1_perRow: 0.2606 - f1_perClass: 0.0024 - acc: 0.9953\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3201 - f1_perRow: 0.3013 - f1_perClass: 0.0022 - acc: 0.9952\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3101 - f1_perRow: 0.3400 - f1_perClass: 0.0028 - acc: 0.9955\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4251 - f1_perRow: 0.2611 - f1_perClass: 0.0022 - acc: 0.9944\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4551 - f1_perRow: 0.2066 - f1_perClass: 0.0010 - acc: 0.9945\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4183 - f1_perRow: 0.2376 - f1_perClass: 0.0028 - acc: 0.9954\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3368 - f1_perRow: 0.3177 - f1_perClass: 0.0020 - acc: 0.9950\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4728 - f1_perRow: 0.2440 - f1_perClass: 0.0019 - acc: 0.9953\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3669 - f1_perRow: 0.2810 - f1_perClass: 0.0019 - acc: 0.9951\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3288 - f1_perRow: 0.3219 - f1_perClass: 0.0027 - acc: 0.9959\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4288 - f1_perRow: 0.2872 - f1_perClass: 0.0022 - acc: 0.9952\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3304 - f1_perRow: 0.3232 - f1_perClass: 0.0021 - acc: 0.9954\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3962 - f1_perRow: 0.2947 - f1_perClass: 0.0025 - acc: 0.9944\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2978 - f1_perRow: 0.3304 - f1_perClass: 0.0023 - acc: 0.9953\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3311 - f1_perRow: 0.3321 - f1_perClass: 0.0026 - acc: 0.9952\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3117 - f1_perRow: 0.3666 - f1_perClass: 0.0026 - acc: 0.9959\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4034 - f1_perRow: 0.3587 - f1_perClass: 0.0032 - acc: 0.9937\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4143 - f1_perRow: 0.2431 - f1_perClass: 0.0014 - acc: 0.9947\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3986 - f1_perRow: 0.2077 - f1_perClass: 0.0021 - acc: 0.9953\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3614 - f1_perRow: 0.2599 - f1_perClass: 0.0021 - acc: 0.9951\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3167 - f1_perRow: 0.3109 - f1_perClass: 0.0022 - acc: 0.9952\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3072 - f1_perRow: 0.3376 - f1_perClass: 0.0027 - acc: 0.9958\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3074 - f1_perRow: 0.3385 - f1_perClass: 0.0026 - acc: 0.9959\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2508 - f1_perRow: 0.4366 - f1_perClass: 0.0030 - acc: 0.9962\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3296 - f1_perRow: 0.3809 - f1_perClass: 0.0036 - acc: 0.9957\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4112 - f1_perRow: 0.3367 - f1_perClass: 0.0019 - acc: 0.9953\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3734 - f1_perRow: 0.3140 - f1_perClass: 0.0024 - acc: 0.9953\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2882 - f1_perRow: 0.3819 - f1_perClass: 0.0029 - acc: 0.9960\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3039 - f1_perRow: 0.3654 - f1_perClass: 0.0024 - acc: 0.9956\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2803 - f1_perRow: 0.3966 - f1_perClass: 0.0030 - acc: 0.9960\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3684 - f1_perRow: 0.3265 - f1_perClass: 0.0031 - acc: 0.9954\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4383 - f1_perRow: 0.2370 - f1_perClass: 0.0013 - acc: 0.9947\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3851 - f1_perRow: 0.2449 - f1_perClass: 0.0018 - acc: 0.9949\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3214 - f1_perRow: 0.3475 - f1_perClass: 0.0031 - acc: 0.9962\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3440 - f1_perRow: 0.3826 - f1_perClass: 0.0029 - acc: 0.9953\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3345 - f1_perRow: 0.3835 - f1_perClass: 0.0025 - acc: 0.9955\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3628 - f1_perRow: 0.3514 - f1_perClass: 0.0026 - acc: 0.9947\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4022 - f1_perRow: 0.3053 - f1_perClass: 0.0021 - acc: 0.9953\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3771 - f1_perRow: 0.2374 - f1_perClass: 0.0015 - acc: 0.9947\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3760 - f1_perRow: 0.2375 - f1_perClass: 0.0021 - acc: 0.9950\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2943 - f1_perRow: 0.3177 - f1_perClass: 0.0022 - acc: 0.9949\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3569 - f1_perRow: 0.3407 - f1_perClass: 0.0030 - acc: 0.9951\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3168 - f1_perRow: 0.3478 - f1_perClass: 0.0020 - acc: 0.9950\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3028 - f1_perRow: 0.3455 - f1_perClass: 0.0022 - acc: 0.9952\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3140 - f1_perRow: 0.3503 - f1_perClass: 0.0033 - acc: 0.9963\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3026 - f1_perRow: 0.3970 - f1_perClass: 0.0028 - acc: 0.9961\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3136 - f1_perRow: 0.3834 - f1_perClass: 0.0025 - acc: 0.9956\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2669 - f1_perRow: 0.4627 - f1_perClass: 0.0032 - acc: 0.9962\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2448 - f1_perRow: 0.4942 - f1_perClass: 0.0037 - acc: 0.9968\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2660 - f1_perRow: 0.4849 - f1_perClass: 0.0032 - acc: 0.9965\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2520 - f1_perRow: 0.5203 - f1_perClass: 0.0032 - acc: 0.9964\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.7442 - f1_perRow: 0.4174 - f1_perClass: 0.0036 - acc: 0.9872\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.8128 - f1_perRow: 0.1025 - f1_perClass: 4.4367e-04 - acc: 0.9943\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5640 - f1_perRow: 0.0862 - f1_perClass: 9.1520e-04 - acc: 0.9943\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5082 - f1_perRow: 0.0962 - f1_perClass: 8.8508e-04 - acc: 0.9942\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4757 - f1_perRow: 0.1112 - f1_perClass: 7.5535e-04 - acc: 0.9942\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4893 - f1_perRow: 0.1259 - f1_perClass: 0.0013 - acc: 0.9943\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4097 - f1_perRow: 0.1557 - f1_perClass: 0.0014 - acc: 0.9942\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4257 - f1_perRow: 0.1503 - f1_perClass: 0.0013 - acc: 0.9942\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3943 - f1_perRow: 0.1755 - f1_perClass: 0.0015 - acc: 0.9942\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3771 - f1_perRow: 0.2107 - f1_perClass: 0.0015 - acc: 0.9943\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3386 - f1_perRow: 0.2342 - f1_perClass: 0.0021 - acc: 0.9943\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4043 - f1_perRow: 0.2258 - f1_perClass: 0.0017 - acc: 0.9943\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4407 - f1_perRow: 0.2132 - f1_perClass: 0.0017 - acc: 0.9942\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3424 - f1_perRow: 0.2227 - f1_perClass: 0.0020 - acc: 0.9943\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3592 - f1_perRow: 0.2539 - f1_perClass: 0.0023 - acc: 0.9942\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3849 - f1_perRow: 0.2590 - f1_perClass: 0.0015 - acc: 0.9943\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 76s 1ms/step - loss: 3.8451 - f1_perRow: 0.0231 - f1_perClass: 0.0023 - acc: 0.9606\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.9651 - f1_perRow: 0.1610 - f1_perClass: 0.0041 - acc: 0.9847\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7967 - f1_perRow: 0.2616 - f1_perClass: 0.0056 - acc: 0.9847\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6697 - f1_perRow: 0.3450 - f1_perClass: 0.0068 - acc: 0.9847\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5898 - f1_perRow: 0.4254 - f1_perClass: 0.0084 - acc: 0.9847\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5341 - f1_perRow: 0.4975 - f1_perClass: 0.0097 - acc: 0.9880\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5020 - f1_perRow: 0.5190 - f1_perClass: 0.0101 - acc: 0.9889\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4952 - f1_perRow: 0.5377 - f1_perClass: 0.0104 - acc: 0.9882\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4926 - f1_perRow: 0.5300 - f1_perClass: 0.0102 - acc: 0.9883\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4845 - f1_perRow: 0.5263 - f1_perClass: 0.0101 - acc: 0.9890\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4847 - f1_perRow: 0.5432 - f1_perClass: 0.0105 - acc: 0.9887\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4715 - f1_perRow: 0.5571 - f1_perClass: 0.0108 - acc: 0.9889\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4626 - f1_perRow: 0.5327 - f1_perClass: 0.0102 - acc: 0.9902\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4615 - f1_perRow: 0.5578 - f1_perClass: 0.0106 - acc: 0.9894\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4662 - f1_perRow: 0.5561 - f1_perClass: 0.0106 - acc: 0.9892\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4603 - f1_perRow: 0.5628 - f1_perClass: 0.0105 - acc: 0.9899\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4474 - f1_perRow: 0.5624 - f1_perClass: 0.0107 - acc: 0.9905\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4498 - f1_perRow: 0.5717 - f1_perClass: 0.0105 - acc: 0.9901\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4446 - f1_perRow: 0.5740 - f1_perClass: 0.0109 - acc: 0.9904\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4308 - f1_perRow: 0.5887 - f1_perClass: 0.0109 - acc: 0.9913\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4882 - f1_perRow: 0.5349 - f1_perClass: 0.0101 - acc: 0.9879\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4499 - f1_perRow: 0.5762 - f1_perClass: 0.0110 - acc: 0.9900\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4503 - f1_perRow: 0.5813 - f1_perClass: 0.0112 - acc: 0.9897\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4316 - f1_perRow: 0.5576 - f1_perClass: 0.0104 - acc: 0.9910\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4134 - f1_perRow: 0.5823 - f1_perClass: 0.0107 - acc: 0.9927\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4192 - f1_perRow: 0.6187 - f1_perClass: 0.0112 - acc: 0.9916\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4178 - f1_perRow: 0.6024 - f1_perClass: 0.0112 - acc: 0.9915\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4617 - f1_perRow: 0.5996 - f1_perClass: 0.0110 - acc: 0.9902\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4121 - f1_perRow: 0.5942 - f1_perClass: 0.0110 - acc: 0.9912\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4108 - f1_perRow: 0.6075 - f1_perClass: 0.0113 - acc: 0.9918\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4037 - f1_perRow: 0.6145 - f1_perClass: 0.0111 - acc: 0.9920\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3803 - f1_perRow: 0.6292 - f1_perClass: 0.0113 - acc: 0.9934\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3978 - f1_perRow: 0.6420 - f1_perClass: 0.0115 - acc: 0.9919\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3730 - f1_perRow: 0.6607 - f1_perClass: 0.0116 - acc: 0.9927\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4287 - f1_perRow: 0.5987 - f1_perClass: 0.0109 - acc: 0.9913\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3819 - f1_perRow: 0.6506 - f1_perClass: 0.0116 - acc: 0.9929\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3710 - f1_perRow: 0.6655 - f1_perClass: 0.0117 - acc: 0.9935\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3639 - f1_perRow: 0.6494 - f1_perClass: 0.0116 - acc: 0.9932\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3747 - f1_perRow: 0.6820 - f1_perClass: 0.0119 - acc: 0.9932\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3554 - f1_perRow: 0.6661 - f1_perClass: 0.0116 - acc: 0.9937\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3367 - f1_perRow: 0.6942 - f1_perClass: 0.0118 - acc: 0.9943\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3203 - f1_perRow: 0.7140 - f1_perClass: 0.0124 - acc: 0.9948\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4816 - f1_perRow: 0.6258 - f1_perClass: 0.0114 - acc: 0.9911\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4269 - f1_perRow: 0.5821 - f1_perClass: 0.0105 - acc: 0.9910\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3612 - f1_perRow: 0.6398 - f1_perClass: 0.0111 - acc: 0.9939\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3426 - f1_perRow: 0.6689 - f1_perClass: 0.0115 - acc: 0.9945\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3743 - f1_perRow: 0.6691 - f1_perClass: 0.0116 - acc: 0.9929\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3531 - f1_perRow: 0.6810 - f1_perClass: 0.0119 - acc: 0.9937\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3058 - f1_perRow: 0.7161 - f1_perClass: 0.0122 - acc: 0.9952\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2923 - f1_perRow: 0.7435 - f1_perClass: 0.0124 - acc: 0.9955\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3055 - f1_perRow: 0.7328 - f1_perClass: 0.0120 - acc: 0.9948\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3073 - f1_perRow: 0.7448 - f1_perClass: 0.0125 - acc: 0.9948\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3246 - f1_perRow: 0.7200 - f1_perClass: 0.0122 - acc: 0.9944\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2907 - f1_perRow: 0.7477 - f1_perClass: 0.0123 - acc: 0.9949\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2892 - f1_perRow: 0.7581 - f1_perClass: 0.0125 - acc: 0.9954\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2480 - f1_perRow: 0.7849 - f1_perClass: 0.0129 - acc: 0.9964\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3168 - f1_perRow: 0.7531 - f1_perClass: 0.0127 - acc: 0.9947\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2500 - f1_perRow: 0.7916 - f1_perClass: 0.0130 - acc: 0.9964\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2736 - f1_perRow: 0.7653 - f1_perClass: 0.0123 - acc: 0.9956\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3566 - f1_perRow: 0.7295 - f1_perClass: 0.0124 - acc: 0.9934\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2539 - f1_perRow: 0.7759 - f1_perClass: 0.0127 - acc: 0.9962\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2499 - f1_perRow: 0.7910 - f1_perClass: 0.0130 - acc: 0.9964\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2041 - f1_perRow: 0.8274 - f1_perClass: 0.0134 - acc: 0.9975\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2040 - f1_perRow: 0.8490 - f1_perClass: 0.0135 - acc: 0.9976\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1838 - f1_perRow: 0.8636 - f1_perClass: 0.0139 - acc: 0.9980\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2108 - f1_perRow: 0.8417 - f1_perClass: 0.0135 - acc: 0.9972\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1675 - f1_perRow: 0.8966 - f1_perClass: 0.0139 - acc: 0.9984\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1616 - f1_perRow: 0.8972 - f1_perClass: 0.0140 - acc: 0.9984\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1703 - f1_perRow: 0.8801 - f1_perClass: 0.0140 - acc: 0.9980\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1855 - f1_perRow: 0.8737 - f1_perClass: 0.0136 - acc: 0.9977\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1848 - f1_perRow: 0.8823 - f1_perClass: 0.0139 - acc: 0.9978\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6434 - f1_perRow: 0.6586 - f1_perClass: 0.0114 - acc: 0.9917\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6292 - f1_perRow: 0.4660 - f1_perClass: 0.0094 - acc: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4969 - f1_perRow: 0.5373 - f1_perClass: 0.0106 - acc: 0.9890\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3611 - f1_perRow: 0.6270 - f1_perClass: 0.0108 - acc: 0.9948\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3097 - f1_perRow: 0.7253 - f1_perClass: 0.0122 - acc: 0.9971\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2827 - f1_perRow: 0.7586 - f1_perClass: 0.0126 - acc: 0.9966\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2666 - f1_perRow: 0.7936 - f1_perClass: 0.0129 - acc: 0.9962\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2177 - f1_perRow: 0.8271 - f1_perClass: 0.0134 - acc: 0.9976\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2005 - f1_perRow: 0.8486 - f1_perClass: 0.0137 - acc: 0.9978\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2094 - f1_perRow: 0.8477 - f1_perClass: 0.0135 - acc: 0.9973\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2258 - f1_perRow: 0.8308 - f1_perClass: 0.0132 - acc: 0.9969\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1811 - f1_perRow: 0.8710 - f1_perClass: 0.0138 - acc: 0.9979\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.1723 - f1_perRow: 0.8831 - f1_perClass: 0.0139 - acc: 0.9982\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1698 - f1_perRow: 0.8849 - f1_perClass: 0.0138 - acc: 0.9980\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2230 - f1_perRow: 0.8424 - f1_perClass: 0.0135 - acc: 0.9970\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3309 - f1_perRow: 0.7863 - f1_perClass: 0.0130 - acc: 0.9945\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2879 - f1_perRow: 0.7783 - f1_perClass: 0.0127 - acc: 0.9952\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2331 - f1_perRow: 0.7988 - f1_perClass: 0.0130 - acc: 0.9967\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2061 - f1_perRow: 0.8467 - f1_perClass: 0.0131 - acc: 0.9973\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1667 - f1_perRow: 0.8697 - f1_perClass: 0.0137 - acc: 0.9983\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1647 - f1_perRow: 0.8936 - f1_perClass: 0.0140 - acc: 0.9984\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1648 - f1_perRow: 0.8927 - f1_perClass: 0.0141 - acc: 0.9983\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1501 - f1_perRow: 0.9065 - f1_perClass: 0.0142 - acc: 0.9987\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1436 - f1_perRow: 0.9115 - f1_perClass: 0.0142 - acc: 0.9986\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1373 - f1_perRow: 0.9175 - f1_perClass: 0.0142 - acc: 0.9988\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1377 - f1_perRow: 0.9152 - f1_perClass: 0.0143 - acc: 0.9987\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1423 - f1_perRow: 0.9133 - f1_perClass: 0.0142 - acc: 0.9987\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1446 - f1_perRow: 0.9117 - f1_perClass: 0.0142 - acc: 0.9984\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1603 - f1_perRow: 0.8957 - f1_perClass: 0.0140 - acc: 0.9983\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1852 - f1_perRow: 0.8809 - f1_perClass: 0.0138 - acc: 0.9977\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2757 - f1_perRow: 0.8356 - f1_perClass: 0.0134 - acc: 0.9961\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.7351 - f1_perRow: 0.5556 - f1_perClass: 0.0110 - acc: 0.9897\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3630 - f1_perRow: 0.5918 - f1_perClass: 0.0095 - acc: 0.9931\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3382 - f1_perRow: 0.6990 - f1_perClass: 0.0129 - acc: 0.9936\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2579 - f1_perRow: 0.7536 - f1_perClass: 0.0118 - acc: 0.9965\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2153 - f1_perRow: 0.8271 - f1_perClass: 0.0136 - acc: 0.9977\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1876 - f1_perRow: 0.8773 - f1_perClass: 0.0136 - acc: 0.9984\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1852 - f1_perRow: 0.8599 - f1_perClass: 0.0138 - acc: 0.9982\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1663 - f1_perRow: 0.9016 - f1_perClass: 0.0141 - acc: 0.9985\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1577 - f1_perRow: 0.8899 - f1_perClass: 0.0141 - acc: 0.9987\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1486 - f1_perRow: 0.9094 - f1_perClass: 0.0141 - acc: 0.9988\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1485 - f1_perRow: 0.9149 - f1_perClass: 0.0143 - acc: 0.9986\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1703 - f1_perRow: 0.8884 - f1_perClass: 0.0141 - acc: 0.9981\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1531 - f1_perRow: 0.8978 - f1_perClass: 0.0140 - acc: 0.9986\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1447 - f1_perRow: 0.9114 - f1_perClass: 0.0141 - acc: 0.9987\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1375 - f1_perRow: 0.9119 - f1_perClass: 0.0144 - acc: 0.9988\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1350 - f1_perRow: 0.9332 - f1_perClass: 0.0143 - acc: 0.9989\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1287 - f1_perRow: 0.9219 - f1_perClass: 0.0144 - acc: 0.9989\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1331 - f1_perRow: 0.9246 - f1_perClass: 0.0143 - acc: 0.9989\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1254 - f1_perRow: 0.9298 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1325 - f1_perRow: 0.9327 - f1_perClass: 0.0143 - acc: 0.9990\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1304 - f1_perRow: 0.9309 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1236 - f1_perRow: 0.9331 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1276 - f1_perRow: 0.9257 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1212 - f1_perRow: 0.9357 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1181 - f1_perRow: 0.9354 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1241 - f1_perRow: 0.9355 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1217 - f1_perRow: 0.9301 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1211 - f1_perRow: 0.9376 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1212 - f1_perRow: 0.9322 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1250 - f1_perRow: 0.9368 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1220 - f1_perRow: 0.9327 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1230 - f1_perRow: 0.9417 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1228 - f1_perRow: 0.9264 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1208 - f1_perRow: 0.9343 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1155 - f1_perRow: 0.9400 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1200 - f1_perRow: 0.9381 - f1_perClass: 0.0145 - acc: 0.9990\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1196 - f1_perRow: 0.9360 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1193 - f1_perRow: 0.9387 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1211 - f1_perRow: 0.9340 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1209 - f1_perRow: 0.9389 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1332 - f1_perRow: 0.9334 - f1_perClass: 0.0144 - acc: 0.9989\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1219 - f1_perRow: 0.9287 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1236 - f1_perRow: 0.9372 - f1_perClass: 0.0145 - acc: 0.9990\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1197 - f1_perRow: 0.9412 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1197 - f1_perRow: 0.9356 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1212 - f1_perRow: 0.9365 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1170 - f1_perRow: 0.9424 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1185 - f1_perRow: 0.9301 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1231 - f1_perRow: 0.9503 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1191 - f1_perRow: 0.9285 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1217 - f1_perRow: 0.9429 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1184 - f1_perRow: 0.9365 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1190 - f1_perRow: 0.9435 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1187 - f1_perRow: 0.9405 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1259 - f1_perRow: 0.9290 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1231 - f1_perRow: 0.9375 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1247 - f1_perRow: 0.9313 - f1_perClass: 0.0143 - acc: 0.9989\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1212 - f1_perRow: 0.9334 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1213 - f1_perRow: 0.9356 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1201 - f1_perRow: 0.9354 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1202 - f1_perRow: 0.9367 - f1_perClass: 0.0145 - acc: 0.9990\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1184 - f1_perRow: 0.9441 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1196 - f1_perRow: 0.9335 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1198 - f1_perRow: 0.9449 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1205 - f1_perRow: 0.9310 - f1_perClass: 0.0145 - acc: 0.9990\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1240 - f1_perRow: 0.9409 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1172 - f1_perRow: 0.9318 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1193 - f1_perRow: 0.9433 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1192 - f1_perRow: 0.9317 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1204 - f1_perRow: 0.9422 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1195 - f1_perRow: 0.9338 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1199 - f1_perRow: 0.9388 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1212 - f1_perRow: 0.9404 - f1_perClass: 0.0145 - acc: 0.9990\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1139 - f1_perRow: 0.9374 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1179 - f1_perRow: 0.9446 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1162 - f1_perRow: 0.9344 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1192 - f1_perRow: 0.9466 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1160 - f1_perRow: 0.9460 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1188 - f1_perRow: 0.9283 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1160 - f1_perRow: 0.9401 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1161 - f1_perRow: 0.9412 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1154 - f1_perRow: 0.9447 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1178 - f1_perRow: 0.9379 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1177 - f1_perRow: 0.9438 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1170 - f1_perRow: 0.9381 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1157 - f1_perRow: 0.9379 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1168 - f1_perRow: 0.9430 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1207 - f1_perRow: 0.9306 - f1_perClass: 0.0144 - acc: 0.9990\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1229 - f1_perRow: 0.9458 - f1_perClass: 0.0144 - acc: 0.9991\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1180 - f1_perRow: 0.9349 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1161 - f1_perRow: 0.9366 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1150 - f1_perRow: 0.9425 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1181 - f1_perRow: 0.9401 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1179 - f1_perRow: 0.9439 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1157 - f1_perRow: 0.9386 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.1170 - f1_perRow: 0.9412 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1158 - f1_perRow: 0.9393 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1154 - f1_perRow: 0.9475 - f1_perClass: 0.0145 - acc: 0.9991\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 77s 1ms/step - loss: 8.2454 - f1_perRow: 0.0113 - f1_perClass: 0.0030 - acc: 0.7763\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2434 - f1_perRow: 0.1029 - f1_perClass: 0.0015 - acc: 0.9877\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.9865 - f1_perRow: 0.1824 - f1_perClass: 0.0034 - acc: 0.9877\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.9305 - f1_perRow: 0.2628 - f1_perClass: 0.0037 - acc: 0.9877\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.8340 - f1_perRow: 0.2541 - f1_perClass: 0.0046 - acc: 0.9877\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7353 - f1_perRow: 0.3239 - f1_perClass: 0.0046 - acc: 0.9889\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6855 - f1_perRow: 0.3627 - f1_perClass: 0.0057 - acc: 0.9932\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6403 - f1_perRow: 0.4753 - f1_perClass: 0.0063 - acc: 0.9932\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6158 - f1_perRow: 0.4966 - f1_perClass: 0.0070 - acc: 0.9932\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5999 - f1_perRow: 0.5449 - f1_perClass: 0.0069 - acc: 0.9938\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5920 - f1_perRow: 0.5205 - f1_perClass: 0.0072 - acc: 0.9936\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5852 - f1_perRow: 0.5489 - f1_perClass: 0.0071 - acc: 0.9937\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5805 - f1_perRow: 0.5336 - f1_perClass: 0.0071 - acc: 0.9937\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5744 - f1_perRow: 0.5418 - f1_perClass: 0.0071 - acc: 0.9939\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5705 - f1_perRow: 0.5529 - f1_perClass: 0.0073 - acc: 0.9939\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5708 - f1_perRow: 0.5466 - f1_perClass: 0.0073 - acc: 0.9939\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5619 - f1_perRow: 0.5621 - f1_perClass: 0.0073 - acc: 0.9940\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5620 - f1_perRow: 0.5503 - f1_perClass: 0.0073 - acc: 0.9941\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5595 - f1_perRow: 0.5701 - f1_perClass: 0.0075 - acc: 0.9942\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5544 - f1_perRow: 0.5604 - f1_perClass: 0.0074 - acc: 0.9941\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5528 - f1_perRow: 0.5825 - f1_perClass: 0.0075 - acc: 0.9942\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5606 - f1_perRow: 0.5614 - f1_perClass: 0.0075 - acc: 0.9942\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5497 - f1_perRow: 0.5729 - f1_perClass: 0.0076 - acc: 0.9942\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5362 - f1_perRow: 0.5866 - f1_perClass: 0.0076 - acc: 0.9946\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5364 - f1_perRow: 0.6029 - f1_perClass: 0.0078 - acc: 0.9945\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5301 - f1_perRow: 0.6000 - f1_perClass: 0.0077 - acc: 0.9948\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5217 - f1_perRow: 0.5960 - f1_perClass: 0.0079 - acc: 0.9948\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5267 - f1_perRow: 0.5915 - f1_perClass: 0.0078 - acc: 0.9948\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5406 - f1_perRow: 0.5946 - f1_perClass: 0.0078 - acc: 0.9946\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5316 - f1_perRow: 0.6136 - f1_perClass: 0.0076 - acc: 0.9947\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5254 - f1_perRow: 0.5722 - f1_perClass: 0.0079 - acc: 0.9948\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5295 - f1_perRow: 0.6279 - f1_perClass: 0.0079 - acc: 0.9949\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5146 - f1_perRow: 0.5985 - f1_perClass: 0.0079 - acc: 0.9949\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5166 - f1_perRow: 0.6160 - f1_perClass: 0.0079 - acc: 0.9949\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5095 - f1_perRow: 0.6206 - f1_perClass: 0.0080 - acc: 0.9949\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5090 - f1_perRow: 0.6126 - f1_perClass: 0.0079 - acc: 0.9950\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5101 - f1_perRow: 0.6082 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5129 - f1_perRow: 0.6217 - f1_perClass: 0.0078 - acc: 0.9948\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5032 - f1_perRow: 0.6059 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5114 - f1_perRow: 0.6031 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5087 - f1_perRow: 0.6375 - f1_perClass: 0.0079 - acc: 0.9950\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5079 - f1_perRow: 0.6021 - f1_perClass: 0.0081 - acc: 0.9950\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5099 - f1_perRow: 0.6031 - f1_perClass: 0.0078 - acc: 0.9949\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5027 - f1_perRow: 0.6299 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5046 - f1_perRow: 0.6186 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5020 - f1_perRow: 0.6222 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4954 - f1_perRow: 0.6117 - f1_perClass: 0.0080 - acc: 0.9951\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4944 - f1_perRow: 0.6131 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4974 - f1_perRow: 0.6349 - f1_perClass: 0.0080 - acc: 0.9951\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4987 - f1_perRow: 0.6204 - f1_perClass: 0.0081 - acc: 0.9950\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4953 - f1_perRow: 0.6043 - f1_perClass: 0.0080 - acc: 0.9951\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4943 - f1_perRow: 0.6329 - f1_perClass: 0.0080 - acc: 0.9949\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4968 - f1_perRow: 0.6103 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4985 - f1_perRow: 0.6194 - f1_perClass: 0.0079 - acc: 0.9950\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5007 - f1_perRow: 0.6466 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4936 - f1_perRow: 0.5979 - f1_perClass: 0.0079 - acc: 0.9950\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5069 - f1_perRow: 0.6275 - f1_perClass: 0.0082 - acc: 0.9950\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4979 - f1_perRow: 0.6296 - f1_perClass: 0.0079 - acc: 0.9950\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4967 - f1_perRow: 0.6116 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4886 - f1_perRow: 0.6200 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4946 - f1_perRow: 0.6223 - f1_perClass: 0.0081 - acc: 0.9950\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4925 - f1_perRow: 0.6292 - f1_perClass: 0.0080 - acc: 0.9949\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4872 - f1_perRow: 0.6229 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4886 - f1_perRow: 0.6204 - f1_perClass: 0.0080 - acc: 0.9951\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4913 - f1_perRow: 0.6405 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4875 - f1_perRow: 0.6197 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4899 - f1_perRow: 0.6152 - f1_perClass: 0.0080 - acc: 0.9951\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5024 - f1_perRow: 0.6242 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5001 - f1_perRow: 0.6159 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5010 - f1_perRow: 0.6290 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5000 - f1_perRow: 0.6342 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4952 - f1_perRow: 0.6081 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5003 - f1_perRow: 0.6492 - f1_perClass: 0.0080 - acc: 0.9952\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4985 - f1_perRow: 0.6024 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5026 - f1_perRow: 0.6428 - f1_perClass: 0.0080 - acc: 0.9951\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4990 - f1_perRow: 0.6204 - f1_perClass: 0.0079 - acc: 0.9950\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4951 - f1_perRow: 0.6127 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4946 - f1_perRow: 0.6470 - f1_perClass: 0.0081 - acc: 0.9950\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4953 - f1_perRow: 0.6099 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4915 - f1_perRow: 0.6125 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4910 - f1_perRow: 0.6421 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4898 - f1_perRow: 0.6283 - f1_perClass: 0.0080 - acc: 0.9950\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4887 - f1_perRow: 0.6065 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4867 - f1_perRow: 0.6443 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4860 - f1_perRow: 0.6260 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4857 - f1_perRow: 0.6142 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4838 - f1_perRow: 0.6467 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4793 - f1_perRow: 0.6156 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4856 - f1_perRow: 0.6488 - f1_perClass: 0.0083 - acc: 0.9951\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4800 - f1_perRow: 0.6139 - f1_perClass: 0.0080 - acc: 0.9953\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4811 - f1_perRow: 0.6456 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4797 - f1_perRow: 0.6210 - f1_perClass: 0.0083 - acc: 0.9951\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4853 - f1_perRow: 0.6438 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4824 - f1_perRow: 0.6406 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4803 - f1_perRow: 0.6223 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4764 - f1_perRow: 0.6304 - f1_perClass: 0.0082 - acc: 0.9953\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4788 - f1_perRow: 0.6341 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4792 - f1_perRow: 0.6348 - f1_perClass: 0.0081 - acc: 0.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4816 - f1_perRow: 0.6273 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4816 - f1_perRow: 0.6281 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4773 - f1_perRow: 0.6343 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4838 - f1_perRow: 0.6324 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4723 - f1_perRow: 0.6292 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4781 - f1_perRow: 0.6374 - f1_perClass: 0.0083 - acc: 0.9951\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4789 - f1_perRow: 0.6356 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4800 - f1_perRow: 0.6411 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4844 - f1_perRow: 0.6437 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4872 - f1_perRow: 0.6029 - f1_perClass: 0.0081 - acc: 0.9953\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4971 - f1_perRow: 0.6414 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4887 - f1_perRow: 0.6484 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4870 - f1_perRow: 0.6113 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4804 - f1_perRow: 0.6518 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4811 - f1_perRow: 0.6171 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4805 - f1_perRow: 0.6444 - f1_perClass: 0.0081 - acc: 0.9950\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4829 - f1_perRow: 0.6283 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4812 - f1_perRow: 0.6464 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4846 - f1_perRow: 0.6169 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4785 - f1_perRow: 0.6434 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4786 - f1_perRow: 0.6259 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4796 - f1_perRow: 0.6349 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4741 - f1_perRow: 0.6407 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4736 - f1_perRow: 0.6361 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4737 - f1_perRow: 0.6272 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4774 - f1_perRow: 0.6467 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4719 - f1_perRow: 0.6350 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4731 - f1_perRow: 0.6414 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4745 - f1_perRow: 0.6330 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4752 - f1_perRow: 0.6224 - f1_perClass: 0.0081 - acc: 0.9953\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4751 - f1_perRow: 0.6404 - f1_perClass: 0.0082 - acc: 0.9953\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4739 - f1_perRow: 0.6401 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4797 - f1_perRow: 0.6281 - f1_perClass: 0.0083 - acc: 0.9951\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4742 - f1_perRow: 0.6250 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4786 - f1_perRow: 0.6449 - f1_perClass: 0.0084 - acc: 0.9952\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4721 - f1_perRow: 0.6306 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4732 - f1_perRow: 0.6332 - f1_perClass: 0.0081 - acc: 0.9953\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4801 - f1_perRow: 0.6340 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4758 - f1_perRow: 0.6459 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4735 - f1_perRow: 0.6225 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4706 - f1_perRow: 0.6550 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4822 - f1_perRow: 0.6218 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4812 - f1_perRow: 0.6283 - f1_perClass: 0.0080 - acc: 0.9952\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4779 - f1_perRow: 0.6450 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4749 - f1_perRow: 0.6313 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4771 - f1_perRow: 0.6226 - f1_perClass: 0.0080 - acc: 0.9952\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4833 - f1_perRow: 0.6294 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4831 - f1_perRow: 0.6385 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4776 - f1_perRow: 0.6307 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4771 - f1_perRow: 0.6201 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4782 - f1_perRow: 0.6459 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4740 - f1_perRow: 0.6350 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4720 - f1_perRow: 0.6381 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4708 - f1_perRow: 0.6302 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4765 - f1_perRow: 0.6597 - f1_perClass: 0.0082 - acc: 0.9953\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4730 - f1_perRow: 0.6246 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4743 - f1_perRow: 0.6501 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4725 - f1_perRow: 0.6235 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4721 - f1_perRow: 0.6341 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4729 - f1_perRow: 0.6452 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4712 - f1_perRow: 0.6462 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4754 - f1_perRow: 0.6157 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4749 - f1_perRow: 0.6435 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4753 - f1_perRow: 0.6382 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4679 - f1_perRow: 0.6273 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4719 - f1_perRow: 0.6483 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4754 - f1_perRow: 0.6278 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4711 - f1_perRow: 0.6317 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4758 - f1_perRow: 0.6387 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4709 - f1_perRow: 0.6371 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4724 - f1_perRow: 0.6344 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4690 - f1_perRow: 0.6395 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4691 - f1_perRow: 0.6180 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4706 - f1_perRow: 0.6627 - f1_perClass: 0.0083 - acc: 0.9953\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4828 - f1_perRow: 0.6177 - f1_perClass: 0.0081 - acc: 0.9951\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4692 - f1_perRow: 0.6296 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4719 - f1_perRow: 0.6500 - f1_perClass: 0.0083 - acc: 0.9953\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4669 - f1_perRow: 0.6336 - f1_perClass: 0.0082 - acc: 0.9953\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4687 - f1_perRow: 0.6482 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4692 - f1_perRow: 0.6256 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4706 - f1_perRow: 0.6449 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4772 - f1_perRow: 0.6352 - f1_perClass: 0.0083 - acc: 0.9953\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4738 - f1_perRow: 0.6268 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4727 - f1_perRow: 0.6526 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4688 - f1_perRow: 0.6324 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4682 - f1_perRow: 0.6363 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4676 - f1_perRow: 0.6399 - f1_perClass: 0.0083 - acc: 0.9953\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4715 - f1_perRow: 0.6329 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4683 - f1_perRow: 0.6499 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4686 - f1_perRow: 0.6333 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4693 - f1_perRow: 0.6406 - f1_perClass: 0.0082 - acc: 0.9951\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4684 - f1_perRow: 0.6381 - f1_perClass: 0.0083 - acc: 0.9951\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4679 - f1_perRow: 0.6479 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4694 - f1_perRow: 0.6336 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4761 - f1_perRow: 0.6237 - f1_perClass: 0.0082 - acc: 0.9953\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4702 - f1_perRow: 0.6528 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4689 - f1_perRow: 0.6460 - f1_perClass: 0.0082 - acc: 0.9952\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4643 - f1_perRow: 0.6408 - f1_perClass: 0.0082 - acc: 0.9953\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4663 - f1_perRow: 0.6287 - f1_perClass: 0.0083 - acc: 0.9951\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4657 - f1_perRow: 0.6473 - f1_perClass: 0.0081 - acc: 0.9952\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4740 - f1_perRow: 0.6416 - f1_perClass: 0.0083 - acc: 0.9952\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4667 - f1_perRow: 0.6289 - f1_perClass: 0.0083 - acc: 0.9953\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 79s 1ms/step - loss: 5.8268 - f1_perRow: 0.0809 - f1_perClass: 0.0116 - acc: 0.9437\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.9890 - f1_perRow: 0.1830 - f1_perClass: 0.0147 - acc: 0.9476\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.7598 - f1_perRow: 0.2286 - f1_perClass: 0.0183 - acc: 0.9476\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5861 - f1_perRow: 0.2723 - f1_perClass: 0.0199 - acc: 0.9476\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.4668 - f1_perRow: 0.2921 - f1_perClass: 0.0208 - acc: 0.9476\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.3236 - f1_perRow: 0.3535 - f1_perClass: 0.0243 - acc: 0.9597\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.1883 - f1_perRow: 0.4094 - f1_perClass: 0.0269 - acc: 0.9660\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.0911 - f1_perRow: 0.4822 - f1_perClass: 0.0292 - acc: 0.9680\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9828 - f1_perRow: 0.5161 - f1_perClass: 0.0304 - acc: 0.9687\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9374 - f1_perRow: 0.5202 - f1_perClass: 0.0308 - acc: 0.9693\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.0438 - f1_perRow: 0.5180 - f1_perClass: 0.0305 - acc: 0.9688\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.9944 - f1_perRow: 0.5112 - f1_perClass: 0.0312 - acc: 0.9703\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.9413 - f1_perRow: 0.5534 - f1_perClass: 0.0306 - acc: 0.9704\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9015 - f1_perRow: 0.5166 - f1_perClass: 0.0310 - acc: 0.9703\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9029 - f1_perRow: 0.5340 - f1_perClass: 0.0314 - acc: 0.9700\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8728 - f1_perRow: 0.5477 - f1_perClass: 0.0319 - acc: 0.9702\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8373 - f1_perRow: 0.5330 - f1_perClass: 0.0318 - acc: 0.9713\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8095 - f1_perRow: 0.5531 - f1_perClass: 0.0316 - acc: 0.9716\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8407 - f1_perRow: 0.5489 - f1_perClass: 0.0321 - acc: 0.9718\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7850 - f1_perRow: 0.5489 - f1_perClass: 0.0326 - acc: 0.9723\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8323 - f1_perRow: 0.5619 - f1_perClass: 0.0322 - acc: 0.9721\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8122 - f1_perRow: 0.5853 - f1_perClass: 0.0316 - acc: 0.9722\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7925 - f1_perRow: 0.5398 - f1_perClass: 0.0333 - acc: 0.9731\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.7834 - f1_perRow: 0.5657 - f1_perClass: 0.0328 - acc: 0.9741\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7532 - f1_perRow: 0.5757 - f1_perClass: 0.0330 - acc: 0.9726\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8165 - f1_perRow: 0.5458 - f1_perClass: 0.0314 - acc: 0.9702\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7835 - f1_perRow: 0.5382 - f1_perClass: 0.0312 - acc: 0.9716\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.9025 - f1_perRow: 0.5747 - f1_perClass: 0.0322 - acc: 0.9715\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7593 - f1_perRow: 0.5431 - f1_perClass: 0.0318 - acc: 0.9721\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7460 - f1_perRow: 0.5698 - f1_perClass: 0.0340 - acc: 0.9728\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6772 - f1_perRow: 0.5748 - f1_perClass: 0.0333 - acc: 0.9737\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.6592 - f1_perRow: 0.5610 - f1_perClass: 0.0334 - acc: 0.9739\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.9521 - f1_perRow: 0.5763 - f1_perClass: 0.0336 - acc: 0.9719\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.0142 - f1_perRow: 0.5727 - f1_perClass: 0.0307 - acc: 0.9717\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8737 - f1_perRow: 0.5203 - f1_perClass: 0.0321 - acc: 0.9720\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8219 - f1_perRow: 0.5635 - f1_perClass: 0.0319 - acc: 0.9720\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7766 - f1_perRow: 0.5479 - f1_perClass: 0.0317 - acc: 0.9728\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7343 - f1_perRow: 0.5684 - f1_perClass: 0.0331 - acc: 0.9741\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.6807 - f1_perRow: 0.5791 - f1_perClass: 0.0333 - acc: 0.9738\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.6654 - f1_perRow: 0.5775 - f1_perClass: 0.0334 - acc: 0.9740\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8533 - f1_perRow: 0.5596 - f1_perClass: 0.0334 - acc: 0.9722\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8577 - f1_perRow: 0.6134 - f1_perClass: 0.0322 - acc: 0.9730\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7177 - f1_perRow: 0.5465 - f1_perClass: 0.0343 - acc: 0.9757\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6590 - f1_perRow: 0.6047 - f1_perClass: 0.0333 - acc: 0.9754\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6360 - f1_perRow: 0.5962 - f1_perClass: 0.0336 - acc: 0.9751\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.5780 - f1_perRow: 0.5969 - f1_perClass: 0.0347 - acc: 0.9756\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.6130 - f1_perRow: 0.5914 - f1_perClass: 0.0351 - acc: 0.9756\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.6686 - f1_perRow: 0.6513 - f1_perClass: 0.0336 - acc: 0.9764\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.6517 - f1_perRow: 0.6028 - f1_perClass: 0.0350 - acc: 0.9756\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.5788 - f1_perRow: 0.6002 - f1_perClass: 0.0342 - acc: 0.9746\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.6667 - f1_perRow: 0.6047 - f1_perClass: 0.0341 - acc: 0.9739\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.5722 - f1_perRow: 0.6030 - f1_perClass: 0.0346 - acc: 0.9765\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.6963 - f1_perRow: 0.5955 - f1_perClass: 0.0347 - acc: 0.9768\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.6016 - f1_perRow: 0.5913 - f1_perClass: 0.0353 - acc: 0.9775\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7052 - f1_perRow: 0.6219 - f1_perClass: 0.0328 - acc: 0.9741\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7749 - f1_perRow: 0.5412 - f1_perClass: 0.0336 - acc: 0.9703\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.6795 - f1_perRow: 0.5986 - f1_perClass: 0.0333 - acc: 0.9730\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.6511 - f1_perRow: 0.5834 - f1_perClass: 0.0324 - acc: 0.9733\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6290 - f1_perRow: 0.5623 - f1_perClass: 0.0357 - acc: 0.9759\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6331 - f1_perRow: 0.6349 - f1_perClass: 0.0319 - acc: 0.9757\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7842 - f1_perRow: 0.5652 - f1_perClass: 0.0348 - acc: 0.9730\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6594 - f1_perRow: 0.6090 - f1_perClass: 0.0351 - acc: 0.9748\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6150 - f1_perRow: 0.5998 - f1_perClass: 0.0325 - acc: 0.9749\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.5866 - f1_perRow: 0.5878 - f1_perClass: 0.0351 - acc: 0.9759\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.5683 - f1_perRow: 0.6110 - f1_perClass: 0.0347 - acc: 0.9760\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.5506 - f1_perRow: 0.6138 - f1_perClass: 0.0351 - acc: 0.9771\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.6658 - f1_perRow: 0.6498 - f1_perClass: 0.0343 - acc: 0.9779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7735 - f1_perRow: 0.5710 - f1_perClass: 0.0364 - acc: 0.9757\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.5632 - f1_perRow: 0.6529 - f1_perClass: 0.0334 - acc: 0.9767\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.5219 - f1_perRow: 0.6226 - f1_perClass: 0.0338 - acc: 0.9772\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.5792 - f1_perRow: 0.6008 - f1_perClass: 0.0346 - acc: 0.9764\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.5652 - f1_perRow: 0.6211 - f1_perClass: 0.0346 - acc: 0.9752\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.4617 - f1_perRow: 0.6271 - f1_perClass: 0.0357 - acc: 0.9781\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.4387 - f1_perRow: 0.6356 - f1_perClass: 0.0356 - acc: 0.9774\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.4365 - f1_perRow: 0.6351 - f1_perClass: 0.0365 - acc: 0.9791\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4266 - f1_perRow: 0.6845 - f1_perClass: 0.0356 - acc: 0.9791\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.5943 - f1_perRow: 0.6003 - f1_perClass: 0.0378 - acc: 0.9790\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.5327 - f1_perRow: 0.6970 - f1_perClass: 0.0344 - acc: 0.9794\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.4304 - f1_perRow: 0.6225 - f1_perClass: 0.0371 - acc: 0.9801\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.4715 - f1_perRow: 0.6637 - f1_perClass: 0.0353 - acc: 0.9782\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.4046 - f1_perRow: 0.6493 - f1_perClass: 0.0365 - acc: 0.9793\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3829 - f1_perRow: 0.6862 - f1_perClass: 0.0358 - acc: 0.9800\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3536 - f1_perRow: 0.6604 - f1_perClass: 0.0371 - acc: 0.9799\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.4184 - f1_perRow: 0.6689 - f1_perClass: 0.0371 - acc: 0.9799\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3935 - f1_perRow: 0.6481 - f1_perClass: 0.0377 - acc: 0.9794\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3617 - f1_perRow: 0.6872 - f1_perClass: 0.0366 - acc: 0.9800\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.4723 - f1_perRow: 0.6816 - f1_perClass: 0.0363 - acc: 0.9799\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.4401 - f1_perRow: 0.6268 - f1_perClass: 0.0383 - acc: 0.9804\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.6396 - f1_perRow: 0.6956 - f1_perClass: 0.0353 - acc: 0.9790\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.5094 - f1_perRow: 0.6169 - f1_perClass: 0.0372 - acc: 0.9791\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.4832 - f1_perRow: 0.6763 - f1_perClass: 0.0359 - acc: 0.9800\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.4045 - f1_perRow: 0.6744 - f1_perClass: 0.0365 - acc: 0.9809\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3942 - f1_perRow: 0.6475 - f1_perClass: 0.0370 - acc: 0.9801\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4246 - f1_perRow: 0.6893 - f1_perClass: 0.0356 - acc: 0.9796\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3638 - f1_perRow: 0.6587 - f1_perClass: 0.0368 - acc: 0.9798\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3486 - f1_perRow: 0.6740 - f1_perClass: 0.0370 - acc: 0.9807\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2993 - f1_perRow: 0.6826 - f1_perClass: 0.0369 - acc: 0.9804\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3059 - f1_perRow: 0.6621 - f1_perClass: 0.0384 - acc: 0.9809\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3924 - f1_perRow: 0.7270 - f1_perClass: 0.0363 - acc: 0.9809\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4104 - f1_perRow: 0.6351 - f1_perClass: 0.0396 - acc: 0.9808\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3776 - f1_perRow: 0.7053 - f1_perClass: 0.0368 - acc: 0.9811\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3088 - f1_perRow: 0.6829 - f1_perClass: 0.0377 - acc: 0.9814\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3456 - f1_perRow: 0.6839 - f1_perClass: 0.0369 - acc: 0.9806\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3983 - f1_perRow: 0.6851 - f1_perClass: 0.0369 - acc: 0.9805\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3132 - f1_perRow: 0.6693 - f1_perClass: 0.0374 - acc: 0.9805\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3989 - f1_perRow: 0.6751 - f1_perClass: 0.0360 - acc: 0.9791\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.4429 - f1_perRow: 0.6426 - f1_perClass: 0.0373 - acc: 0.9792\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4531 - f1_perRow: 0.7124 - f1_perClass: 0.0357 - acc: 0.9805\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.5039 - f1_perRow: 0.6131 - f1_perClass: 0.0382 - acc: 0.9802\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4296 - f1_perRow: 0.6909 - f1_perClass: 0.0357 - acc: 0.9790\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4692 - f1_perRow: 0.6501 - f1_perClass: 0.0355 - acc: 0.9777\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.4428 - f1_perRow: 0.6251 - f1_perClass: 0.0378 - acc: 0.9791\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.3771 - f1_perRow: 0.6942 - f1_perClass: 0.0365 - acc: 0.9802\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3596 - f1_perRow: 0.6586 - f1_perClass: 0.0370 - acc: 0.9798\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3595 - f1_perRow: 0.6805 - f1_perClass: 0.0365 - acc: 0.9803\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3525 - f1_perRow: 0.6571 - f1_perClass: 0.0382 - acc: 0.9807\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3509 - f1_perRow: 0.7188 - f1_perClass: 0.0362 - acc: 0.9808\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3424 - f1_perRow: 0.6688 - f1_perClass: 0.0381 - acc: 0.9812\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2590 - f1_perRow: 0.6823 - f1_perClass: 0.0379 - acc: 0.9817\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2576 - f1_perRow: 0.7328 - f1_perClass: 0.0367 - acc: 0.9817\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2488 - f1_perRow: 0.6846 - f1_perClass: 0.0383 - acc: 0.9818\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3500 - f1_perRow: 0.6816 - f1_perClass: 0.0382 - acc: 0.9816\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2666 - f1_perRow: 0.7053 - f1_perClass: 0.0376 - acc: 0.9814\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2580 - f1_perRow: 0.6615 - f1_perClass: 0.0392 - acc: 0.9816\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3373 - f1_perRow: 0.7131 - f1_perClass: 0.0372 - acc: 0.9814\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4045 - f1_perRow: 0.6736 - f1_perClass: 0.0374 - acc: 0.9802\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.3180 - f1_perRow: 0.7077 - f1_perClass: 0.0371 - acc: 0.9816\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2693 - f1_perRow: 0.6894 - f1_perClass: 0.0372 - acc: 0.9811\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.3148 - f1_perRow: 0.6567 - f1_perClass: 0.0388 - acc: 0.9815\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2831 - f1_perRow: 0.7240 - f1_perClass: 0.0370 - acc: 0.9814\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2344 - f1_perRow: 0.6752 - f1_perClass: 0.0387 - acc: 0.9818\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2339 - f1_perRow: 0.7014 - f1_perClass: 0.0380 - acc: 0.9818\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2288 - f1_perRow: 0.7208 - f1_perClass: 0.0376 - acc: 0.9818\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3492 - f1_perRow: 0.6624 - f1_perClass: 0.0398 - acc: 0.9813\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2213 - f1_perRow: 0.7340 - f1_perClass: 0.0371 - acc: 0.9817\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2228 - f1_perRow: 0.6735 - f1_perClass: 0.0389 - acc: 0.9817\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3296 - f1_perRow: 0.6792 - f1_perClass: 0.0384 - acc: 0.9817\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3284 - f1_perRow: 0.7312 - f1_perClass: 0.0369 - acc: 0.9817\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2471 - f1_perRow: 0.6795 - f1_perClass: 0.0386 - acc: 0.9818\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2275 - f1_perRow: 0.7103 - f1_perClass: 0.0378 - acc: 0.9818\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2461 - f1_perRow: 0.6998 - f1_perClass: 0.0381 - acc: 0.9816\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.1993 - f1_perRow: 0.6900 - f1_perClass: 0.0387 - acc: 0.9816\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2237 - f1_perRow: 0.7181 - f1_perClass: 0.0380 - acc: 0.9817\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3095 - f1_perRow: 0.6880 - f1_perClass: 0.0387 - acc: 0.9818\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2444 - f1_perRow: 0.6812 - f1_perClass: 0.0391 - acc: 0.9818\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2038 - f1_perRow: 0.7054 - f1_perClass: 0.0384 - acc: 0.9818\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.1902 - f1_perRow: 0.7174 - f1_perClass: 0.0379 - acc: 0.9817\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.1941 - f1_perRow: 0.6909 - f1_perClass: 0.0391 - acc: 0.9817\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2834 - f1_perRow: 0.7079 - f1_perClass: 0.0381 - acc: 0.9818\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3428 - f1_perRow: 0.6536 - f1_perClass: 0.0399 - acc: 0.9818\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3888 - f1_perRow: 0.7520 - f1_perClass: 0.0363 - acc: 0.9818\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.4297 - f1_perRow: 0.6290 - f1_perClass: 0.0395 - acc: 0.9818\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2765 - f1_perRow: 0.7062 - f1_perClass: 0.0374 - acc: 0.9817\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2937 - f1_perRow: 0.7279 - f1_perClass: 0.0365 - acc: 0.9816\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.3521 - f1_perRow: 0.6390 - f1_perClass: 0.0391 - acc: 0.9819\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2700 - f1_perRow: 0.7130 - f1_perClass: 0.0373 - acc: 0.9817\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.5772 - f1_perRow: 0.6730 - f1_perClass: 0.0355 - acc: 0.9772\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.5114 - f1_perRow: 0.5961 - f1_perClass: 0.0375 - acc: 0.9801\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3269 - f1_perRow: 0.6855 - f1_perClass: 0.0363 - acc: 0.9805\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3297 - f1_perRow: 0.6822 - f1_perClass: 0.0372 - acc: 0.9807\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3862 - f1_perRow: 0.6811 - f1_perClass: 0.0370 - acc: 0.9798\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2420 - f1_perRow: 0.6998 - f1_perClass: 0.0376 - acc: 0.9815\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.3060 - f1_perRow: 0.6639 - f1_perClass: 0.0390 - acc: 0.9814\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2895 - f1_perRow: 0.7093 - f1_perClass: 0.0372 - acc: 0.9813\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2515 - f1_perRow: 0.7063 - f1_perClass: 0.0382 - acc: 0.9818\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.1768 - f1_perRow: 0.6947 - f1_perClass: 0.0388 - acc: 0.9818\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2246 - f1_perRow: 0.7002 - f1_perClass: 0.0389 - acc: 0.9820\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.1727 - f1_perRow: 0.7172 - f1_perClass: 0.0385 - acc: 0.9819\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2307 - f1_perRow: 0.6832 - f1_perClass: 0.0399 - acc: 0.9811\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3221 - f1_perRow: 0.6980 - f1_perClass: 0.0383 - acc: 0.9818\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.1937 - f1_perRow: 0.7237 - f1_perClass: 0.0376 - acc: 0.9819\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2658 - f1_perRow: 0.6836 - f1_perClass: 0.0386 - acc: 0.9819\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2121 - f1_perRow: 0.7109 - f1_perClass: 0.0379 - acc: 0.9819\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2195 - f1_perRow: 0.7170 - f1_perClass: 0.0377 - acc: 0.9819\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2540 - f1_perRow: 0.7149 - f1_perClass: 0.0378 - acc: 0.9819\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2939 - f1_perRow: 0.6767 - f1_perClass: 0.0388 - acc: 0.9819\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3060 - f1_perRow: 0.7009 - f1_perClass: 0.0381 - acc: 0.9818\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.3630 - f1_perRow: 0.6707 - f1_perClass: 0.0385 - acc: 0.9816\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2629 - f1_perRow: 0.6964 - f1_perClass: 0.0378 - acc: 0.9818\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2079 - f1_perRow: 0.7124 - f1_perClass: 0.0376 - acc: 0.9819\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2838 - f1_perRow: 0.6982 - f1_perClass: 0.0380 - acc: 0.9818\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.3328 - f1_perRow: 0.6770 - f1_perClass: 0.0387 - acc: 0.9818\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3194 - f1_perRow: 0.6960 - f1_perClass: 0.0382 - acc: 0.9818\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2042 - f1_perRow: 0.7055 - f1_perClass: 0.0378 - acc: 0.9818\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2732 - f1_perRow: 0.6769 - f1_perClass: 0.0387 - acc: 0.9819\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2466 - f1_perRow: 0.7283 - f1_perClass: 0.0372 - acc: 0.9818\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3155 - f1_perRow: 0.6745 - f1_perClass: 0.0392 - acc: 0.9817\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2178 - f1_perRow: 0.6990 - f1_perClass: 0.0383 - acc: 0.9819\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2115 - f1_perRow: 0.7325 - f1_perClass: 0.0373 - acc: 0.9819\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.3072 - f1_perRow: 0.6703 - f1_perClass: 0.0387 - acc: 0.9818\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.2608 - f1_perRow: 0.7076 - f1_perClass: 0.0376 - acc: 0.9812\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.3866 - f1_perRow: 0.6783 - f1_perClass: 0.0363 - acc: 0.9785\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.3260 - f1_perRow: 0.6460 - f1_perClass: 0.0383 - acc: 0.9805\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2405 - f1_perRow: 0.6954 - f1_perClass: 0.0385 - acc: 0.9816\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.2610 - f1_perRow: 0.7058 - f1_perClass: 0.0382 - acc: 0.9816\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.2006 - f1_perRow: 0.7013 - f1_perClass: 0.0388 - acc: 0.9818\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.2120 - f1_perRow: 0.7126 - f1_perClass: 0.0383 - acc: 0.9816\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.1514 - f1_perRow: 0.7019 - f1_perClass: 0.0393 - acc: 0.9819\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.1931 - f1_perRow: 0.7006 - f1_perClass: 0.0397 - acc: 0.9818\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.2186 - f1_perRow: 0.7380 - f1_perClass: 0.0375 - acc: 0.9818\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 79s 1ms/step - loss: 5.2350 - f1_perRow: 0.0192 - f1_perClass: 0.0038 - acc: 0.8407\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.6858 - f1_perRow: 0.0539 - f1_perClass: 0.0024 - acc: 0.9812\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.4326 - f1_perRow: 0.0812 - f1_perClass: 0.0024 - acc: 0.9812\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.2249 - f1_perRow: 0.2003 - f1_perClass: 0.0053 - acc: 0.9812\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.1216 - f1_perRow: 0.2370 - f1_perClass: 0.0064 - acc: 0.9812\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.0636 - f1_perRow: 0.2511 - f1_perClass: 0.0066 - acc: 0.9812\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.9862 - f1_perRow: 0.2739 - f1_perClass: 0.0069 - acc: 0.9812\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.9171 - f1_perRow: 0.2794 - f1_perClass: 0.0072 - acc: 0.9812\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.8504 - f1_perRow: 0.3059 - f1_perClass: 0.0074 - acc: 0.9812\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7923 - f1_perRow: 0.3414 - f1_perClass: 0.0079 - acc: 0.9812\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7647 - f1_perRow: 0.3620 - f1_perClass: 0.0088 - acc: 0.9812\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7376 - f1_perRow: 0.3851 - f1_perClass: 0.0089 - acc: 0.9812\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7108 - f1_perRow: 0.3940 - f1_perClass: 0.0094 - acc: 0.9812\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6911 - f1_perRow: 0.4156 - f1_perClass: 0.0092 - acc: 0.9812\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6717 - f1_perRow: 0.4214 - f1_perClass: 0.0098 - acc: 0.9812\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6549 - f1_perRow: 0.4333 - f1_perClass: 0.0099 - acc: 0.9866\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6498 - f1_perRow: 0.4498 - f1_perClass: 0.0099 - acc: 0.9892\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6381 - f1_perRow: 0.4524 - f1_perClass: 0.0103 - acc: 0.9899\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6309 - f1_perRow: 0.4585 - f1_perClass: 0.0103 - acc: 0.9899\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6227 - f1_perRow: 0.4738 - f1_perClass: 0.0105 - acc: 0.9898\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6265 - f1_perRow: 0.4771 - f1_perClass: 0.0108 - acc: 0.9903\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6302 - f1_perRow: 0.4793 - f1_perClass: 0.0107 - acc: 0.9904\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6265 - f1_perRow: 0.4754 - f1_perClass: 0.0110 - acc: 0.9901\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6156 - f1_perRow: 0.5012 - f1_perClass: 0.0112 - acc: 0.9906\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5977 - f1_perRow: 0.5184 - f1_perClass: 0.0112 - acc: 0.9901\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5876 - f1_perRow: 0.5274 - f1_perClass: 0.0119 - acc: 0.9899\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5813 - f1_perRow: 0.5376 - f1_perClass: 0.0116 - acc: 0.9904\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5672 - f1_perRow: 0.5388 - f1_perClass: 0.0122 - acc: 0.9907\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5715 - f1_perRow: 0.5698 - f1_perClass: 0.0124 - acc: 0.9909\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5592 - f1_perRow: 0.5670 - f1_perClass: 0.0122 - acc: 0.9905\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5404 - f1_perRow: 0.5983 - f1_perClass: 0.0127 - acc: 0.9914\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5348 - f1_perRow: 0.6121 - f1_perClass: 0.0135 - acc: 0.9911\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.5348 - f1_perRow: 0.6051 - f1_perClass: 0.0128 - acc: 0.9913\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5266 - f1_perRow: 0.6269 - f1_perClass: 0.0129 - acc: 0.9914\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5257 - f1_perRow: 0.6263 - f1_perClass: 0.0136 - acc: 0.9912\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5289 - f1_perRow: 0.6284 - f1_perClass: 0.0135 - acc: 0.9913\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5374 - f1_perRow: 0.6196 - f1_perClass: 0.0125 - acc: 0.9914\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5295 - f1_perRow: 0.6419 - f1_perClass: 0.0138 - acc: 0.9910\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5167 - f1_perRow: 0.6294 - f1_perClass: 0.0130 - acc: 0.9910\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4898 - f1_perRow: 0.6523 - f1_perClass: 0.0139 - acc: 0.9919\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4844 - f1_perRow: 0.6535 - f1_perClass: 0.0135 - acc: 0.9917\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4781 - f1_perRow: 0.6601 - f1_perClass: 0.0137 - acc: 0.9921\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4754 - f1_perRow: 0.6677 - f1_perClass: 0.0138 - acc: 0.9921\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4721 - f1_perRow: 0.6657 - f1_perClass: 0.0138 - acc: 0.9918\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4830 - f1_perRow: 0.6622 - f1_perClass: 0.0136 - acc: 0.9918\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4679 - f1_perRow: 0.6705 - f1_perClass: 0.0139 - acc: 0.9918\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4715 - f1_perRow: 0.6824 - f1_perClass: 0.0137 - acc: 0.9919\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4847 - f1_perRow: 0.6806 - f1_perClass: 0.0140 - acc: 0.9913\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4766 - f1_perRow: 0.6622 - f1_perClass: 0.0133 - acc: 0.9917\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4613 - f1_perRow: 0.6709 - f1_perClass: 0.0139 - acc: 0.9919\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4651 - f1_perRow: 0.6722 - f1_perClass: 0.0138 - acc: 0.9919\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4728 - f1_perRow: 0.6765 - f1_perClass: 0.0141 - acc: 0.9915\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4499 - f1_perRow: 0.6603 - f1_perClass: 0.0137 - acc: 0.9919\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4480 - f1_perRow: 0.6751 - f1_perClass: 0.0139 - acc: 0.9919\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4652 - f1_perRow: 0.6915 - f1_perClass: 0.0140 - acc: 0.9922\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4597 - f1_perRow: 0.6733 - f1_perClass: 0.0141 - acc: 0.9917\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4526 - f1_perRow: 0.6776 - f1_perClass: 0.0139 - acc: 0.9920\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4495 - f1_perRow: 0.6813 - f1_perClass: 0.0141 - acc: 0.9922\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4323 - f1_perRow: 0.7047 - f1_perClass: 0.0141 - acc: 0.9923\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4199 - f1_perRow: 0.6910 - f1_perClass: 0.0143 - acc: 0.9922\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4292 - f1_perRow: 0.6920 - f1_perClass: 0.0140 - acc: 0.9922\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4353 - f1_perRow: 0.6976 - f1_perClass: 0.0141 - acc: 0.9923\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4621 - f1_perRow: 0.6821 - f1_perClass: 0.0140 - acc: 0.9922\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4352 - f1_perRow: 0.6916 - f1_perClass: 0.0142 - acc: 0.9918\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4452 - f1_perRow: 0.6867 - f1_perClass: 0.0144 - acc: 0.9918\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4364 - f1_perRow: 0.6927 - f1_perClass: 0.0139 - acc: 0.9922\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4355 - f1_perRow: 0.6908 - f1_perClass: 0.0141 - acc: 0.9926\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4271 - f1_perRow: 0.7103 - f1_perClass: 0.0140 - acc: 0.9926\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4236 - f1_perRow: 0.6969 - f1_perClass: 0.0144 - acc: 0.9924\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4130 - f1_perRow: 0.6966 - f1_perClass: 0.0143 - acc: 0.9927\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4146 - f1_perRow: 0.7098 - f1_perClass: 0.0143 - acc: 0.9927\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4116 - f1_perRow: 0.6986 - f1_perClass: 0.0143 - acc: 0.9928\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4024 - f1_perRow: 0.7115 - f1_perClass: 0.0144 - acc: 0.9930\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4190 - f1_perRow: 0.6994 - f1_perClass: 0.0141 - acc: 0.9929\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4133 - f1_perRow: 0.7123 - f1_perClass: 0.0145 - acc: 0.9933\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4132 - f1_perRow: 0.7142 - f1_perClass: 0.0144 - acc: 0.9929\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4073 - f1_perRow: 0.6992 - f1_perClass: 0.0142 - acc: 0.9931\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4188 - f1_perRow: 0.6919 - f1_perClass: 0.0144 - acc: 0.9927\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4092 - f1_perRow: 0.7226 - f1_perClass: 0.0141 - acc: 0.9933\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4178 - f1_perRow: 0.7089 - f1_perClass: 0.0146 - acc: 0.9930\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4268 - f1_perRow: 0.6988 - f1_perClass: 0.0141 - acc: 0.9929\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4069 - f1_perRow: 0.7104 - f1_perClass: 0.0144 - acc: 0.9929\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4079 - f1_perRow: 0.7051 - f1_perClass: 0.0143 - acc: 0.9929\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4033 - f1_perRow: 0.7086 - f1_perClass: 0.0144 - acc: 0.9931\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4068 - f1_perRow: 0.7056 - f1_perClass: 0.0144 - acc: 0.9936\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4061 - f1_perRow: 0.7293 - f1_perClass: 0.0143 - acc: 0.9933\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4229 - f1_perRow: 0.7015 - f1_perClass: 0.0143 - acc: 0.9931\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4312 - f1_perRow: 0.6968 - f1_perClass: 0.0145 - acc: 0.9924\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4297 - f1_perRow: 0.7048 - f1_perClass: 0.0142 - acc: 0.9927\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4263 - f1_perRow: 0.6976 - f1_perClass: 0.0144 - acc: 0.9923\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4081 - f1_perRow: 0.7061 - f1_perClass: 0.0140 - acc: 0.9929\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4133 - f1_perRow: 0.7107 - f1_perClass: 0.0143 - acc: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4044 - f1_perRow: 0.7166 - f1_perClass: 0.0143 - acc: 0.9932\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4125 - f1_perRow: 0.7090 - f1_perClass: 0.0144 - acc: 0.9928\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4025 - f1_perRow: 0.7130 - f1_perClass: 0.0148 - acc: 0.9930\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4018 - f1_perRow: 0.7084 - f1_perClass: 0.0142 - acc: 0.9930\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3967 - f1_perRow: 0.7121 - f1_perClass: 0.0144 - acc: 0.9932\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3925 - f1_perRow: 0.7319 - f1_perClass: 0.0146 - acc: 0.9933\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4446 - f1_perRow: 0.7136 - f1_perClass: 0.0142 - acc: 0.9933\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4070 - f1_perRow: 0.6998 - f1_perClass: 0.0144 - acc: 0.9933\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4041 - f1_perRow: 0.7162 - f1_perClass: 0.0143 - acc: 0.9931\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3825 - f1_perRow: 0.7223 - f1_perClass: 0.0146 - acc: 0.9940\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4073 - f1_perRow: 0.7158 - f1_perClass: 0.0146 - acc: 0.9931\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4106 - f1_perRow: 0.7264 - f1_perClass: 0.0142 - acc: 0.9932\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4370 - f1_perRow: 0.7038 - f1_perClass: 0.0141 - acc: 0.9926\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4154 - f1_perRow: 0.7156 - f1_perClass: 0.0148 - acc: 0.9925\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4148 - f1_perRow: 0.7032 - f1_perClass: 0.0139 - acc: 0.9929\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4044 - f1_perRow: 0.7065 - f1_perClass: 0.0144 - acc: 0.9929\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4009 - f1_perRow: 0.7229 - f1_perClass: 0.0146 - acc: 0.9937\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4293 - f1_perRow: 0.7172 - f1_perClass: 0.0143 - acc: 0.9931\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4125 - f1_perRow: 0.7008 - f1_perClass: 0.0143 - acc: 0.9929\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3992 - f1_perRow: 0.7094 - f1_perClass: 0.0147 - acc: 0.9929\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4000 - f1_perRow: 0.7310 - f1_perClass: 0.0140 - acc: 0.9930\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3919 - f1_perRow: 0.7232 - f1_perClass: 0.0147 - acc: 0.9933\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3798 - f1_perRow: 0.7121 - f1_perClass: 0.0145 - acc: 0.9937\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3817 - f1_perRow: 0.7368 - f1_perClass: 0.0146 - acc: 0.9938\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3799 - f1_perRow: 0.7303 - f1_perClass: 0.0144 - acc: 0.9939\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3870 - f1_perRow: 0.7316 - f1_perClass: 0.0148 - acc: 0.9937\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3784 - f1_perRow: 0.7204 - f1_perClass: 0.0149 - acc: 0.9939\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3730 - f1_perRow: 0.7526 - f1_perClass: 0.0144 - acc: 0.9941\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3697 - f1_perRow: 0.7349 - f1_perClass: 0.0149 - acc: 0.9943\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3665 - f1_perRow: 0.7357 - f1_perClass: 0.0148 - acc: 0.9942\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3714 - f1_perRow: 0.7471 - f1_perClass: 0.0147 - acc: 0.9943\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3662 - f1_perRow: 0.7414 - f1_perClass: 0.0147 - acc: 0.9942\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3678 - f1_perRow: 0.7388 - f1_perClass: 0.0149 - acc: 0.9941\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3640 - f1_perRow: 0.7411 - f1_perClass: 0.0147 - acc: 0.9942\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3733 - f1_perRow: 0.7347 - f1_perClass: 0.0148 - acc: 0.9940\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3812 - f1_perRow: 0.7399 - f1_perClass: 0.0148 - acc: 0.9940\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3672 - f1_perRow: 0.7541 - f1_perClass: 0.0148 - acc: 0.9942\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4058 - f1_perRow: 0.7424 - f1_perClass: 0.0147 - acc: 0.9934\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3735 - f1_perRow: 0.7281 - f1_perClass: 0.0147 - acc: 0.9939\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3748 - f1_perRow: 0.7386 - f1_perClass: 0.0147 - acc: 0.9938\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3807 - f1_perRow: 0.7244 - f1_perClass: 0.0147 - acc: 0.9941\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3826 - f1_perRow: 0.7287 - f1_perClass: 0.0150 - acc: 0.9936\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4087 - f1_perRow: 0.7374 - f1_perClass: 0.0142 - acc: 0.9933\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3907 - f1_perRow: 0.7287 - f1_perClass: 0.0146 - acc: 0.9936\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3927 - f1_perRow: 0.7218 - f1_perClass: 0.0144 - acc: 0.9934\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3745 - f1_perRow: 0.7282 - f1_perClass: 0.0149 - acc: 0.9938\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3603 - f1_perRow: 0.7372 - f1_perClass: 0.0146 - acc: 0.9942\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3592 - f1_perRow: 0.7470 - f1_perClass: 0.0149 - acc: 0.9943\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3673 - f1_perRow: 0.7593 - f1_perClass: 0.0148 - acc: 0.9943\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4109 - f1_perRow: 0.7435 - f1_perClass: 0.0147 - acc: 0.9940\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3767 - f1_perRow: 0.7238 - f1_perClass: 0.0149 - acc: 0.9944\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3709 - f1_perRow: 0.7518 - f1_perClass: 0.0146 - acc: 0.9942\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3762 - f1_perRow: 0.7434 - f1_perClass: 0.0148 - acc: 0.9941\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3627 - f1_perRow: 0.7323 - f1_perClass: 0.0148 - acc: 0.9946\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3535 - f1_perRow: 0.7628 - f1_perClass: 0.0149 - acc: 0.9943\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3623 - f1_perRow: 0.7458 - f1_perClass: 0.0150 - acc: 0.9945\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3640 - f1_perRow: 0.7396 - f1_perClass: 0.0150 - acc: 0.9941\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3742 - f1_perRow: 0.7470 - f1_perClass: 0.0151 - acc: 0.9939\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3521 - f1_perRow: 0.7615 - f1_perClass: 0.0147 - acc: 0.9946\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3673 - f1_perRow: 0.7438 - f1_perClass: 0.0151 - acc: 0.9942\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4073 - f1_perRow: 0.7181 - f1_perClass: 0.0145 - acc: 0.9933\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3964 - f1_perRow: 0.7601 - f1_perClass: 0.0146 - acc: 0.9936\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3756 - f1_perRow: 0.7229 - f1_perClass: 0.0152 - acc: 0.9939\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3847 - f1_perRow: 0.7559 - f1_perClass: 0.0144 - acc: 0.9937\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3722 - f1_perRow: 0.7219 - f1_perClass: 0.0147 - acc: 0.9941\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3602 - f1_perRow: 0.7502 - f1_perClass: 0.0148 - acc: 0.9946\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3492 - f1_perRow: 0.7552 - f1_perClass: 0.0150 - acc: 0.9947\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3557 - f1_perRow: 0.7482 - f1_perClass: 0.0151 - acc: 0.9946\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4268 - f1_perRow: 0.7376 - f1_perClass: 0.0144 - acc: 0.9936\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3864 - f1_perRow: 0.7397 - f1_perClass: 0.0150 - acc: 0.9939\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3719 - f1_perRow: 0.7364 - f1_perClass: 0.0148 - acc: 0.9944\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3704 - f1_perRow: 0.7477 - f1_perClass: 0.0144 - acc: 0.9942\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3634 - f1_perRow: 0.7420 - f1_perClass: 0.0151 - acc: 0.9942\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3609 - f1_perRow: 0.7648 - f1_perClass: 0.0146 - acc: 0.9945\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3611 - f1_perRow: 0.7429 - f1_perClass: 0.0153 - acc: 0.9945\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3476 - f1_perRow: 0.7739 - f1_perClass: 0.0148 - acc: 0.9947\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3532 - f1_perRow: 0.7439 - f1_perClass: 0.0151 - acc: 0.9946\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3507 - f1_perRow: 0.7563 - f1_perClass: 0.0148 - acc: 0.9943\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3591 - f1_perRow: 0.7599 - f1_perClass: 0.0151 - acc: 0.9943\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3609 - f1_perRow: 0.7403 - f1_perClass: 0.0151 - acc: 0.9947\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3533 - f1_perRow: 0.7743 - f1_perClass: 0.0150 - acc: 0.9944\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3568 - f1_perRow: 0.7460 - f1_perClass: 0.0149 - acc: 0.9945\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3447 - f1_perRow: 0.7568 - f1_perClass: 0.0150 - acc: 0.9945\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3635 - f1_perRow: 0.7464 - f1_perClass: 0.0151 - acc: 0.9941\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3597 - f1_perRow: 0.7615 - f1_perClass: 0.0152 - acc: 0.9943\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3565 - f1_perRow: 0.7597 - f1_perClass: 0.0148 - acc: 0.9943\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3485 - f1_perRow: 0.7456 - f1_perClass: 0.0150 - acc: 0.9945\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3459 - f1_perRow: 0.7608 - f1_perClass: 0.0151 - acc: 0.9945\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3711 - f1_perRow: 0.7501 - f1_perClass: 0.0149 - acc: 0.9944\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3703 - f1_perRow: 0.7863 - f1_perClass: 0.0148 - acc: 0.9947\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3696 - f1_perRow: 0.7267 - f1_perClass: 0.0149 - acc: 0.9946\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3848 - f1_perRow: 0.7550 - f1_perClass: 0.0146 - acc: 0.9941\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3698 - f1_perRow: 0.7470 - f1_perClass: 0.0150 - acc: 0.9942\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3644 - f1_perRow: 0.7379 - f1_perClass: 0.0147 - acc: 0.9945\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3596 - f1_perRow: 0.7541 - f1_perClass: 0.0149 - acc: 0.9946\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3503 - f1_perRow: 0.7511 - f1_perClass: 0.0150 - acc: 0.9947\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3474 - f1_perRow: 0.7572 - f1_perClass: 0.0154 - acc: 0.9947\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3512 - f1_perRow: 0.7635 - f1_perClass: 0.0146 - acc: 0.9947\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3451 - f1_perRow: 0.7737 - f1_perClass: 0.0154 - acc: 0.9949\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3927 - f1_perRow: 0.7618 - f1_perClass: 0.0148 - acc: 0.9949\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3721 - f1_perRow: 0.7352 - f1_perClass: 0.0152 - acc: 0.9949\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3779 - f1_perRow: 0.7746 - f1_perClass: 0.0146 - acc: 0.9941\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3837 - f1_perRow: 0.7241 - f1_perClass: 0.0150 - acc: 0.9940\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3591 - f1_perRow: 0.7543 - f1_perClass: 0.0150 - acc: 0.9943\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3495 - f1_perRow: 0.7589 - f1_perClass: 0.0150 - acc: 0.9948\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3578 - f1_perRow: 0.7572 - f1_perClass: 0.0152 - acc: 0.9944\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3689 - f1_perRow: 0.7543 - f1_perClass: 0.0149 - acc: 0.9946\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3625 - f1_perRow: 0.7614 - f1_perClass: 0.0149 - acc: 0.9942\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 78s 1ms/step - loss: 5.2724 - f1_perRow: 0.0287 - f1_perClass: 0.0049 - acc: 0.8576\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.0751 - f1_perRow: 0.0526 - f1_perClass: 0.0024 - acc: 0.9760\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.0091 - f1_perRow: 0.0606 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9517 - f1_perRow: 0.0571 - f1_perClass: 0.0027 - acc: 0.9760\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9139 - f1_perRow: 0.0526 - f1_perClass: 0.0023 - acc: 0.9760\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.9029 - f1_perRow: 0.0552 - f1_perClass: 0.0025 - acc: 0.9760\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8912 - f1_perRow: 0.0575 - f1_perClass: 0.0026 - acc: 0.9760\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8876 - f1_perRow: 0.0584 - f1_perClass: 0.0026 - acc: 0.9760\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8789 - f1_perRow: 0.0570 - f1_perClass: 0.0025 - acc: 0.9760\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8744 - f1_perRow: 0.0608 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8840 - f1_perRow: 0.0602 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8635 - f1_perRow: 0.0610 - f1_perClass: 0.0027 - acc: 0.9760\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8584 - f1_perRow: 0.0626 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8531 - f1_perRow: 0.0610 - f1_perClass: 0.0027 - acc: 0.9760\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8484 - f1_perRow: 0.0632 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8361 - f1_perRow: 0.0652 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8254 - f1_perRow: 0.0672 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.8197 - f1_perRow: 0.0679 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8233 - f1_perRow: 0.0690 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8364 - f1_perRow: 0.0698 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8501 - f1_perRow: 0.0649 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8279 - f1_perRow: 0.0662 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.8284 - f1_perRow: 0.0648 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8173 - f1_perRow: 0.0682 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8229 - f1_perRow: 0.0706 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8155 - f1_perRow: 0.0693 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8207 - f1_perRow: 0.0661 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8411 - f1_perRow: 0.0700 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8248 - f1_perRow: 0.0662 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8394 - f1_perRow: 0.0671 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8257 - f1_perRow: 0.0747 - f1_perClass: 0.0036 - acc: 0.9760\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8202 - f1_perRow: 0.0653 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8423 - f1_perRow: 0.0702 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8277 - f1_perRow: 0.0740 - f1_perClass: 0.0036 - acc: 0.9760\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8122 - f1_perRow: 0.0651 - f1_perClass: 0.0027 - acc: 0.9760\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.8115 - f1_perRow: 0.0718 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8165 - f1_perRow: 0.0746 - f1_perClass: 0.0035 - acc: 0.9760\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7937 - f1_perRow: 0.0690 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8006 - f1_perRow: 0.0715 - f1_perClass: 0.0032 - acc: 0.9760\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7943 - f1_perRow: 0.0746 - f1_perClass: 0.0035 - acc: 0.9760\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7896 - f1_perRow: 0.0700 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8017 - f1_perRow: 0.0726 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7956 - f1_perRow: 0.0712 - f1_perClass: 0.0032 - acc: 0.9760\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7823 - f1_perRow: 0.0722 - f1_perClass: 0.0032 - acc: 0.9760\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8036 - f1_perRow: 0.0778 - f1_perClass: 0.0037 - acc: 0.9760\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8426 - f1_perRow: 0.0669 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8390 - f1_perRow: 0.0649 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8175 - f1_perRow: 0.0715 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8243 - f1_perRow: 0.0669 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8121 - f1_perRow: 0.0735 - f1_perClass: 0.0035 - acc: 0.9760\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8202 - f1_perRow: 0.0746 - f1_perClass: 0.0035 - acc: 0.9760\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8163 - f1_perRow: 0.0659 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7925 - f1_perRow: 0.0726 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7952 - f1_perRow: 0.0699 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7869 - f1_perRow: 0.0766 - f1_perClass: 0.0036 - acc: 0.9760\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8065 - f1_perRow: 0.0685 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7844 - f1_perRow: 0.0727 - f1_perClass: 0.0032 - acc: 0.9760\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7829 - f1_perRow: 0.0734 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7754 - f1_perRow: 0.0758 - f1_perClass: 0.0034 - acc: 0.9760\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7841 - f1_perRow: 0.0721 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7797 - f1_perRow: 0.0745 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7874 - f1_perRow: 0.0744 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7846 - f1_perRow: 0.0696 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7792 - f1_perRow: 0.0776 - f1_perClass: 0.0035 - acc: 0.9760\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7884 - f1_perRow: 0.0779 - f1_perClass: 0.0036 - acc: 0.9760\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8269 - f1_perRow: 0.0676 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8139 - f1_perRow: 0.0718 - f1_perClass: 0.0034 - acc: 0.9760\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7951 - f1_perRow: 0.0721 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7783 - f1_perRow: 0.0743 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7768 - f1_perRow: 0.0721 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7789 - f1_perRow: 0.0749 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7770 - f1_perRow: 0.0760 - f1_perClass: 0.0034 - acc: 0.9760\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.7840 - f1_perRow: 0.0760 - f1_perClass: 0.0034 - acc: 0.9760\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.8019 - f1_perRow: 0.0700 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8478 - f1_perRow: 0.0801 - f1_perClass: 0.0040 - acc: 0.9760\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8266 - f1_perRow: 0.0773 - f1_perClass: 0.0037 - acc: 0.9760\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7858 - f1_perRow: 0.0680 - f1_perClass: 0.0028 - acc: 0.9760\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7792 - f1_perRow: 0.0759 - f1_perClass: 0.0035 - acc: 0.9760\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7845 - f1_perRow: 0.0699 - f1_perClass: 0.0029 - acc: 0.9760\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7869 - f1_perRow: 0.0810 - f1_perClass: 0.0039 - acc: 0.9760\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7879 - f1_perRow: 0.0706 - f1_perClass: 0.0030 - acc: 0.9760\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7770 - f1_perRow: 0.0779 - f1_perClass: 0.0036 - acc: 0.9760\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7888 - f1_perRow: 0.0742 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7603 - f1_perRow: 0.0761 - f1_perClass: 0.0033 - acc: 0.9760\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7774 - f1_perRow: 0.0729 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8029 - f1_perRow: 0.0767 - f1_perClass: 0.0036 - acc: 0.9760\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7773 - f1_perRow: 0.0809 - f1_perClass: 0.0038 - acc: 0.9760\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7643 - f1_perRow: 0.0725 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7755 - f1_perRow: 0.0766 - f1_perClass: 0.0034 - acc: 0.9760\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7749 - f1_perRow: 0.0817 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7768 - f1_perRow: 0.0734 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7961 - f1_perRow: 0.0815 - f1_perClass: 0.0039 - acc: 0.9760\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7895 - f1_perRow: 0.0667 - f1_perClass: 0.0027 - acc: 0.9760\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8080 - f1_perRow: 0.0835 - f1_perClass: 0.0042 - acc: 0.9761\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8025 - f1_perRow: 0.0710 - f1_perClass: 0.0030 - acc: 0.9761\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.8005 - f1_perRow: 0.0719 - f1_perClass: 0.0031 - acc: 0.9760\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7802 - f1_perRow: 0.0797 - f1_perClass: 0.0037 - acc: 0.9760\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7706 - f1_perRow: 0.0738 - f1_perClass: 0.0032 - acc: 0.9760\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7612 - f1_perRow: 0.0784 - f1_perClass: 0.0035 - acc: 0.9761\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7622 - f1_perRow: 0.0761 - f1_perClass: 0.0032 - acc: 0.9761\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7719 - f1_perRow: 0.0823 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7787 - f1_perRow: 0.0724 - f1_perClass: 0.0030 - acc: 0.9761\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7823 - f1_perRow: 0.0803 - f1_perClass: 0.0037 - acc: 0.9761\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7522 - f1_perRow: 0.0767 - f1_perClass: 0.0033 - acc: 0.9761\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7566 - f1_perRow: 0.0847 - f1_perClass: 0.0039 - acc: 0.9761\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7882 - f1_perRow: 0.0688 - f1_perClass: 0.0027 - acc: 0.9761\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8681 - f1_perRow: 0.0772 - f1_perClass: 0.0039 - acc: 0.9761\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7778 - f1_perRow: 0.0763 - f1_perClass: 0.0034 - acc: 0.9761\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7733 - f1_perRow: 0.0694 - f1_perClass: 0.0028 - acc: 0.9761\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7785 - f1_perRow: 0.0824 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7751 - f1_perRow: 0.0770 - f1_perClass: 0.0034 - acc: 0.9760\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7578 - f1_perRow: 0.0756 - f1_perClass: 0.0032 - acc: 0.9761\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7575 - f1_perRow: 0.0812 - f1_perClass: 0.0037 - acc: 0.9761\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7586 - f1_perRow: 0.0763 - f1_perClass: 0.0032 - acc: 0.9761\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7641 - f1_perRow: 0.0822 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7574 - f1_perRow: 0.0763 - f1_perClass: 0.0031 - acc: 0.9761\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7892 - f1_perRow: 0.0832 - f1_perClass: 0.0040 - acc: 0.9761\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7780 - f1_perRow: 0.0724 - f1_perClass: 0.0029 - acc: 0.9761\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7777 - f1_perRow: 0.0850 - f1_perClass: 0.0042 - acc: 0.9761\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7638 - f1_perRow: 0.0728 - f1_perClass: 0.0029 - acc: 0.9761\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7862 - f1_perRow: 0.0810 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7614 - f1_perRow: 0.0852 - f1_perClass: 0.0039 - acc: 0.9761\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7532 - f1_perRow: 0.0793 - f1_perClass: 0.0034 - acc: 0.9761\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7517 - f1_perRow: 0.0800 - f1_perClass: 0.0034 - acc: 0.9761\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7475 - f1_perRow: 0.0851 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7702 - f1_perRow: 0.0797 - f1_perClass: 0.0035 - acc: 0.9761\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7625 - f1_perRow: 0.0788 - f1_perClass: 0.0033 - acc: 0.9761\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7406 - f1_perRow: 0.0827 - f1_perClass: 0.0036 - acc: 0.9761\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7640 - f1_perRow: 0.0816 - f1_perClass: 0.0036 - acc: 0.9761\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7546 - f1_perRow: 0.0802 - f1_perClass: 0.0033 - acc: 0.9761\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7568 - f1_perRow: 0.0824 - f1_perClass: 0.0037 - acc: 0.9761\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7927 - f1_perRow: 0.0773 - f1_perClass: 0.0033 - acc: 0.9761\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7662 - f1_perRow: 0.0767 - f1_perClass: 0.0032 - acc: 0.9761\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7595 - f1_perRow: 0.0833 - f1_perClass: 0.0037 - acc: 0.9761\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7608 - f1_perRow: 0.0756 - f1_perClass: 0.0030 - acc: 0.9762\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.8205 - f1_perRow: 0.0863 - f1_perClass: 0.0042 - acc: 0.9762\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7570 - f1_perRow: 0.0799 - f1_perClass: 0.0034 - acc: 0.9762\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7627 - f1_perRow: 0.0797 - f1_perClass: 0.0035 - acc: 0.9761\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7653 - f1_perRow: 0.0833 - f1_perClass: 0.0038 - acc: 0.9761\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7760 - f1_perRow: 0.0758 - f1_perClass: 0.0030 - acc: 0.9762\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 1.7519 - f1_perRow: 0.0890 - f1_perClass: 0.0041 - acc: 0.9762\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7734 - f1_perRow: 0.0746 - f1_perClass: 0.0028 - acc: 0.9762\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7970 - f1_perRow: 0.0911 - f1_perClass: 0.0046 - acc: 0.9762\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7614 - f1_perRow: 0.0739 - f1_perClass: 0.0028 - acc: 0.9762\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7507 - f1_perRow: 0.0851 - f1_perClass: 0.0039 - acc: 0.9762\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7494 - f1_perRow: 0.0831 - f1_perClass: 0.0035 - acc: 0.9762\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7431 - f1_perRow: 0.0832 - f1_perClass: 0.0035 - acc: 0.9762\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7579 - f1_perRow: 0.0884 - f1_perClass: 0.0042 - acc: 0.9762\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7570 - f1_perRow: 0.0800 - f1_perClass: 0.0033 - acc: 0.9762\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7469 - f1_perRow: 0.0828 - f1_perClass: 0.0035 - acc: 0.9762\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7358 - f1_perRow: 0.0884 - f1_perClass: 0.0039 - acc: 0.9763\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7409 - f1_perRow: 0.0835 - f1_perClass: 0.0033 - acc: 0.9762\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7768 - f1_perRow: 0.0903 - f1_perClass: 0.0044 - acc: 0.9763\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.8072 - f1_perRow: 0.0712 - f1_perClass: 0.0025 - acc: 0.9763\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.8224 - f1_perRow: 0.0902 - f1_perClass: 0.0047 - acc: 0.9762\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7921 - f1_perRow: 0.0705 - f1_perClass: 0.0027 - acc: 0.9762\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7565 - f1_perRow: 0.0786 - f1_perClass: 0.0033 - acc: 0.9761\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7488 - f1_perRow: 0.0879 - f1_perClass: 0.0040 - acc: 0.9762\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7631 - f1_perRow: 0.0826 - f1_perClass: 0.0035 - acc: 0.9763\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7317 - f1_perRow: 0.0885 - f1_perClass: 0.0038 - acc: 0.9762\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7532 - f1_perRow: 0.0816 - f1_perClass: 0.0032 - acc: 0.9763\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7726 - f1_perRow: 0.0889 - f1_perClass: 0.0041 - acc: 0.9762\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7431 - f1_perRow: 0.0814 - f1_perClass: 0.0032 - acc: 0.9762\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7759 - f1_perRow: 0.0920 - f1_perClass: 0.0046 - acc: 0.9762\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7558 - f1_perRow: 0.0770 - f1_perClass: 0.0029 - acc: 0.9762\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7679 - f1_perRow: 0.0870 - f1_perClass: 0.0040 - acc: 0.9763\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7397 - f1_perRow: 0.0838 - f1_perClass: 0.0035 - acc: 0.9762\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7342 - f1_perRow: 0.0842 - f1_perClass: 0.0035 - acc: 0.9763\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7581 - f1_perRow: 0.0885 - f1_perClass: 0.0040 - acc: 0.9762\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7793 - f1_perRow: 0.0773 - f1_perClass: 0.0029 - acc: 0.9761\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7549 - f1_perRow: 0.0893 - f1_perClass: 0.0041 - acc: 0.9763\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7395 - f1_perRow: 0.0826 - f1_perClass: 0.0033 - acc: 0.9762\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7607 - f1_perRow: 0.0853 - f1_perClass: 0.0036 - acc: 0.9763\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7470 - f1_perRow: 0.0901 - f1_perClass: 0.0040 - acc: 0.9763\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7422 - f1_perRow: 0.0811 - f1_perClass: 0.0032 - acc: 0.9763\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7297 - f1_perRow: 0.0902 - f1_perClass: 0.0040 - acc: 0.9763\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7573 - f1_perRow: 0.0837 - f1_perClass: 0.0034 - acc: 0.9763\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7524 - f1_perRow: 0.0894 - f1_perClass: 0.0040 - acc: 0.9763\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7333 - f1_perRow: 0.0840 - f1_perClass: 0.0033 - acc: 0.9763\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7648 - f1_perRow: 0.0836 - f1_perClass: 0.0034 - acc: 0.9763\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7707 - f1_perRow: 0.0926 - f1_perClass: 0.0045 - acc: 0.9762\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7820 - f1_perRow: 0.0819 - f1_perClass: 0.0035 - acc: 0.9763\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7429 - f1_perRow: 0.0858 - f1_perClass: 0.0035 - acc: 0.9763\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7425 - f1_perRow: 0.0872 - f1_perClass: 0.0037 - acc: 0.9763\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7354 - f1_perRow: 0.0881 - f1_perClass: 0.0038 - acc: 0.9763\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7328 - f1_perRow: 0.0844 - f1_perClass: 0.0033 - acc: 0.9763\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7349 - f1_perRow: 0.0920 - f1_perClass: 0.0041 - acc: 0.9763\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7568 - f1_perRow: 0.0826 - f1_perClass: 0.0033 - acc: 0.9763\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7751 - f1_perRow: 0.0906 - f1_perClass: 0.0043 - acc: 0.9763\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7676 - f1_perRow: 0.0820 - f1_perClass: 0.0032 - acc: 0.9763\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7295 - f1_perRow: 0.0880 - f1_perClass: 0.0036 - acc: 0.9763\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7296 - f1_perRow: 0.0899 - f1_perClass: 0.0039 - acc: 0.9763\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 1.7295 - f1_perRow: 0.0895 - f1_perClass: 0.0036 - acc: 0.9763\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7297 - f1_perRow: 0.0914 - f1_perClass: 0.0040 - acc: 0.9763\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7174 - f1_perRow: 0.0898 - f1_perClass: 0.0037 - acc: 0.9763\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 1.7286 - f1_perRow: 0.0896 - f1_perClass: 0.0038 - acc: 0.9763\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 1.7774 - f1_perRow: 0.0880 - f1_perClass: 0.0039 - acc: 0.9763\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7792 - f1_perRow: 0.0790 - f1_perClass: 0.0031 - acc: 0.9762\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7381 - f1_perRow: 0.0870 - f1_perClass: 0.0036 - acc: 0.9763\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.7197 - f1_perRow: 0.0911 - f1_perClass: 0.0038 - acc: 0.9763\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 78s 1ms/step - loss: 9.0343 - f1_perRow: 0.5367 - f1_perClass: 0.2276 - acc: 0.7085\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.9376 - f1_perRow: 0.7113 - f1_perClass: 0.2858 - acc: 0.8636\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 3.1876 - f1_perRow: 0.8494 - f1_perClass: 0.3114 - acc: 0.9435\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.5631 - f1_perRow: 0.9355 - f1_perClass: 0.3292 - acc: 0.9714\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 1.1100 - f1_perRow: 0.9533 - f1_perClass: 0.3336 - acc: 0.9765\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.8874 - f1_perRow: 0.9636 - f1_perClass: 0.3357 - acc: 0.9803\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7643 - f1_perRow: 0.9660 - f1_perClass: 0.3370 - acc: 0.9810\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6751 - f1_perRow: 0.9684 - f1_perClass: 0.3377 - acc: 0.9835\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6183 - f1_perRow: 0.9706 - f1_perClass: 0.3384 - acc: 0.9850\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5874 - f1_perRow: 0.9729 - f1_perClass: 0.3386 - acc: 0.9863\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5527 - f1_perRow: 0.9740 - f1_perClass: 0.3393 - acc: 0.9871\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5257 - f1_perRow: 0.9753 - f1_perClass: 0.3395 - acc: 0.9876\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4958 - f1_perRow: 0.9769 - f1_perClass: 0.3399 - acc: 0.9888\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4818 - f1_perRow: 0.9778 - f1_perClass: 0.3402 - acc: 0.9895\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4656 - f1_perRow: 0.9786 - f1_perClass: 0.3407 - acc: 0.9891\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4512 - f1_perRow: 0.9791 - f1_perClass: 0.3403 - acc: 0.9894\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4522 - f1_perRow: 0.9790 - f1_perClass: 0.3405 - acc: 0.9897\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4459 - f1_perRow: 0.9802 - f1_perClass: 0.3409 - acc: 0.9900\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4442 - f1_perRow: 0.9797 - f1_perClass: 0.3406 - acc: 0.9898\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4215 - f1_perRow: 0.9806 - f1_perClass: 0.3410 - acc: 0.9906\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4136 - f1_perRow: 0.9815 - f1_perClass: 0.3415 - acc: 0.9907\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4014 - f1_perRow: 0.9815 - f1_perClass: 0.3413 - acc: 0.9912\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3847 - f1_perRow: 0.9821 - f1_perClass: 0.3411 - acc: 0.9915\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4040 - f1_perRow: 0.9824 - f1_perClass: 0.3416 - acc: 0.9913\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3946 - f1_perRow: 0.9817 - f1_perClass: 0.3411 - acc: 0.9915\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3635 - f1_perRow: 0.9835 - f1_perClass: 0.3417 - acc: 0.9923\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3579 - f1_perRow: 0.9845 - f1_perClass: 0.3422 - acc: 0.9925\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3429 - f1_perRow: 0.9846 - f1_perClass: 0.3419 - acc: 0.9928\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3600 - f1_perRow: 0.9837 - f1_perClass: 0.3418 - acc: 0.9924\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3215 - f1_perRow: 0.9853 - f1_perClass: 0.3423 - acc: 0.9937\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3278 - f1_perRow: 0.9862 - f1_perClass: 0.3423 - acc: 0.9933\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3339 - f1_perRow: 0.9853 - f1_perClass: 0.3419 - acc: 0.9934\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3135 - f1_perRow: 0.9853 - f1_perClass: 0.3421 - acc: 0.9940\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2918 - f1_perRow: 0.9874 - f1_perClass: 0.3425 - acc: 0.9943\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2792 - f1_perRow: 0.9881 - f1_perClass: 0.3429 - acc: 0.9946\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2806 - f1_perRow: 0.9878 - f1_perClass: 0.3427 - acc: 0.9947\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3115 - f1_perRow: 0.9862 - f1_perClass: 0.3422 - acc: 0.9932\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2742 - f1_perRow: 0.9874 - f1_perClass: 0.3427 - acc: 0.9947\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2631 - f1_perRow: 0.9889 - f1_perClass: 0.3431 - acc: 0.9951\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2552 - f1_perRow: 0.9894 - f1_perClass: 0.3431 - acc: 0.9951\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3062 - f1_perRow: 0.9867 - f1_perClass: 0.3426 - acc: 0.9935\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3228 - f1_perRow: 0.9849 - f1_perClass: 0.3419 - acc: 0.9924\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3135 - f1_perRow: 0.9851 - f1_perClass: 0.3418 - acc: 0.9933\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3054 - f1_perRow: 0.9868 - f1_perClass: 0.3427 - acc: 0.9933\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2985 - f1_perRow: 0.9867 - f1_perClass: 0.3427 - acc: 0.9935\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2954 - f1_perRow: 0.9870 - f1_perClass: 0.3426 - acc: 0.9934\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2765 - f1_perRow: 0.9868 - f1_perClass: 0.3425 - acc: 0.9942\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2404 - f1_perRow: 0.9892 - f1_perClass: 0.3430 - acc: 0.9956\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2342 - f1_perRow: 0.9912 - f1_perClass: 0.3438 - acc: 0.9959\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2328 - f1_perRow: 0.9896 - f1_perClass: 0.3430 - acc: 0.9958\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2189 - f1_perRow: 0.9908 - f1_perClass: 0.3438 - acc: 0.9958\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2119 - f1_perRow: 0.9908 - f1_perClass: 0.3433 - acc: 0.9963\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2035 - f1_perRow: 0.9912 - f1_perClass: 0.3435 - acc: 0.9963\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1980 - f1_perRow: 0.9916 - f1_perClass: 0.3438 - acc: 0.9964\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1981 - f1_perRow: 0.9911 - f1_perClass: 0.3435 - acc: 0.9964\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1975 - f1_perRow: 0.9918 - f1_perClass: 0.3438 - acc: 0.9964\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1992 - f1_perRow: 0.9915 - f1_perClass: 0.3436 - acc: 0.9964\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1993 - f1_perRow: 0.9914 - f1_perClass: 0.3437 - acc: 0.9964\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1916 - f1_perRow: 0.9918 - f1_perClass: 0.3437 - acc: 0.9966\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1941 - f1_perRow: 0.9922 - f1_perClass: 0.3441 - acc: 0.9966\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1904 - f1_perRow: 0.9916 - f1_perClass: 0.3435 - acc: 0.9967\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1815 - f1_perRow: 0.9922 - f1_perClass: 0.3439 - acc: 0.9967\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1786 - f1_perRow: 0.9922 - f1_perClass: 0.3439 - acc: 0.9968\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1783 - f1_perRow: 0.9923 - f1_perClass: 0.3439 - acc: 0.9968\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1797 - f1_perRow: 0.9926 - f1_perClass: 0.3440 - acc: 0.9967\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1786 - f1_perRow: 0.9922 - f1_perClass: 0.3439 - acc: 0.9967\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1750 - f1_perRow: 0.9923 - f1_perClass: 0.3439 - acc: 0.9968\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1750 - f1_perRow: 0.9928 - f1_perClass: 0.3440 - acc: 0.9968\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1717 - f1_perRow: 0.9923 - f1_perClass: 0.3438 - acc: 0.9970\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1688 - f1_perRow: 0.9925 - f1_perClass: 0.3439 - acc: 0.9969\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1679 - f1_perRow: 0.9925 - f1_perClass: 0.3439 - acc: 0.9969\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1696 - f1_perRow: 0.9928 - f1_perClass: 0.3440 - acc: 0.9969\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1736 - f1_perRow: 0.9928 - f1_perClass: 0.3440 - acc: 0.9968\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1691 - f1_perRow: 0.9925 - f1_perClass: 0.3439 - acc: 0.9969\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1685 - f1_perRow: 0.9928 - f1_perClass: 0.3441 - acc: 0.9970\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1630 - f1_perRow: 0.9930 - f1_perClass: 0.3441 - acc: 0.9970\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1608 - f1_perRow: 0.9930 - f1_perClass: 0.3441 - acc: 0.9971\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1616 - f1_perRow: 0.9930 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1583 - f1_perRow: 0.9930 - f1_perClass: 0.3441 - acc: 0.9971\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1595 - f1_perRow: 0.9928 - f1_perClass: 0.3439 - acc: 0.9970\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1633 - f1_perRow: 0.9935 - f1_perClass: 0.3443 - acc: 0.9971\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1798 - f1_perRow: 0.9917 - f1_perClass: 0.3435 - acc: 0.9967\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2561 - f1_perRow: 0.9895 - f1_perClass: 0.3436 - acc: 0.9946\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4112 - f1_perRow: 0.9831 - f1_perClass: 0.3408 - acc: 0.9909\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3956 - f1_perRow: 0.9854 - f1_perClass: 0.3425 - acc: 0.9928\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2839 - f1_perRow: 0.9881 - f1_perClass: 0.3427 - acc: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2540 - f1_perRow: 0.9898 - f1_perClass: 0.3435 - acc: 0.9954\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2137 - f1_perRow: 0.9902 - f1_perClass: 0.3433 - acc: 0.9963\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1965 - f1_perRow: 0.9921 - f1_perClass: 0.3439 - acc: 0.9966\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1856 - f1_perRow: 0.9920 - f1_perClass: 0.3438 - acc: 0.9967\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1718 - f1_perRow: 0.9923 - f1_perClass: 0.3439 - acc: 0.9968\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1725 - f1_perRow: 0.9927 - f1_perClass: 0.3440 - acc: 0.9970\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1725 - f1_perRow: 0.9927 - f1_perClass: 0.3440 - acc: 0.9968\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1663 - f1_perRow: 0.9926 - f1_perClass: 0.3438 - acc: 0.9970\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1653 - f1_perRow: 0.9930 - f1_perClass: 0.3441 - acc: 0.9970\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1594 - f1_perRow: 0.9930 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1585 - f1_perRow: 0.9930 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1575 - f1_perRow: 0.9932 - f1_perClass: 0.3441 - acc: 0.9971\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1567 - f1_perRow: 0.9930 - f1_perClass: 0.3441 - acc: 0.9971\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1596 - f1_perRow: 0.9930 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1510 - f1_perRow: 0.9933 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1527 - f1_perRow: 0.9935 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1565 - f1_perRow: 0.9932 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1510 - f1_perRow: 0.9932 - f1_perClass: 0.3440 - acc: 0.9972\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1524 - f1_perRow: 0.9935 - f1_perClass: 0.3443 - acc: 0.9972\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1539 - f1_perRow: 0.9931 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1527 - f1_perRow: 0.9933 - f1_perClass: 0.3441 - acc: 0.9971\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1523 - f1_perRow: 0.9936 - f1_perClass: 0.3443 - acc: 0.9972\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1498 - f1_perRow: 0.9932 - f1_perClass: 0.3440 - acc: 0.9973\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1490 - f1_perRow: 0.9935 - f1_perClass: 0.3442 - acc: 0.9972\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1506 - f1_perRow: 0.9934 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1516 - f1_perRow: 0.9933 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1579 - f1_perRow: 0.9929 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1982 - f1_perRow: 0.9919 - f1_perClass: 0.3439 - acc: 0.9966\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1864 - f1_perRow: 0.9929 - f1_perClass: 0.3441 - acc: 0.9968\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1832 - f1_perRow: 0.9920 - f1_perClass: 0.3436 - acc: 0.9966\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1750 - f1_perRow: 0.9925 - f1_perClass: 0.3440 - acc: 0.9969\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1632 - f1_perRow: 0.9929 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1626 - f1_perRow: 0.9934 - f1_perClass: 0.3443 - acc: 0.9971\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1603 - f1_perRow: 0.9931 - f1_perClass: 0.3440 - acc: 0.9971\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1560 - f1_perRow: 0.9932 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1580 - f1_perRow: 0.9934 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1550 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9972\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1584 - f1_perRow: 0.9932 - f1_perClass: 0.3440 - acc: 0.9972\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1586 - f1_perRow: 0.9938 - f1_perClass: 0.3444 - acc: 0.9971\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1586 - f1_perRow: 0.9927 - f1_perClass: 0.3438 - acc: 0.9972\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1540 - f1_perRow: 0.9935 - f1_perClass: 0.3442 - acc: 0.9972\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1534 - f1_perRow: 0.9938 - f1_perClass: 0.3444 - acc: 0.9972\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1529 - f1_perRow: 0.9931 - f1_perClass: 0.3439 - acc: 0.9973\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1550 - f1_perRow: 0.9936 - f1_perClass: 0.3443 - acc: 0.9972\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1564 - f1_perRow: 0.9935 - f1_perClass: 0.3442 - acc: 0.9972\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1470 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1531 - f1_perRow: 0.9934 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1496 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1539 - f1_perRow: 0.9937 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1542 - f1_perRow: 0.9933 - f1_perClass: 0.3440 - acc: 0.9972\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1487 - f1_perRow: 0.9935 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1513 - f1_perRow: 0.9936 - f1_perClass: 0.3443 - acc: 0.9972\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1498 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1473 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1465 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9974\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1479 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1480 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1497 - f1_perRow: 0.9934 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1477 - f1_perRow: 0.9937 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1457 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1432 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9974\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1477 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1468 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1463 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1433 - f1_perRow: 0.9937 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1427 - f1_perRow: 0.9936 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1464 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1424 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1410 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1417 - f1_perRow: 0.9936 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1428 - f1_perRow: 0.9939 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1440 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1442 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1455 - f1_perRow: 0.9940 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1423 - f1_perRow: 0.9938 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1445 - f1_perRow: 0.9932 - f1_perClass: 0.3440 - acc: 0.9973\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1489 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9972\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1486 - f1_perRow: 0.9939 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 3s 43us/step - loss: 0.1450 - f1_perRow: 0.9934 - f1_perClass: 0.3440 - acc: 0.9973\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1426 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1434 - f1_perRow: 0.9938 - f1_perClass: 0.3444 - acc: 0.9973\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1422 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1410 - f1_perRow: 0.9936 - f1_perClass: 0.3441 - acc: 0.9974\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1413 - f1_perRow: 0.9940 - f1_perClass: 0.3443 - acc: 0.9974\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1404 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1425 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1396 - f1_perRow: 0.9939 - f1_perClass: 0.3443 - acc: 0.9974\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1396 - f1_perRow: 0.9938 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1424 - f1_perRow: 0.9938 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1411 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1429 - f1_perRow: 0.9936 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1393 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9974\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1387 - f1_perRow: 0.9938 - f1_perClass: 0.3442 - acc: 0.9974\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1428 - f1_perRow: 0.9940 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1441 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1462 - f1_perRow: 0.9934 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.1435 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1421 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.1437 - f1_perRow: 0.9934 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1424 - f1_perRow: 0.9935 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1426 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1489 - f1_perRow: 0.9936 - f1_perClass: 0.3441 - acc: 0.9973\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1427 - f1_perRow: 0.9938 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1435 - f1_perRow: 0.9938 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1452 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.1400 - f1_perRow: 0.9936 - f1_perClass: 0.3441 - acc: 0.9974\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1467 - f1_perRow: 0.9939 - f1_perClass: 0.3443 - acc: 0.9973\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1469 - f1_perRow: 0.9936 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.1397 - f1_perRow: 0.9939 - f1_perClass: 0.3443 - acc: 0.9974\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1386 - f1_perRow: 0.9939 - f1_perClass: 0.3442 - acc: 0.9974\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1379 - f1_perRow: 0.9937 - f1_perClass: 0.3441 - acc: 0.9974\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1471 - f1_perRow: 0.9939 - f1_perClass: 0.3443 - acc: 0.9972\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.1396 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9973\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.1432 - f1_perRow: 0.9937 - f1_perClass: 0.3442 - acc: 0.9972\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 79s 1ms/step - loss: 5.3551 - f1_perRow: 0.0056 - f1_perClass: 0.0016 - acc: 0.8117\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.8225 - f1_perRow: 0.1011 - f1_perClass: 0.0011 - acc: 0.9915\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6159 - f1_perRow: 0.1873 - f1_perClass: 0.0026 - acc: 0.9915\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5588 - f1_perRow: 0.3121 - f1_perClass: 0.0032 - acc: 0.9915\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5051 - f1_perRow: 0.3288 - f1_perClass: 0.0037 - acc: 0.9915\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4885 - f1_perRow: 0.3337 - f1_perClass: 0.0037 - acc: 0.9915\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4683 - f1_perRow: 0.3643 - f1_perClass: 0.0036 - acc: 0.9915\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4433 - f1_perRow: 0.3276 - f1_perClass: 0.0038 - acc: 0.9915\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4354 - f1_perRow: 0.3639 - f1_perClass: 0.0037 - acc: 0.9915\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4214 - f1_perRow: 0.3533 - f1_perClass: 0.0038 - acc: 0.9915\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4183 - f1_perRow: 0.3605 - f1_perClass: 0.0039 - acc: 0.9915\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4100 - f1_perRow: 0.3770 - f1_perClass: 0.0039 - acc: 0.9915\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4062 - f1_perRow: 0.3747 - f1_perClass: 0.0040 - acc: 0.9915\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3995 - f1_perRow: 0.3859 - f1_perClass: 0.0040 - acc: 0.9915\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3998 - f1_perRow: 0.3784 - f1_perClass: 0.0040 - acc: 0.9915\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3969 - f1_perRow: 0.4031 - f1_perClass: 0.0040 - acc: 0.9915\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3951 - f1_perRow: 0.3874 - f1_perClass: 0.0041 - acc: 0.9915\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3905 - f1_perRow: 0.4054 - f1_perClass: 0.0041 - acc: 0.9915\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3894 - f1_perRow: 0.4021 - f1_perClass: 0.0042 - acc: 0.9915\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3847 - f1_perRow: 0.4173 - f1_perClass: 0.0042 - acc: 0.9915\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3811 - f1_perRow: 0.4185 - f1_perClass: 0.0043 - acc: 0.9951\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3777 - f1_perRow: 0.4211 - f1_perClass: 0.0043 - acc: 0.9954\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3731 - f1_perRow: 0.4346 - f1_perClass: 0.0044 - acc: 0.9954\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3687 - f1_perRow: 0.4312 - f1_perClass: 0.0045 - acc: 0.9955\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3663 - f1_perRow: 0.4590 - f1_perClass: 0.0045 - acc: 0.9955\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3663 - f1_perRow: 0.4537 - f1_perClass: 0.0046 - acc: 0.9955\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3612 - f1_perRow: 0.4663 - f1_perClass: 0.0047 - acc: 0.9956\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3598 - f1_perRow: 0.4672 - f1_perClass: 0.0048 - acc: 0.9956\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3582 - f1_perRow: 0.5068 - f1_perClass: 0.0048 - acc: 0.9956\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3471 - f1_perRow: 0.4876 - f1_perClass: 0.0051 - acc: 0.9957\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3419 - f1_perRow: 0.5281 - f1_perClass: 0.0051 - acc: 0.9957\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3397 - f1_perRow: 0.5336 - f1_perClass: 0.0053 - acc: 0.9958\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3360 - f1_perRow: 0.5417 - f1_perClass: 0.0054 - acc: 0.9957\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3294 - f1_perRow: 0.5765 - f1_perClass: 0.0056 - acc: 0.9958\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3269 - f1_perRow: 0.5703 - f1_perClass: 0.0057 - acc: 0.9959\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3282 - f1_perRow: 0.6022 - f1_perClass: 0.0057 - acc: 0.9959\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3222 - f1_perRow: 0.5785 - f1_perClass: 0.0058 - acc: 0.9959\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3262 - f1_perRow: 0.5977 - f1_perClass: 0.0058 - acc: 0.9960\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3233 - f1_perRow: 0.6064 - f1_perClass: 0.0059 - acc: 0.9959\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3291 - f1_perRow: 0.5812 - f1_perClass: 0.0057 - acc: 0.9960\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3301 - f1_perRow: 0.5907 - f1_perClass: 0.0059 - acc: 0.9960\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3272 - f1_perRow: 0.6105 - f1_perClass: 0.0059 - acc: 0.9959\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3190 - f1_perRow: 0.6073 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3276 - f1_perRow: 0.5968 - f1_perClass: 0.0059 - acc: 0.9959\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3164 - f1_perRow: 0.6309 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3189 - f1_perRow: 0.5967 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3203 - f1_perRow: 0.6304 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3171 - f1_perRow: 0.6010 - f1_perClass: 0.0059 - acc: 0.9960\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3173 - f1_perRow: 0.6178 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3158 - f1_perRow: 0.6031 - f1_perClass: 0.0059 - acc: 0.9960\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3172 - f1_perRow: 0.6129 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3163 - f1_perRow: 0.6128 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3173 - f1_perRow: 0.6353 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3116 - f1_perRow: 0.6044 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3121 - f1_perRow: 0.6254 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3134 - f1_perRow: 0.6051 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3173 - f1_perRow: 0.6330 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3145 - f1_perRow: 0.5996 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3156 - f1_perRow: 0.6242 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3160 - f1_perRow: 0.6119 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3139 - f1_perRow: 0.6103 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3111 - f1_perRow: 0.6174 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3104 - f1_perRow: 0.6118 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3124 - f1_perRow: 0.6220 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3134 - f1_perRow: 0.6325 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3099 - f1_perRow: 0.6086 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3133 - f1_perRow: 0.6212 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3088 - f1_perRow: 0.6229 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3133 - f1_perRow: 0.6317 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3107 - f1_perRow: 0.6117 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3121 - f1_perRow: 0.6196 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3112 - f1_perRow: 0.6241 - f1_perClass: 0.0059 - acc: 0.9960\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3088 - f1_perRow: 0.6173 - f1_perClass: 0.0061 - acc: 0.9961\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3081 - f1_perRow: 0.6274 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3071 - f1_perRow: 0.6066 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3085 - f1_perRow: 0.6316 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3079 - f1_perRow: 0.6213 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3069 - f1_perRow: 0.6230 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3057 - f1_perRow: 0.6225 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3066 - f1_perRow: 0.6115 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3096 - f1_perRow: 0.6216 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3065 - f1_perRow: 0.6217 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3069 - f1_perRow: 0.6290 - f1_perClass: 0.0061 - acc: 0.9961\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3052 - f1_perRow: 0.6368 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3113 - f1_perRow: 0.6295 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3089 - f1_perRow: 0.6040 - f1_perClass: 0.0059 - acc: 0.9962\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3108 - f1_perRow: 0.6203 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3074 - f1_perRow: 0.6265 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3049 - f1_perRow: 0.6205 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3070 - f1_perRow: 0.6329 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3056 - f1_perRow: 0.6390 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3061 - f1_perRow: 0.6344 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3069 - f1_perRow: 0.6190 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3066 - f1_perRow: 0.6275 - f1_perClass: 0.0060 - acc: 0.9964\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3075 - f1_perRow: 0.6326 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3066 - f1_perRow: 0.6380 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3136 - f1_perRow: 0.5857 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3196 - f1_perRow: 0.6547 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3149 - f1_perRow: 0.5817 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3183 - f1_perRow: 0.6529 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3149 - f1_perRow: 0.5962 - f1_perClass: 0.0062 - acc: 0.9963\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3212 - f1_perRow: 0.6305 - f1_perClass: 0.0059 - acc: 0.9962\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3125 - f1_perRow: 0.5906 - f1_perClass: 0.0058 - acc: 0.9960\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3068 - f1_perRow: 0.6247 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3097 - f1_perRow: 0.6344 - f1_perClass: 0.0061 - acc: 0.9961\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3092 - f1_perRow: 0.6087 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3078 - f1_perRow: 0.6218 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3055 - f1_perRow: 0.6358 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3082 - f1_perRow: 0.6283 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3015 - f1_perRow: 0.6390 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3070 - f1_perRow: 0.6045 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3040 - f1_perRow: 0.6417 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3070 - f1_perRow: 0.6180 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3043 - f1_perRow: 0.6364 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3059 - f1_perRow: 0.6174 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3087 - f1_perRow: 0.6409 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3052 - f1_perRow: 0.6141 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3039 - f1_perRow: 0.6359 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3033 - f1_perRow: 0.6154 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3028 - f1_perRow: 0.6218 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3035 - f1_perRow: 0.6384 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3049 - f1_perRow: 0.6162 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3046 - f1_perRow: 0.6316 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3067 - f1_perRow: 0.6245 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3070 - f1_perRow: 0.6247 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3076 - f1_perRow: 0.6165 - f1_perClass: 0.0060 - acc: 0.9960\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3100 - f1_perRow: 0.6479 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3063 - f1_perRow: 0.6161 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3082 - f1_perRow: 0.6187 - f1_perClass: 0.0058 - acc: 0.9961\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3043 - f1_perRow: 0.6209 - f1_perClass: 0.0061 - acc: 0.9964\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3056 - f1_perRow: 0.6320 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3055 - f1_perRow: 0.6306 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3035 - f1_perRow: 0.6083 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3051 - f1_perRow: 0.6395 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3031 - f1_perRow: 0.6211 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3034 - f1_perRow: 0.6391 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3031 - f1_perRow: 0.6226 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3045 - f1_perRow: 0.6351 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3037 - f1_perRow: 0.6193 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3030 - f1_perRow: 0.6309 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3042 - f1_perRow: 0.6452 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3053 - f1_perRow: 0.6179 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3052 - f1_perRow: 0.6431 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3034 - f1_perRow: 0.6161 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3032 - f1_perRow: 0.6320 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3035 - f1_perRow: 0.6201 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2994 - f1_perRow: 0.6310 - f1_perClass: 0.0061 - acc: 0.9964\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3006 - f1_perRow: 0.6423 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2998 - f1_perRow: 0.6226 - f1_perClass: 0.0061 - acc: 0.9964\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3026 - f1_perRow: 0.6486 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3019 - f1_perRow: 0.6255 - f1_perClass: 0.0061 - acc: 0.9961\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3025 - f1_perRow: 0.6142 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3021 - f1_perRow: 0.6336 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3005 - f1_perRow: 0.6270 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3054 - f1_perRow: 0.6222 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3032 - f1_perRow: 0.6269 - f1_perClass: 0.0062 - acc: 0.9962\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3027 - f1_perRow: 0.6397 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3014 - f1_perRow: 0.6209 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2993 - f1_perRow: 0.6373 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3020 - f1_perRow: 0.6158 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3029 - f1_perRow: 0.6454 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3028 - f1_perRow: 0.6286 - f1_perClass: 0.0062 - acc: 0.9963\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3013 - f1_perRow: 0.6242 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3009 - f1_perRow: 0.6209 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3001 - f1_perRow: 0.6459 - f1_perClass: 0.0062 - acc: 0.9963\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2980 - f1_perRow: 0.6370 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2999 - f1_perRow: 0.6190 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3011 - f1_perRow: 0.6430 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2997 - f1_perRow: 0.6267 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3027 - f1_perRow: 0.6253 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3019 - f1_perRow: 0.6359 - f1_perClass: 0.0062 - acc: 0.9963\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3030 - f1_perRow: 0.6243 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3023 - f1_perRow: 0.6346 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3032 - f1_perRow: 0.6194 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.3001 - f1_perRow: 0.6301 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2980 - f1_perRow: 0.6239 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3004 - f1_perRow: 0.6120 - f1_perClass: 0.0059 - acc: 0.9961\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2998 - f1_perRow: 0.6397 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3027 - f1_perRow: 0.6366 - f1_perClass: 0.0062 - acc: 0.9963\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2977 - f1_perRow: 0.6248 - f1_perClass: 0.0060 - acc: 0.9964\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2977 - f1_perRow: 0.6193 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2975 - f1_perRow: 0.6417 - f1_perClass: 0.0062 - acc: 0.9963\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2994 - f1_perRow: 0.6407 - f1_perClass: 0.0062 - acc: 0.9961\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2999 - f1_perRow: 0.6314 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3004 - f1_perRow: 0.6132 - f1_perClass: 0.0061 - acc: 0.9964\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2999 - f1_perRow: 0.6529 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3034 - f1_perRow: 0.6221 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3020 - f1_perRow: 0.6195 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2997 - f1_perRow: 0.6337 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3011 - f1_perRow: 0.6355 - f1_perClass: 0.0062 - acc: 0.9962\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2996 - f1_perRow: 0.6241 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3006 - f1_perRow: 0.6166 - f1_perClass: 0.0060 - acc: 0.9963\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3017 - f1_perRow: 0.6521 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3019 - f1_perRow: 0.6236 - f1_perClass: 0.0062 - acc: 0.9964\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3050 - f1_perRow: 0.6278 - f1_perClass: 0.0060 - acc: 0.9961\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3033 - f1_perRow: 0.6322 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3010 - f1_perRow: 0.6213 - f1_perClass: 0.0061 - acc: 0.9962\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3006 - f1_perRow: 0.6381 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3008 - f1_perRow: 0.6208 - f1_perClass: 0.0061 - acc: 0.9963\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3017 - f1_perRow: 0.6368 - f1_perClass: 0.0060 - acc: 0.9962\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 79s 1ms/step - loss: 4.8710 - f1_perRow: 0.0415 - f1_perClass: 0.0040 - acc: 0.8910\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.1653 - f1_perRow: 0.2487 - f1_perClass: 0.0086 - acc: 0.9764\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.9651 - f1_perRow: 0.3672 - f1_perClass: 0.0097 - acc: 0.9764\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.8480 - f1_perRow: 0.4203 - f1_perClass: 0.0112 - acc: 0.9764\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7846 - f1_perRow: 0.4471 - f1_perClass: 0.0122 - acc: 0.9764\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7325 - f1_perRow: 0.5038 - f1_perClass: 0.0128 - acc: 0.9764\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6954 - f1_perRow: 0.5081 - f1_perClass: 0.0135 - acc: 0.9764\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6675 - f1_perRow: 0.5406 - f1_perClass: 0.0138 - acc: 0.9889\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6449 - f1_perRow: 0.5550 - f1_perClass: 0.0142 - acc: 0.9937\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6244 - f1_perRow: 0.5777 - f1_perClass: 0.0146 - acc: 0.9945\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6005 - f1_perRow: 0.5881 - f1_perClass: 0.0151 - acc: 0.9952\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5763 - f1_perRow: 0.6186 - f1_perClass: 0.0155 - acc: 0.9953\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5489 - f1_perRow: 0.6456 - f1_perClass: 0.0162 - acc: 0.9956\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5201 - f1_perRow: 0.6813 - f1_perClass: 0.0168 - acc: 0.9957\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4961 - f1_perRow: 0.7015 - f1_perClass: 0.0177 - acc: 0.9956\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4600 - f1_perRow: 0.7448 - f1_perClass: 0.0183 - acc: 0.9959\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4313 - f1_perRow: 0.7668 - f1_perClass: 0.0190 - acc: 0.9960\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.4048 - f1_perRow: 0.8077 - f1_perClass: 0.0196 - acc: 0.9962\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.3862 - f1_perRow: 0.8355 - f1_perClass: 0.0202 - acc: 0.9962\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3702 - f1_perRow: 0.8545 - f1_perClass: 0.0207 - acc: 0.9964\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3524 - f1_perRow: 0.8655 - f1_perClass: 0.0208 - acc: 0.9966\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3504 - f1_perRow: 0.8693 - f1_perClass: 0.0208 - acc: 0.9966\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3698 - f1_perRow: 0.8587 - f1_perClass: 0.0208 - acc: 0.9965\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3612 - f1_perRow: 0.8555 - f1_perClass: 0.0207 - acc: 0.9965\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.3463 - f1_perRow: 0.8715 - f1_perClass: 0.0209 - acc: 0.9967\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3307 - f1_perRow: 0.8714 - f1_perClass: 0.0208 - acc: 0.9968\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3246 - f1_perRow: 0.8722 - f1_perClass: 0.0210 - acc: 0.9969\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3221 - f1_perRow: 0.8793 - f1_perClass: 0.0211 - acc: 0.9970\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3027 - f1_perRow: 0.8819 - f1_perClass: 0.0212 - acc: 0.9972\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3393 - f1_perRow: 0.8836 - f1_perClass: 0.0208 - acc: 0.9969\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3275 - f1_perRow: 0.8771 - f1_perClass: 0.0210 - acc: 0.9970\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.3237 - f1_perRow: 0.8659 - f1_perClass: 0.0210 - acc: 0.9969\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3065 - f1_perRow: 0.8874 - f1_perClass: 0.0211 - acc: 0.9970\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3000 - f1_perRow: 0.8892 - f1_perClass: 0.0212 - acc: 0.9971\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2998 - f1_perRow: 0.8821 - f1_perClass: 0.0212 - acc: 0.9973\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3003 - f1_perRow: 0.8965 - f1_perClass: 0.0210 - acc: 0.9971\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3013 - f1_perRow: 0.8873 - f1_perClass: 0.0215 - acc: 0.9975\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2821 - f1_perRow: 0.8923 - f1_perClass: 0.0214 - acc: 0.9975\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2735 - f1_perRow: 0.8975 - f1_perClass: 0.0215 - acc: 0.9976\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3067 - f1_perRow: 0.8976 - f1_perClass: 0.0213 - acc: 0.9972\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2963 - f1_perRow: 0.8980 - f1_perClass: 0.0212 - acc: 0.9973\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2931 - f1_perRow: 0.8919 - f1_perClass: 0.0215 - acc: 0.9976\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2832 - f1_perRow: 0.9017 - f1_perClass: 0.0215 - acc: 0.9975\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2914 - f1_perRow: 0.8904 - f1_perClass: 0.0211 - acc: 0.9973\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2714 - f1_perRow: 0.8881 - f1_perClass: 0.0215 - acc: 0.9978\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2776 - f1_perRow: 0.9104 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2600 - f1_perRow: 0.9168 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2607 - f1_perRow: 0.9108 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2622 - f1_perRow: 0.8982 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2696 - f1_perRow: 0.9187 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2648 - f1_perRow: 0.9060 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2649 - f1_perRow: 0.9029 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2614 - f1_perRow: 0.9154 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2488 - f1_perRow: 0.9057 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2546 - f1_perRow: 0.9191 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2601 - f1_perRow: 0.8975 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2592 - f1_perRow: 0.9149 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2571 - f1_perRow: 0.9110 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2556 - f1_perRow: 0.8950 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 3s 44us/step - loss: 0.2537 - f1_perRow: 0.9228 - f1_perClass: 0.0215 - acc: 0.9978\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.3029 - f1_perRow: 0.8791 - f1_perClass: 0.0212 - acc: 0.9971\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.3310 - f1_perRow: 0.8792 - f1_perClass: 0.0211 - acc: 0.9966\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2949 - f1_perRow: 0.8823 - f1_perClass: 0.0212 - acc: 0.9974\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2997 - f1_perRow: 0.8981 - f1_perClass: 0.0215 - acc: 0.9974\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2818 - f1_perRow: 0.8909 - f1_perClass: 0.0214 - acc: 0.9977\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2629 - f1_perRow: 0.9053 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2555 - f1_perRow: 0.9119 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2535 - f1_perRow: 0.9135 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2543 - f1_perRow: 0.9092 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2499 - f1_perRow: 0.9142 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2448 - f1_perRow: 0.9026 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2436 - f1_perRow: 0.9121 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2479 - f1_perRow: 0.9112 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2483 - f1_perRow: 0.9044 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2513 - f1_perRow: 0.9096 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2580 - f1_perRow: 0.9205 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2538 - f1_perRow: 0.9014 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2517 - f1_perRow: 0.9150 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2464 - f1_perRow: 0.9103 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2476 - f1_perRow: 0.9055 - f1_perClass: 0.0217 - acc: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2441 - f1_perRow: 0.9196 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2455 - f1_perRow: 0.9041 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2436 - f1_perRow: 0.9130 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2515 - f1_perRow: 0.9072 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2393 - f1_perRow: 0.9076 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2407 - f1_perRow: 0.9178 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2393 - f1_perRow: 0.9127 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2351 - f1_perRow: 0.9065 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2416 - f1_perRow: 0.9144 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2388 - f1_perRow: 0.9067 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2364 - f1_perRow: 0.9187 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2348 - f1_perRow: 0.9173 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2375 - f1_perRow: 0.9049 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2409 - f1_perRow: 0.9243 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2363 - f1_perRow: 0.9028 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2426 - f1_perRow: 0.9137 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2354 - f1_perRow: 0.9165 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2374 - f1_perRow: 0.9092 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2353 - f1_perRow: 0.9145 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2344 - f1_perRow: 0.9133 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2313 - f1_perRow: 0.9085 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2339 - f1_perRow: 0.9181 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2382 - f1_perRow: 0.9048 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2401 - f1_perRow: 0.9197 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2390 - f1_perRow: 0.9088 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2366 - f1_perRow: 0.9127 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2325 - f1_perRow: 0.9195 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2327 - f1_perRow: 0.9060 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2361 - f1_perRow: 0.9191 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2343 - f1_perRow: 0.9054 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2385 - f1_perRow: 0.9146 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2349 - f1_perRow: 0.9122 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2327 - f1_perRow: 0.9063 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2347 - f1_perRow: 0.9170 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2407 - f1_perRow: 0.9103 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2387 - f1_perRow: 0.9119 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2311 - f1_perRow: 0.9091 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2356 - f1_perRow: 0.9157 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2335 - f1_perRow: 0.9075 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2330 - f1_perRow: 0.9176 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2258 - f1_perRow: 0.9114 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2290 - f1_perRow: 0.9120 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2295 - f1_perRow: 0.9145 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2343 - f1_perRow: 0.9120 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2337 - f1_perRow: 0.9158 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2263 - f1_perRow: 0.9157 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2281 - f1_perRow: 0.9111 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2285 - f1_perRow: 0.9146 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2266 - f1_perRow: 0.9087 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2321 - f1_perRow: 0.9191 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2370 - f1_perRow: 0.9165 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2331 - f1_perRow: 0.8999 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2383 - f1_perRow: 0.9260 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2289 - f1_perRow: 0.9046 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2309 - f1_perRow: 0.9240 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2270 - f1_perRow: 0.9063 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2259 - f1_perRow: 0.9203 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2306 - f1_perRow: 0.9094 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2288 - f1_perRow: 0.9161 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2286 - f1_perRow: 0.9055 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.2315 - f1_perRow: 0.9210 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2290 - f1_perRow: 0.9056 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2277 - f1_perRow: 0.9157 - f1_perClass: 0.0216 - acc: 0.9979\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2261 - f1_perRow: 0.9124 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2247 - f1_perRow: 0.9144 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2291 - f1_perRow: 0.9205 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2267 - f1_perRow: 0.8975 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2366 - f1_perRow: 0.9247 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2332 - f1_perRow: 0.9005 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2302 - f1_perRow: 0.9282 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2309 - f1_perRow: 0.9079 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 3s 43us/step - loss: 0.2242 - f1_perRow: 0.9145 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2250 - f1_perRow: 0.9083 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2282 - f1_perRow: 0.9185 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2228 - f1_perRow: 0.9097 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2242 - f1_perRow: 0.9221 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2274 - f1_perRow: 0.9035 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2262 - f1_perRow: 0.9217 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2297 - f1_perRow: 0.9005 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2289 - f1_perRow: 0.9305 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2252 - f1_perRow: 0.9041 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2255 - f1_perRow: 0.9260 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2235 - f1_perRow: 0.8984 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2274 - f1_perRow: 0.9235 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2257 - f1_perRow: 0.9068 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2287 - f1_perRow: 0.9193 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2221 - f1_perRow: 0.9086 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2238 - f1_perRow: 0.9172 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2218 - f1_perRow: 0.9119 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2201 - f1_perRow: 0.9171 - f1_perClass: 0.0218 - acc: 0.9980\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2189 - f1_perRow: 0.9107 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2197 - f1_perRow: 0.9139 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2205 - f1_perRow: 0.9086 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2248 - f1_perRow: 0.9262 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2263 - f1_perRow: 0.9031 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2193 - f1_perRow: 0.9214 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2222 - f1_perRow: 0.9031 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2239 - f1_perRow: 0.9230 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2262 - f1_perRow: 0.9042 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2251 - f1_perRow: 0.9184 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2239 - f1_perRow: 0.9099 - f1_perClass: 0.0217 - acc: 0.9980\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2215 - f1_perRow: 0.9177 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2223 - f1_perRow: 0.9041 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2177 - f1_perRow: 0.9254 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2222 - f1_perRow: 0.9070 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2293 - f1_perRow: 0.9130 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2222 - f1_perRow: 0.9140 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2186 - f1_perRow: 0.9142 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2193 - f1_perRow: 0.9092 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2170 - f1_perRow: 0.9171 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2159 - f1_perRow: 0.9100 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2229 - f1_perRow: 0.9200 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2143 - f1_perRow: 0.9120 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2251 - f1_perRow: 0.9103 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2197 - f1_perRow: 0.9199 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.2153 - f1_perRow: 0.9109 - f1_perClass: 0.0218 - acc: 0.9979\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.2250 - f1_perRow: 0.9100 - f1_perClass: 0.0217 - acc: 0.9978\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2236 - f1_perRow: 0.9102 - f1_perClass: 0.0217 - acc: 0.9979\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.2282 - f1_perRow: 0.9133 - f1_perClass: 0.0216 - acc: 0.9978\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.2265 - f1_perRow: 0.9097 - f1_perClass: 0.0218 - acc: 0.9978\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 80s 1ms/step - loss: 6.2895 - f1_perRow: 0.0397 - f1_perClass: 0.0069 - acc: 0.7982\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.7678 - f1_perRow: 0.0780 - f1_perClass: 0.0055 - acc: 0.9638\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.6531 - f1_perRow: 0.0801 - f1_perClass: 0.0055 - acc: 0.9638\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.6290 - f1_perRow: 0.0884 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.6248 - f1_perRow: 0.0805 - f1_perClass: 0.0055 - acc: 0.9638\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5897 - f1_perRow: 0.0806 - f1_perClass: 0.0052 - acc: 0.9638\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5712 - f1_perRow: 0.0866 - f1_perClass: 0.0058 - acc: 0.9638\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5695 - f1_perRow: 0.0867 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5486 - f1_perRow: 0.0900 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5340 - f1_perRow: 0.0871 - f1_perClass: 0.0057 - acc: 0.9638\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5416 - f1_perRow: 0.0919 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5203 - f1_perRow: 0.0870 - f1_perClass: 0.0056 - acc: 0.9638\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5251 - f1_perRow: 0.0920 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5255 - f1_perRow: 0.0955 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5165 - f1_perRow: 0.0908 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.5152 - f1_perRow: 0.0975 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5272 - f1_perRow: 0.0917 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5132 - f1_perRow: 0.0904 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5085 - f1_perRow: 0.0925 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5086 - f1_perRow: 0.0931 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.5015 - f1_perRow: 0.0928 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4985 - f1_perRow: 0.0940 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5124 - f1_perRow: 0.0965 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4986 - f1_perRow: 0.0954 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.5018 - f1_perRow: 0.0941 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4940 - f1_perRow: 0.0910 - f1_perClass: 0.0057 - acc: 0.9638\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.5372 - f1_perRow: 0.0960 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5000 - f1_perRow: 0.0969 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.5451 - f1_perRow: 0.0943 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.5367 - f1_perRow: 0.0833 - f1_perClass: 0.0052 - acc: 0.9638\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.5127 - f1_perRow: 0.0986 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4817 - f1_perRow: 0.0913 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.5133 - f1_perRow: 0.0984 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4948 - f1_perRow: 0.0994 - f1_perClass: 0.0068 - acc: 0.9638\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4950 - f1_perRow: 0.0901 - f1_perClass: 0.0057 - acc: 0.9638\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4887 - f1_perRow: 0.0927 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4704 - f1_perRow: 0.0992 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4992 - f1_perRow: 0.0986 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4905 - f1_perRow: 0.0917 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4728 - f1_perRow: 0.0922 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4886 - f1_perRow: 0.1022 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4784 - f1_perRow: 0.0959 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4752 - f1_perRow: 0.0957 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4693 - f1_perRow: 0.0964 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4621 - f1_perRow: 0.0987 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 3s 44us/step - loss: 2.4889 - f1_perRow: 0.0971 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4569 - f1_perRow: 0.0952 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4706 - f1_perRow: 0.0978 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4674 - f1_perRow: 0.0956 - f1_perClass: 0.0063 - acc: 0.9638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4606 - f1_perRow: 0.0972 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4727 - f1_perRow: 0.0965 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.5053 - f1_perRow: 0.0917 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4915 - f1_perRow: 0.0963 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4806 - f1_perRow: 0.0923 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4715 - f1_perRow: 0.0955 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4670 - f1_perRow: 0.0954 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4632 - f1_perRow: 0.0979 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4597 - f1_perRow: 0.1009 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4625 - f1_perRow: 0.0934 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4871 - f1_perRow: 0.1010 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4946 - f1_perRow: 0.0999 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4881 - f1_perRow: 0.0914 - f1_perClass: 0.0057 - acc: 0.9638\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4558 - f1_perRow: 0.0977 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4768 - f1_perRow: 0.1042 - f1_perClass: 0.0073 - acc: 0.9638\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4570 - f1_perRow: 0.0908 - f1_perClass: 0.0057 - acc: 0.9638\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4671 - f1_perRow: 0.1058 - f1_perClass: 0.0071 - acc: 0.9638\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4641 - f1_perRow: 0.0979 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4837 - f1_perRow: 0.0915 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4634 - f1_perRow: 0.0983 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4570 - f1_perRow: 0.0963 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4417 - f1_perRow: 0.0999 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4544 - f1_perRow: 0.0974 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4713 - f1_perRow: 0.1021 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4720 - f1_perRow: 0.0951 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4646 - f1_perRow: 0.0994 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4521 - f1_perRow: 0.0960 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4392 - f1_perRow: 0.0984 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4354 - f1_perRow: 0.1023 - f1_perClass: 0.0068 - acc: 0.9638\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4504 - f1_perRow: 0.0999 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4449 - f1_perRow: 0.0966 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4606 - f1_perRow: 0.0983 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4619 - f1_perRow: 0.0937 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4587 - f1_perRow: 0.0983 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4664 - f1_perRow: 0.1050 - f1_perClass: 0.0074 - acc: 0.9638\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4518 - f1_perRow: 0.0968 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4564 - f1_perRow: 0.0937 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.5010 - f1_perRow: 0.1066 - f1_perClass: 0.0079 - acc: 0.9638\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.5023 - f1_perRow: 0.0844 - f1_perClass: 0.0052 - acc: 0.9638\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4896 - f1_perRow: 0.1030 - f1_perClass: 0.0073 - acc: 0.9638\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4678 - f1_perRow: 0.0935 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4606 - f1_perRow: 0.0973 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4472 - f1_perRow: 0.1014 - f1_perClass: 0.0068 - acc: 0.9638\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4489 - f1_perRow: 0.1016 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4529 - f1_perRow: 0.0932 - f1_perClass: 0.0058 - acc: 0.9638\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4518 - f1_perRow: 0.1041 - f1_perClass: 0.0072 - acc: 0.9638\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4532 - f1_perRow: 0.0948 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4380 - f1_perRow: 0.0985 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4357 - f1_perRow: 0.1049 - f1_perClass: 0.0071 - acc: 0.9638\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4425 - f1_perRow: 0.0958 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.4523 - f1_perRow: 0.1027 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4392 - f1_perRow: 0.0986 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4470 - f1_perRow: 0.0993 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4387 - f1_perRow: 0.0984 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4339 - f1_perRow: 0.0999 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4214 - f1_perRow: 0.1025 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4411 - f1_perRow: 0.1032 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4338 - f1_perRow: 0.0974 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4385 - f1_perRow: 0.1031 - f1_perClass: 0.0068 - acc: 0.9638\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4256 - f1_perRow: 0.1026 - f1_perClass: 0.0068 - acc: 0.9638\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 2.4500 - f1_perRow: 0.1001 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4455 - f1_perRow: 0.0953 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4353 - f1_perRow: 0.0994 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4454 - f1_perRow: 0.1063 - f1_perClass: 0.0074 - acc: 0.9638\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4348 - f1_perRow: 0.0965 - f1_perClass: 0.0061 - acc: 0.9638\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4449 - f1_perRow: 0.1000 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4554 - f1_perRow: 0.1037 - f1_perClass: 0.0073 - acc: 0.9638\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4599 - f1_perRow: 0.0929 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4449 - f1_perRow: 0.1022 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4435 - f1_perRow: 0.0986 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4295 - f1_perRow: 0.1028 - f1_perClass: 0.0068 - acc: 0.9638\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4414 - f1_perRow: 0.0999 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4394 - f1_perRow: 0.0992 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4299 - f1_perRow: 0.1041 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4285 - f1_perRow: 0.1001 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4327 - f1_perRow: 0.1017 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4405 - f1_perRow: 0.0989 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4499 - f1_perRow: 0.1032 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4384 - f1_perRow: 0.0977 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4291 - f1_perRow: 0.1007 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4347 - f1_perRow: 0.1054 - f1_perClass: 0.0071 - acc: 0.9638\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4288 - f1_perRow: 0.1012 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4320 - f1_perRow: 0.0996 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4186 - f1_perRow: 0.1031 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4321 - f1_perRow: 0.1015 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4580 - f1_perRow: 0.0977 - f1_perClass: 0.0064 - acc: 0.9638\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4437 - f1_perRow: 0.1024 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4298 - f1_perRow: 0.0967 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4530 - f1_perRow: 0.1085 - f1_perClass: 0.0075 - acc: 0.9638\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4480 - f1_perRow: 0.0961 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4450 - f1_perRow: 0.1026 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4331 - f1_perRow: 0.0996 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4335 - f1_perRow: 0.0995 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4510 - f1_perRow: 0.1038 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4471 - f1_perRow: 0.0975 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4483 - f1_perRow: 0.1021 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4431 - f1_perRow: 0.1068 - f1_perClass: 0.0074 - acc: 0.9638\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4497 - f1_perRow: 0.0926 - f1_perClass: 0.0056 - acc: 0.9638\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4482 - f1_perRow: 0.1127 - f1_perClass: 0.0080 - acc: 0.9638\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4596 - f1_perRow: 0.0955 - f1_perClass: 0.0058 - acc: 0.9638\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4584 - f1_perRow: 0.1045 - f1_perClass: 0.0072 - acc: 0.9638\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4399 - f1_perRow: 0.0953 - f1_perClass: 0.0059 - acc: 0.9638\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4245 - f1_perRow: 0.1066 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4468 - f1_perRow: 0.1053 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4270 - f1_perRow: 0.1034 - f1_perClass: 0.0069 - acc: 0.9639\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4358 - f1_perRow: 0.0994 - f1_perClass: 0.0063 - acc: 0.9638\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4107 - f1_perRow: 0.1025 - f1_perClass: 0.0066 - acc: 0.9638\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4346 - f1_perRow: 0.1049 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4325 - f1_perRow: 0.1048 - f1_perClass: 0.0070 - acc: 0.9639\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4289 - f1_perRow: 0.0974 - f1_perClass: 0.0060 - acc: 0.9638\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4124 - f1_perRow: 0.1081 - f1_perClass: 0.0072 - acc: 0.9639\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4423 - f1_perRow: 0.1024 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4467 - f1_perRow: 0.1036 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4302 - f1_perRow: 0.1015 - f1_perClass: 0.0066 - acc: 0.9639\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4213 - f1_perRow: 0.1019 - f1_perClass: 0.0065 - acc: 0.9638\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4255 - f1_perRow: 0.1030 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4225 - f1_perRow: 0.1046 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4177 - f1_perRow: 0.1021 - f1_perClass: 0.0065 - acc: 0.9639\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4145 - f1_perRow: 0.1029 - f1_perClass: 0.0066 - acc: 0.9639\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4391 - f1_perRow: 0.1030 - f1_perClass: 0.0066 - acc: 0.9639\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4326 - f1_perRow: 0.1056 - f1_perClass: 0.0071 - acc: 0.9639\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4140 - f1_perRow: 0.1002 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4290 - f1_perRow: 0.1104 - f1_perClass: 0.0075 - acc: 0.9639\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4306 - f1_perRow: 0.0988 - f1_perClass: 0.0061 - acc: 0.9639\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4223 - f1_perRow: 0.1063 - f1_perClass: 0.0070 - acc: 0.9639\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4204 - f1_perRow: 0.1016 - f1_perClass: 0.0064 - acc: 0.9639\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4191 - f1_perRow: 0.1101 - f1_perClass: 0.0074 - acc: 0.9639\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4247 - f1_perRow: 0.1009 - f1_perClass: 0.0063 - acc: 0.9640\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4318 - f1_perRow: 0.1039 - f1_perClass: 0.0068 - acc: 0.9639\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4208 - f1_perRow: 0.1032 - f1_perClass: 0.0066 - acc: 0.9639\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4173 - f1_perRow: 0.1069 - f1_perClass: 0.0071 - acc: 0.9639\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4503 - f1_perRow: 0.0993 - f1_perClass: 0.0062 - acc: 0.9638\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4407 - f1_perRow: 0.1069 - f1_perClass: 0.0071 - acc: 0.9639\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4231 - f1_perRow: 0.1057 - f1_perClass: 0.0068 - acc: 0.9639\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4362 - f1_perRow: 0.1016 - f1_perClass: 0.0064 - acc: 0.9639\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4367 - f1_perRow: 0.1051 - f1_perClass: 0.0069 - acc: 0.9638\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4178 - f1_perRow: 0.1056 - f1_perClass: 0.0069 - acc: 0.9639\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4277 - f1_perRow: 0.1016 - f1_perClass: 0.0063 - acc: 0.9639\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4324 - f1_perRow: 0.1121 - f1_perClass: 0.0079 - acc: 0.9640\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4264 - f1_perRow: 0.0974 - f1_perClass: 0.0057 - acc: 0.9639\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4219 - f1_perRow: 0.1079 - f1_perClass: 0.0072 - acc: 0.9639\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4290 - f1_perRow: 0.1060 - f1_perClass: 0.0070 - acc: 0.9638\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4184 - f1_perRow: 0.1033 - f1_perClass: 0.0067 - acc: 0.9638\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 2.4154 - f1_perRow: 0.1030 - f1_perClass: 0.0065 - acc: 0.9639\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4200 - f1_perRow: 0.1063 - f1_perClass: 0.0069 - acc: 0.9639\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 2.4090 - f1_perRow: 0.1062 - f1_perClass: 0.0069 - acc: 0.9639\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 2.4100 - f1_perRow: 0.1051 - f1_perClass: 0.0066 - acc: 0.9639\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4287 - f1_perRow: 0.1077 - f1_perClass: 0.0073 - acc: 0.9639\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4152 - f1_perRow: 0.1046 - f1_perClass: 0.0066 - acc: 0.9640\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 2.4303 - f1_perRow: 0.1066 - f1_perClass: 0.0068 - acc: 0.9639\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 2.4332 - f1_perRow: 0.1051 - f1_perClass: 0.0070 - acc: 0.9639\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 80s 1ms/step - loss: 4.4164 - f1_perRow: 0.0045 - f1_perClass: 0.0013 - acc: 0.8861\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 1.0244 - f1_perRow: 0.0242 - f1_perClass: 5.7558e-04 - acc: 0.9917\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.8310 - f1_perRow: 0.0542 - f1_perClass: 5.8331e-04 - acc: 0.9917\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.7401 - f1_perRow: 0.0854 - f1_perClass: 0.0015 - acc: 0.9917\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6779 - f1_perRow: 0.1051 - f1_perClass: 0.0012 - acc: 0.9917\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6523 - f1_perRow: 0.1214 - f1_perClass: 0.0018 - acc: 0.9917\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6401 - f1_perRow: 0.1502 - f1_perClass: 0.0016 - acc: 0.9917\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6058 - f1_perRow: 0.1666 - f1_perClass: 0.0022 - acc: 0.9917\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6028 - f1_perRow: 0.1910 - f1_perClass: 0.0022 - acc: 0.9921\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.5898 - f1_perRow: 0.2040 - f1_perClass: 0.0025 - acc: 0.9932\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5738 - f1_perRow: 0.2447 - f1_perClass: 0.0026 - acc: 0.9931\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5753 - f1_perRow: 0.2650 - f1_perClass: 0.0031 - acc: 0.9932\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5692 - f1_perRow: 0.2568 - f1_perClass: 0.0028 - acc: 0.9935\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5531 - f1_perRow: 0.2968 - f1_perClass: 0.0029 - acc: 0.9937\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5492 - f1_perRow: 0.2947 - f1_perClass: 0.0031 - acc: 0.9937\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5460 - f1_perRow: 0.3009 - f1_perClass: 0.0030 - acc: 0.9938\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5494 - f1_perRow: 0.3175 - f1_perClass: 0.0032 - acc: 0.9937\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5452 - f1_perRow: 0.2938 - f1_perClass: 0.0030 - acc: 0.9938\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5427 - f1_perRow: 0.3292 - f1_perClass: 0.0033 - acc: 0.9937\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5322 - f1_perRow: 0.3218 - f1_perClass: 0.0032 - acc: 0.9938\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5342 - f1_perRow: 0.3017 - f1_perClass: 0.0032 - acc: 0.9939\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5365 - f1_perRow: 0.3318 - f1_perClass: 0.0033 - acc: 0.9938\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5279 - f1_perRow: 0.3240 - f1_perClass: 0.0032 - acc: 0.9939\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5256 - f1_perRow: 0.3214 - f1_perClass: 0.0033 - acc: 0.9939\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5275 - f1_perRow: 0.3398 - f1_perClass: 0.0033 - acc: 0.9938\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5331 - f1_perRow: 0.3107 - f1_perClass: 0.0031 - acc: 0.9939\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5341 - f1_perRow: 0.3372 - f1_perClass: 0.0034 - acc: 0.9938\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5351 - f1_perRow: 0.3212 - f1_perClass: 0.0031 - acc: 0.9939\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5350 - f1_perRow: 0.3261 - f1_perClass: 0.0033 - acc: 0.9939\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5287 - f1_perRow: 0.3241 - f1_perClass: 0.0032 - acc: 0.9940\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5291 - f1_perRow: 0.3367 - f1_perClass: 0.0033 - acc: 0.9939\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5243 - f1_perRow: 0.3281 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5193 - f1_perRow: 0.3256 - f1_perClass: 0.0032 - acc: 0.9940\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5222 - f1_perRow: 0.3408 - f1_perClass: 0.0033 - acc: 0.9939\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5169 - f1_perRow: 0.3413 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5175 - f1_perRow: 0.3420 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5213 - f1_perRow: 0.3435 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5144 - f1_perRow: 0.3382 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5185 - f1_perRow: 0.3349 - f1_perClass: 0.0033 - acc: 0.9939\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5162 - f1_perRow: 0.3580 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5130 - f1_perRow: 0.3372 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5145 - f1_perRow: 0.3383 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5114 - f1_perRow: 0.3450 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5122 - f1_perRow: 0.3421 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5062 - f1_perRow: 0.3548 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5112 - f1_perRow: 0.3424 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5168 - f1_perRow: 0.3370 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5150 - f1_perRow: 0.3474 - f1_perClass: 0.0033 - acc: 0.9939\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.5136 - f1_perRow: 0.3406 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5117 - f1_perRow: 0.3376 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5188 - f1_perRow: 0.3196 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5334 - f1_perRow: 0.3640 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5120 - f1_perRow: 0.3331 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5236 - f1_perRow: 0.3429 - f1_perClass: 0.0032 - acc: 0.9940\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5126 - f1_perRow: 0.3527 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5110 - f1_perRow: 0.3339 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5053 - f1_perRow: 0.3587 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5148 - f1_perRow: 0.3419 - f1_perClass: 0.0036 - acc: 0.9940\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5109 - f1_perRow: 0.3465 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5006 - f1_perRow: 0.3496 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5087 - f1_perRow: 0.3537 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5085 - f1_perRow: 0.3564 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5060 - f1_perRow: 0.3377 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5045 - f1_perRow: 0.3501 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4972 - f1_perRow: 0.3616 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5062 - f1_perRow: 0.3613 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5028 - f1_perRow: 0.3387 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4971 - f1_perRow: 0.3589 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5061 - f1_perRow: 0.3564 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5038 - f1_perRow: 0.3540 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5099 - f1_perRow: 0.3508 - f1_perClass: 0.0034 - acc: 0.9940\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5060 - f1_perRow: 0.3585 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5058 - f1_perRow: 0.3479 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5104 - f1_perRow: 0.3538 - f1_perClass: 0.0033 - acc: 0.9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5043 - f1_perRow: 0.3561 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5026 - f1_perRow: 0.3596 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.5080 - f1_perRow: 0.3548 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4947 - f1_perRow: 0.3522 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4992 - f1_perRow: 0.3604 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4995 - f1_perRow: 0.3611 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.5028 - f1_perRow: 0.3634 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5065 - f1_perRow: 0.3448 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5090 - f1_perRow: 0.3541 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5137 - f1_perRow: 0.3479 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5076 - f1_perRow: 0.3448 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5053 - f1_perRow: 0.3530 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5055 - f1_perRow: 0.3580 - f1_perClass: 0.0035 - acc: 0.9940\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4985 - f1_perRow: 0.3560 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5081 - f1_perRow: 0.3514 - f1_perClass: 0.0034 - acc: 0.9939\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4990 - f1_perRow: 0.3608 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5003 - f1_perRow: 0.3560 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5118 - f1_perRow: 0.3659 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4990 - f1_perRow: 0.3434 - f1_perClass: 0.0038 - acc: 0.9941\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5177 - f1_perRow: 0.3688 - f1_perClass: 0.0033 - acc: 0.9940\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.5004 - f1_perRow: 0.3524 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4957 - f1_perRow: 0.3658 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5027 - f1_perRow: 0.3472 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5018 - f1_perRow: 0.3764 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5003 - f1_perRow: 0.3483 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4980 - f1_perRow: 0.3640 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5012 - f1_perRow: 0.3622 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4971 - f1_perRow: 0.3581 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4986 - f1_perRow: 0.3679 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4969 - f1_perRow: 0.3529 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4970 - f1_perRow: 0.3519 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4930 - f1_perRow: 0.3654 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4956 - f1_perRow: 0.3591 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4957 - f1_perRow: 0.3551 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4921 - f1_perRow: 0.3634 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4982 - f1_perRow: 0.3741 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4924 - f1_perRow: 0.3572 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4948 - f1_perRow: 0.3511 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4978 - f1_perRow: 0.3697 - f1_perClass: 0.0036 - acc: 0.9940\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4951 - f1_perRow: 0.3688 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4940 - f1_perRow: 0.3517 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4990 - f1_perRow: 0.3686 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4959 - f1_perRow: 0.3533 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4956 - f1_perRow: 0.3482 - f1_perClass: 0.0037 - acc: 0.9940\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5040 - f1_perRow: 0.3836 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4994 - f1_perRow: 0.3453 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5095 - f1_perRow: 0.3725 - f1_perClass: 0.0036 - acc: 0.9940\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4945 - f1_perRow: 0.3592 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4960 - f1_perRow: 0.3500 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4959 - f1_perRow: 0.3682 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4960 - f1_perRow: 0.3615 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4872 - f1_perRow: 0.3687 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4976 - f1_perRow: 0.3572 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4908 - f1_perRow: 0.3843 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4944 - f1_perRow: 0.3469 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5040 - f1_perRow: 0.3556 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5185 - f1_perRow: 0.3498 - f1_perClass: 0.0039 - acc: 0.9939\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.5065 - f1_perRow: 0.3456 - f1_perClass: 0.0032 - acc: 0.9941\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5061 - f1_perRow: 0.3533 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.5022 - f1_perRow: 0.3534 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4952 - f1_perRow: 0.3566 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5014 - f1_perRow: 0.3601 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4948 - f1_perRow: 0.3553 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4946 - f1_perRow: 0.3630 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4985 - f1_perRow: 0.3417 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4912 - f1_perRow: 0.3768 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4920 - f1_perRow: 0.3621 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4870 - f1_perRow: 0.3663 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4878 - f1_perRow: 0.3724 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4917 - f1_perRow: 0.3647 - f1_perClass: 0.0038 - acc: 0.9941\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4897 - f1_perRow: 0.3748 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4993 - f1_perRow: 0.3545 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4902 - f1_perRow: 0.3696 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.5075 - f1_perRow: 0.3711 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4939 - f1_perRow: 0.3493 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4890 - f1_perRow: 0.3676 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4992 - f1_perRow: 0.3609 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4854 - f1_perRow: 0.3667 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4911 - f1_perRow: 0.3523 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4845 - f1_perRow: 0.3747 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.5032 - f1_perRow: 0.3546 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4879 - f1_perRow: 0.3724 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4919 - f1_perRow: 0.3704 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4954 - f1_perRow: 0.3564 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4902 - f1_perRow: 0.3767 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4935 - f1_perRow: 0.3558 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4948 - f1_perRow: 0.3632 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4891 - f1_perRow: 0.3650 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4936 - f1_perRow: 0.3571 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4918 - f1_perRow: 0.3756 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4946 - f1_perRow: 0.3592 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4937 - f1_perRow: 0.3572 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4977 - f1_perRow: 0.3726 - f1_perClass: 0.0033 - acc: 0.9941\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4892 - f1_perRow: 0.3557 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4913 - f1_perRow: 0.3722 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4942 - f1_perRow: 0.3594 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4930 - f1_perRow: 0.3594 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4886 - f1_perRow: 0.3759 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4927 - f1_perRow: 0.3579 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4956 - f1_perRow: 0.3536 - f1_perClass: 0.0038 - acc: 0.9941\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.5039 - f1_perRow: 0.3653 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4933 - f1_perRow: 0.3793 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.4927 - f1_perRow: 0.3579 - f1_perClass: 0.0038 - acc: 0.9941\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4944 - f1_perRow: 0.3656 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4944 - f1_perRow: 0.3441 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4939 - f1_perRow: 0.3763 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4885 - f1_perRow: 0.3621 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4857 - f1_perRow: 0.3733 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4947 - f1_perRow: 0.3562 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4985 - f1_perRow: 0.3535 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4923 - f1_perRow: 0.3763 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4875 - f1_perRow: 0.3654 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4917 - f1_perRow: 0.3663 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4964 - f1_perRow: 0.3488 - f1_perClass: 0.0038 - acc: 0.9941\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4947 - f1_perRow: 0.3841 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4913 - f1_perRow: 0.3474 - f1_perClass: 0.0037 - acc: 0.9942\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4862 - f1_perRow: 0.3798 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4980 - f1_perRow: 0.3697 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4989 - f1_perRow: 0.3452 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4958 - f1_perRow: 0.3663 - f1_perClass: 0.0036 - acc: 0.9942\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.4887 - f1_perRow: 0.3752 - f1_perClass: 0.0036 - acc: 0.9941\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4878 - f1_perRow: 0.3521 - f1_perClass: 0.0034 - acc: 0.9941\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.4915 - f1_perRow: 0.3582 - f1_perClass: 0.0038 - acc: 0.9941\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4918 - f1_perRow: 0.3806 - f1_perClass: 0.0035 - acc: 0.9942\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.4902 - f1_perRow: 0.3561 - f1_perClass: 0.0035 - acc: 0.9941\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.4883 - f1_perRow: 0.3734 - f1_perClass: 0.0037 - acc: 0.9941\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 84s 1ms/step - loss: 13.1004 - f1_perRow: 0.5583 - f1_perClass: 0.3441 - acc: 0.6197\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 10.5653 - f1_perRow: 0.6382 - f1_perClass: 0.3703 - acc: 0.7393\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 8.4396 - f1_perRow: 0.7210 - f1_perClass: 0.3985 - acc: 0.8213\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 6.9504 - f1_perRow: 0.7723 - f1_perClass: 0.4169 - acc: 0.8594\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 6.2679 - f1_perRow: 0.7945 - f1_perClass: 0.4281 - acc: 0.8700\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.9122 - f1_perRow: 0.8105 - f1_perClass: 0.4325 - acc: 0.8785\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.7085 - f1_perRow: 0.8156 - f1_perClass: 0.4346 - acc: 0.8827\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.6486 - f1_perRow: 0.8163 - f1_perClass: 0.4351 - acc: 0.8828\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.5675 - f1_perRow: 0.8175 - f1_perClass: 0.4346 - acc: 0.8834\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.4725 - f1_perRow: 0.8235 - f1_perClass: 0.4385 - acc: 0.8858\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.4260 - f1_perRow: 0.8215 - f1_perClass: 0.4360 - acc: 0.8856\n",
      "Epoch 12/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.3981 - f1_perRow: 0.8234 - f1_perClass: 0.4374 - acc: 0.8877\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.3622 - f1_perRow: 0.8263 - f1_perClass: 0.4390 - acc: 0.8880\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.3449 - f1_perRow: 0.8276 - f1_perClass: 0.4393 - acc: 0.8890\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.3248 - f1_perRow: 0.8252 - f1_perClass: 0.4372 - acc: 0.8900\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.3029 - f1_perRow: 0.8267 - f1_perClass: 0.4381 - acc: 0.8903\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 5.2807 - f1_perRow: 0.8299 - f1_perClass: 0.4399 - acc: 0.8902\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.2900 - f1_perRow: 0.8245 - f1_perClass: 0.4364 - acc: 0.8906\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.3010 - f1_perRow: 0.8281 - f1_perClass: 0.4383 - acc: 0.8901\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.2701 - f1_perRow: 0.8308 - f1_perClass: 0.4407 - acc: 0.8908\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.2598 - f1_perRow: 0.8316 - f1_perClass: 0.4404 - acc: 0.8902\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.2414 - f1_perRow: 0.8265 - f1_perClass: 0.4376 - acc: 0.8916\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.2401 - f1_perRow: 0.8321 - f1_perClass: 0.4405 - acc: 0.8914\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.2060 - f1_perRow: 0.8333 - f1_perClass: 0.4416 - acc: 0.8921\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1916 - f1_perRow: 0.8302 - f1_perClass: 0.4394 - acc: 0.8928\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1741 - f1_perRow: 0.8334 - f1_perClass: 0.4409 - acc: 0.8931\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.1697 - f1_perRow: 0.8323 - f1_perClass: 0.4400 - acc: 0.8929\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1715 - f1_perRow: 0.8315 - f1_perClass: 0.4402 - acc: 0.8924\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.1568 - f1_perRow: 0.8352 - f1_perClass: 0.4422 - acc: 0.8930\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1744 - f1_perRow: 0.8322 - f1_perClass: 0.4401 - acc: 0.8925\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.1658 - f1_perRow: 0.8314 - f1_perClass: 0.4393 - acc: 0.8929\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1492 - f1_perRow: 0.8312 - f1_perClass: 0.4399 - acc: 0.8933\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1534 - f1_perRow: 0.8345 - f1_perClass: 0.4414 - acc: 0.8938\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1393 - f1_perRow: 0.8345 - f1_perClass: 0.4411 - acc: 0.8933\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1356 - f1_perRow: 0.8327 - f1_perClass: 0.4408 - acc: 0.8935\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.1604 - f1_perRow: 0.8353 - f1_perClass: 0.4413 - acc: 0.8935\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1251 - f1_perRow: 0.8345 - f1_perClass: 0.4415 - acc: 0.8933\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1333 - f1_perRow: 0.8333 - f1_perClass: 0.4406 - acc: 0.8935\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1226 - f1_perRow: 0.8314 - f1_perClass: 0.4390 - acc: 0.8933\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1428 - f1_perRow: 0.8337 - f1_perClass: 0.4411 - acc: 0.8934\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.1372 - f1_perRow: 0.8353 - f1_perClass: 0.4416 - acc: 0.8932\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.1341 - f1_perRow: 0.8320 - f1_perClass: 0.4397 - acc: 0.8932\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1037 - f1_perRow: 0.8330 - f1_perClass: 0.4402 - acc: 0.8936\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.1245 - f1_perRow: 0.8338 - f1_perClass: 0.4409 - acc: 0.8937\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.1243 - f1_perRow: 0.8342 - f1_perClass: 0.4408 - acc: 0.8940\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1016 - f1_perRow: 0.8339 - f1_perClass: 0.4409 - acc: 0.8941\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0880 - f1_perRow: 0.8326 - f1_perClass: 0.4398 - acc: 0.8943\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0856 - f1_perRow: 0.8373 - f1_perClass: 0.4424 - acc: 0.8939\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0756 - f1_perRow: 0.8339 - f1_perClass: 0.4408 - acc: 0.8944\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0717 - f1_perRow: 0.8348 - f1_perClass: 0.4409 - acc: 0.8944\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0634 - f1_perRow: 0.8372 - f1_perClass: 0.4423 - acc: 0.8947\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0735 - f1_perRow: 0.8354 - f1_perClass: 0.4415 - acc: 0.8945\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0641 - f1_perRow: 0.8331 - f1_perClass: 0.4398 - acc: 0.8944\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0819 - f1_perRow: 0.8359 - f1_perClass: 0.4415 - acc: 0.8944\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0920 - f1_perRow: 0.8352 - f1_perClass: 0.4412 - acc: 0.8941\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0766 - f1_perRow: 0.8348 - f1_perClass: 0.4411 - acc: 0.8946\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0686 - f1_perRow: 0.8374 - f1_perClass: 0.4429 - acc: 0.8947\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0605 - f1_perRow: 0.8378 - f1_perClass: 0.4426 - acc: 0.8951\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0655 - f1_perRow: 0.8353 - f1_perClass: 0.4414 - acc: 0.8947\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0418 - f1_perRow: 0.8351 - f1_perClass: 0.4410 - acc: 0.8949\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0404 - f1_perRow: 0.8358 - f1_perClass: 0.4413 - acc: 0.8946\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0384 - f1_perRow: 0.8375 - f1_perClass: 0.4424 - acc: 0.8954\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0346 - f1_perRow: 0.8363 - f1_perClass: 0.4416 - acc: 0.8950\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0447 - f1_perRow: 0.8376 - f1_perClass: 0.4426 - acc: 0.8945\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0424 - f1_perRow: 0.8361 - f1_perClass: 0.4412 - acc: 0.8948\n",
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0528 - f1_perRow: 0.8363 - f1_perClass: 0.4414 - acc: 0.8942\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0394 - f1_perRow: 0.8322 - f1_perClass: 0.4391 - acc: 0.8952\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0507 - f1_perRow: 0.8394 - f1_perClass: 0.4437 - acc: 0.8951\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0292 - f1_perRow: 0.8377 - f1_perClass: 0.4426 - acc: 0.8953\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0541 - f1_perRow: 0.8354 - f1_perClass: 0.4410 - acc: 0.8945\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0789 - f1_perRow: 0.8367 - f1_perClass: 0.4417 - acc: 0.8946\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0564 - f1_perRow: 0.8357 - f1_perClass: 0.4416 - acc: 0.8951\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0365 - f1_perRow: 0.8382 - f1_perClass: 0.4430 - acc: 0.8957\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0326 - f1_perRow: 0.8361 - f1_perClass: 0.4419 - acc: 0.8951\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0489 - f1_perRow: 0.8357 - f1_perClass: 0.4408 - acc: 0.8954\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0397 - f1_perRow: 0.8391 - f1_perClass: 0.4437 - acc: 0.8951\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0435 - f1_perRow: 0.8368 - f1_perClass: 0.4416 - acc: 0.8949\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0236 - f1_perRow: 0.8338 - f1_perClass: 0.4397 - acc: 0.8948\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0115 - f1_perRow: 0.8371 - f1_perClass: 0.4422 - acc: 0.8955\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0237 - f1_perRow: 0.8373 - f1_perClass: 0.4420 - acc: 0.8955\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0118 - f1_perRow: 0.8372 - f1_perClass: 0.4417 - acc: 0.8959\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0070 - f1_perRow: 0.8394 - f1_perClass: 0.4435 - acc: 0.8956\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0378 - f1_perRow: 0.8354 - f1_perClass: 0.4408 - acc: 0.8957\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0327 - f1_perRow: 0.8369 - f1_perClass: 0.4421 - acc: 0.8955\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0143 - f1_perRow: 0.8365 - f1_perClass: 0.4417 - acc: 0.8957\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0095 - f1_perRow: 0.8367 - f1_perClass: 0.4416 - acc: 0.8962\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9960 - f1_perRow: 0.8374 - f1_perClass: 0.4420 - acc: 0.8957\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0035 - f1_perRow: 0.8389 - f1_perClass: 0.4429 - acc: 0.8957\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0119 - f1_perRow: 0.8363 - f1_perClass: 0.4414 - acc: 0.8956\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0351 - f1_perRow: 0.8374 - f1_perClass: 0.4422 - acc: 0.8953\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0492 - f1_perRow: 0.8378 - f1_perClass: 0.4424 - acc: 0.8952\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0255 - f1_perRow: 0.8333 - f1_perClass: 0.4395 - acc: 0.8958\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0287 - f1_perRow: 0.8364 - f1_perClass: 0.4414 - acc: 0.8959\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0441 - f1_perRow: 0.8385 - f1_perClass: 0.4428 - acc: 0.8950\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9989 - f1_perRow: 0.8355 - f1_perClass: 0.4410 - acc: 0.8957\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0071 - f1_perRow: 0.8353 - f1_perClass: 0.4404 - acc: 0.8956\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.0026 - f1_perRow: 0.8377 - f1_perClass: 0.4427 - acc: 0.8954\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0040 - f1_perRow: 0.8414 - f1_perClass: 0.4444 - acc: 0.8956\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0025 - f1_perRow: 0.8350 - f1_perClass: 0.4402 - acc: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0009 - f1_perRow: 0.8377 - f1_perClass: 0.4422 - acc: 0.8962\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9958 - f1_perRow: 0.8410 - f1_perClass: 0.4441 - acc: 0.8959\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9797 - f1_perRow: 0.8342 - f1_perClass: 0.4402 - acc: 0.8959\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9785 - f1_perRow: 0.8398 - f1_perClass: 0.4430 - acc: 0.8961\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9684 - f1_perRow: 0.8394 - f1_perClass: 0.4429 - acc: 0.8963\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9579 - f1_perRow: 0.8375 - f1_perClass: 0.4420 - acc: 0.8965\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.0094 - f1_perRow: 0.8386 - f1_perClass: 0.4422 - acc: 0.8964\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 4.9656 - f1_perRow: 0.8377 - f1_perClass: 0.4421 - acc: 0.8963\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9889 - f1_perRow: 0.8385 - f1_perClass: 0.4425 - acc: 0.8963\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 4.9634 - f1_perRow: 0.8398 - f1_perClass: 0.4434 - acc: 0.8965\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9725 - f1_perRow: 0.8395 - f1_perClass: 0.4431 - acc: 0.8959\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0046 - f1_perRow: 0.8379 - f1_perClass: 0.4418 - acc: 0.8958\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9762 - f1_perRow: 0.8354 - f1_perClass: 0.4402 - acc: 0.8959\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9948 - f1_perRow: 0.8416 - f1_perClass: 0.4447 - acc: 0.8961\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 4.9923 - f1_perRow: 0.8346 - f1_perClass: 0.4401 - acc: 0.8961\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0007 - f1_perRow: 0.8386 - f1_perClass: 0.4425 - acc: 0.8959\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0718 - f1_perRow: 0.8345 - f1_perClass: 0.4404 - acc: 0.8950\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0408 - f1_perRow: 0.8377 - f1_perClass: 0.4421 - acc: 0.8945\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0039 - f1_perRow: 0.8386 - f1_perClass: 0.4432 - acc: 0.8956\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9885 - f1_perRow: 0.8376 - f1_perClass: 0.4422 - acc: 0.8955\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 4.9960 - f1_perRow: 0.8380 - f1_perClass: 0.4417 - acc: 0.8958\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 4.9797 - f1_perRow: 0.8399 - f1_perClass: 0.4437 - acc: 0.8959\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9712 - f1_perRow: 0.8385 - f1_perClass: 0.4426 - acc: 0.8960\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9689 - f1_perRow: 0.8398 - f1_perClass: 0.4431 - acc: 0.8965\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0119 - f1_perRow: 0.8350 - f1_perClass: 0.4399 - acc: 0.8957\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.0419 - f1_perRow: 0.8374 - f1_perClass: 0.4423 - acc: 0.8960\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9976 - f1_perRow: 0.8425 - f1_perClass: 0.4453 - acc: 0.8965\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0081 - f1_perRow: 0.8305 - f1_perClass: 0.4370 - acc: 0.8962\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 4.9846 - f1_perRow: 0.8402 - f1_perClass: 0.4440 - acc: 0.8956\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9824 - f1_perRow: 0.8388 - f1_perClass: 0.4428 - acc: 0.8968\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9803 - f1_perRow: 0.8338 - f1_perClass: 0.4392 - acc: 0.8964\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9779 - f1_perRow: 0.8421 - f1_perClass: 0.4448 - acc: 0.8958\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9806 - f1_perRow: 0.8392 - f1_perClass: 0.4430 - acc: 0.8960\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9681 - f1_perRow: 0.8359 - f1_perClass: 0.4409 - acc: 0.8966\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9588 - f1_perRow: 0.8410 - f1_perClass: 0.4436 - acc: 0.8962\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9391 - f1_perRow: 0.8367 - f1_perClass: 0.4410 - acc: 0.8974\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 4.9550 - f1_perRow: 0.8422 - f1_perClass: 0.4446 - acc: 0.8965\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 4.9999 - f1_perRow: 0.8380 - f1_perClass: 0.4421 - acc: 0.8964\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9855 - f1_perRow: 0.8342 - f1_perClass: 0.4390 - acc: 0.8969\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9595 - f1_perRow: 0.8422 - f1_perClass: 0.4449 - acc: 0.8972\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9538 - f1_perRow: 0.8380 - f1_perClass: 0.4418 - acc: 0.8969\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9716 - f1_perRow: 0.8413 - f1_perClass: 0.4442 - acc: 0.8966\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9539 - f1_perRow: 0.8360 - f1_perClass: 0.4407 - acc: 0.8966\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9644 - f1_perRow: 0.8383 - f1_perClass: 0.4421 - acc: 0.8967\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 4.9619 - f1_perRow: 0.8429 - f1_perClass: 0.4447 - acc: 0.8965\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9625 - f1_perRow: 0.8403 - f1_perClass: 0.4439 - acc: 0.8964\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9703 - f1_perRow: 0.8336 - f1_perClass: 0.4388 - acc: 0.8966\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9750 - f1_perRow: 0.8420 - f1_perClass: 0.4443 - acc: 0.8964\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9554 - f1_perRow: 0.8378 - f1_perClass: 0.4422 - acc: 0.8967\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.0289 - f1_perRow: 0.8363 - f1_perClass: 0.4409 - acc: 0.8957\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.0006 - f1_perRow: 0.8410 - f1_perClass: 0.4439 - acc: 0.8967\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 4.9943 - f1_perRow: 0.8380 - f1_perClass: 0.4424 - acc: 0.8961\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9775 - f1_perRow: 0.8391 - f1_perClass: 0.4429 - acc: 0.8965\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9615 - f1_perRow: 0.8381 - f1_perClass: 0.4421 - acc: 0.8968\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9633 - f1_perRow: 0.8389 - f1_perClass: 0.4426 - acc: 0.8967\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 4.9664 - f1_perRow: 0.8390 - f1_perClass: 0.4428 - acc: 0.8965\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9615 - f1_perRow: 0.8392 - f1_perClass: 0.4427 - acc: 0.8965\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9561 - f1_perRow: 0.8396 - f1_perClass: 0.4431 - acc: 0.8973\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9458 - f1_perRow: 0.8360 - f1_perClass: 0.4405 - acc: 0.8974\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9515 - f1_perRow: 0.8416 - f1_perClass: 0.4439 - acc: 0.8970\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9502 - f1_perRow: 0.8390 - f1_perClass: 0.4429 - acc: 0.8969\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9524 - f1_perRow: 0.8379 - f1_perClass: 0.4419 - acc: 0.8972\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9622 - f1_perRow: 0.8423 - f1_perClass: 0.4446 - acc: 0.8965\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9655 - f1_perRow: 0.8375 - f1_perClass: 0.4415 - acc: 0.8967\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9358 - f1_perRow: 0.8371 - f1_perClass: 0.4415 - acc: 0.8969\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 4.9588 - f1_perRow: 0.8427 - f1_perClass: 0.4446 - acc: 0.8965\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 4.9637 - f1_perRow: 0.8382 - f1_perClass: 0.4421 - acc: 0.8963\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 4.9805 - f1_perRow: 0.8378 - f1_perClass: 0.4418 - acc: 0.8961\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 4.9571 - f1_perRow: 0.8408 - f1_perClass: 0.4439 - acc: 0.8967\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.7194 - f1_perRow: 0.8210 - f1_perClass: 0.4389 - acc: 0.8829\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 10.3978 - f1_perRow: 0.7463 - f1_perClass: 0.4048 - acc: 0.8118\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 6.6952 - f1_perRow: 0.8215 - f1_perClass: 0.4390 - acc: 0.8752\n",
      "Epoch 172/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 6.4126 - f1_perRow: 0.8037 - f1_perClass: 0.4302 - acc: 0.8760\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.9877 - f1_perRow: 0.8104 - f1_perClass: 0.4319 - acc: 0.8822\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.6826 - f1_perRow: 0.8198 - f1_perClass: 0.4363 - acc: 0.8871\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.5906 - f1_perRow: 0.8221 - f1_perClass: 0.4373 - acc: 0.8884\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.5111 - f1_perRow: 0.8246 - f1_perClass: 0.4382 - acc: 0.8897\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.4313 - f1_perRow: 0.8256 - f1_perClass: 0.4375 - acc: 0.8901\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.4277 - f1_perRow: 0.8290 - f1_perClass: 0.4399 - acc: 0.8905\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.3751 - f1_perRow: 0.8267 - f1_perClass: 0.4380 - acc: 0.8908\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.3516 - f1_perRow: 0.8295 - f1_perClass: 0.4395 - acc: 0.8912\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.3425 - f1_perRow: 0.8313 - f1_perClass: 0.4405 - acc: 0.8914\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.3223 - f1_perRow: 0.8283 - f1_perClass: 0.4387 - acc: 0.8915\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.3353 - f1_perRow: 0.8314 - f1_perClass: 0.4400 - acc: 0.8910\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.3640 - f1_perRow: 0.8270 - f1_perClass: 0.4374 - acc: 0.8913\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.3045 - f1_perRow: 0.8316 - f1_perClass: 0.4405 - acc: 0.8917\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.2816 - f1_perRow: 0.8327 - f1_perClass: 0.4410 - acc: 0.8917\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.2700 - f1_perRow: 0.8314 - f1_perClass: 0.4397 - acc: 0.8917\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.2712 - f1_perRow: 0.8312 - f1_perClass: 0.4404 - acc: 0.8925\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.2664 - f1_perRow: 0.8352 - f1_perClass: 0.4416 - acc: 0.8928\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.2488 - f1_perRow: 0.8310 - f1_perClass: 0.4399 - acc: 0.8923\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.2361 - f1_perRow: 0.8335 - f1_perClass: 0.4405 - acc: 0.8927\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.2238 - f1_perRow: 0.8314 - f1_perClass: 0.4394 - acc: 0.8929\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.2025 - f1_perRow: 0.8348 - f1_perClass: 0.4415 - acc: 0.8933\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 5.2723 - f1_perRow: 0.8313 - f1_perClass: 0.4392 - acc: 0.8932\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 5.2461 - f1_perRow: 0.8303 - f1_perClass: 0.4393 - acc: 0.8931\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.2106 - f1_perRow: 0.8367 - f1_perClass: 0.4423 - acc: 0.8938\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 5.2049 - f1_perRow: 0.8331 - f1_perClass: 0.4409 - acc: 0.8930\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 5.2057 - f1_perRow: 0.8333 - f1_perClass: 0.4403 - acc: 0.8934\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1968 - f1_perRow: 0.8337 - f1_perClass: 0.4407 - acc: 0.8936\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 5.1767 - f1_perRow: 0.8364 - f1_perClass: 0.4421 - acc: 0.8940\n",
      "Epoch 1/200\n",
      "57867/57867 [==============================] - 83s 1ms/step - loss: 4.9784 - f1_perRow: 0.0017 - f1_perClass: 3.7260e-04 - acc: 0.7931\n",
      "Epoch 2/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 1.2875e-09 - f1_perClass: 2.0601e-12 - acc: 0.9979\n",
      "Epoch 3/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 4/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 5/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 6/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 7/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 8/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 9/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 10/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 11/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 13/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 14/200\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 15/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 16/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 17/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 18/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 19/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 20/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 21/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 22/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 23/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 24/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 25/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 26/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 27/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 28/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 29/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 30/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 31/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 32/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 33/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 34/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 35/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 36/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 37/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 38/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 39/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 40/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 41/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 42/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 43/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 44/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 45/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 46/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 47/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 48/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 49/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 50/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 51/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 52/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 53/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 54/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 55/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 56/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 57/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 58/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 59/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 60/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 61/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 62/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 63/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 64/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 65/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 67/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 68/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 69/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 70/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 71/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 72/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 73/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 74/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 75/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 76/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 77/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 78/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 79/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 80/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 81/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 82/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 83/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 84/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 85/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 86/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 87/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 88/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 89/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 90/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 91/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 92/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 93/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 94/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 95/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 96/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 97/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 98/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 99/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 100/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 101/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 102/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 103/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 104/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 105/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 106/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 107/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 108/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 109/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 110/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 111/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 112/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 113/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 114/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 115/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 116/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 117/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 118/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 119/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 120/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 121/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 122/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 123/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 124/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 125/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 126/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 127/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 128/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 129/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 130/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 131/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 132/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 133/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 134/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 135/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 136/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 137/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 138/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 139/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 140/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 141/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 142/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 143/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 144/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 145/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 146/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 147/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 148/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 149/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 150/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 151/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 152/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 153/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 154/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 155/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 156/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 157/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 158/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 159/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 160/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 161/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 162/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 163/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 164/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 165/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 166/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 167/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 168/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 169/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 170/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 171/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 173/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 174/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 175/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 176/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 177/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 178/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 179/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 180/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 181/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 182/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 183/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 184/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 185/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 186/200\n",
      "57867/57867 [==============================] - 2s 42us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 187/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 188/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 189/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 190/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 191/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 192/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 193/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 194/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 195/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 196/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 197/200\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 198/200\n",
      "57867/57867 [==============================] - 2s 43us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 199/200\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n",
      "Epoch 200/200\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 0.6796 - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.9979\n"
     ]
    }
   ],
   "source": [
    "#split model\n",
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "#splitting data\n",
    "X=x_lstm_prossed_train2\n",
    "y=y_lstm_prossed_train\n",
    "a,b,c,d,e,f,g,h,ii,jj,k,l,m,n,o,p=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "print(len(y_lstm_prossed_train[0]))\n",
    "for i in range(0,len(y_lstm_prossed_train)):\n",
    "    a.append(y_lstm_prossed_train[i][0])\n",
    "    b.append(y_lstm_prossed_train[i][1])\n",
    "    c.append(y_lstm_prossed_train[i][2])\n",
    "    d.append(y_lstm_prossed_train[i][3])\n",
    "    e.append(y_lstm_prossed_train[i][4])\n",
    "    f.append(y_lstm_prossed_train[i][5])\n",
    "    g.append(y_lstm_prossed_train[i][6])\n",
    "    h.append(y_lstm_prossed_train[i][7])\n",
    "    ii.append(y_lstm_prossed_train[i][8])\n",
    "    jj.append(y_lstm_prossed_train[i][9])\n",
    "    k.append(y_lstm_prossed_train[i][10])\n",
    "    l.append(y_lstm_prossed_train[i][11])\n",
    "    m.append(y_lstm_prossed_train[i][12])\n",
    "    n.append(y_lstm_prossed_train[i][13])\n",
    "    o.append(y_lstm_prossed_train[i][14])\n",
    "    p.append(y_lstm_prossed_train[i][15])\n",
    "    \n",
    "zzzz=[]    \n",
    "zzzz.append(np.array(a))\n",
    "zzzz.append(np.array(b))\n",
    "zzzz.append(np.array(c))\n",
    "zzzz.append(np.array(d))\n",
    "zzzz.append(np.array(e))\n",
    "zzzz.append(np.array(f))\n",
    "zzzz.append(np.array(g))\n",
    "zzzz.append(np.array(h))\n",
    "zzzz.append(np.array(ii))\n",
    "zzzz.append(np.array(jj))\n",
    "zzzz.append(np.array(k))\n",
    "zzzz.append(np.array(l))\n",
    "zzzz.append(np.array(m))\n",
    "zzzz.append(np.array(n))\n",
    "zzzz.append(np.array(o))\n",
    "zzzz.append(np.array(p))\n",
    "\n",
    "\n",
    "for i in range(0,16):\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "    # lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "    lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "    # td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "    # dout_1  = Dropout(0.1)(td_1)\n",
    "    dout_1  = Dropout(0.1)(lstm_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "    # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "    lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "    dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "    # fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "    fl_out_cnn = Flatten()(out)\n",
    "\n",
    "    # out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "    out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "    dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "    dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "    dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "    # fl2  = Flatten()(out_new)\n",
    "\n",
    "    out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "    toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "    toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "    service_output = Dense(1, activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "    losses = {\n",
    "    #     \"service_output\": f1_loss_perClass ,\n",
    "        \"service_output\": f1_loss_perRow ,\n",
    "        \"service_output\": \"binary_crossentropy\",\n",
    "    }\n",
    "    lossWeights = {#\"service_output\": 20,\n",
    "                   \"service_output\": 30.0 ,\n",
    "        \"service_output\": 20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "    model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "    # model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    hist2 = model2.fit(x_lstm_prossed_train2, zzzz[i], epochs=200, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "    model2.save('number'+str(i)+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(loss=losses,loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=5e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=16500, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=f1_loss, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=3500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM-sigmoid-withRemovedClasses\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4aa1e57ef0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "# plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=load_model( \"LSTM_withSigmoid_LargeData_F1_E100_B500_MSE_False\"  \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n",
      "(32069, 16)\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.333     0.250     0.286         6 2/32057/6/4\n",
      "                      activity     0.999      0.000       nan     0.000        48 0/32021/0/48\n",
      "                       battery     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "                        button     1.000      0.857     0.857     0.857         7 6/32061/1/1\n",
      "              colorTemperature     1.000        nan     0.000     0.000         0 0/32067/2/0\n",
      "                       contact     0.999      0.615     0.842     0.711        78 48/31982/9/30\n",
      "                         level     1.000      0.519     0.875     0.651        27 14/32040/2/13\n",
      "                          lock     0.998      0.571     0.154     0.242        14 8/32011/44/6\n",
      "                        motion     0.966      0.015     0.941     0.029      1099 16/30969/1/1083\n",
      "                          ping     0.997      1.000     0.988     0.994      6975 6972/25008/86/3\n",
      "                        status     0.999      0.820     0.759     0.788        50 41/32006/13/9\n",
      "                        switch     1.000      0.826     1.000     0.905        23 19/32046/0/4\n",
      "                   temperature     0.953      0.009     0.700     0.018      1512 14/30551/6/1498\n",
      "                     threeAxis     1.000      0.500     0.286     0.364         8 4/32051/10/4\n",
      "                       unknown     0.889      0.992     0.867     0.925     22337 22169/6326/3406/168\n",
      "                         water     1.000        nan       nan       nan         0 0/32069/0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.987      0.441     0.532     0.423     32069 0/0/0/0\n",
      "Exact Match ACC : 0.88621 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 811 (0.025)%\n",
      "Total ZXeros in Test : 158 (0.005)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n",
      "(19968, 16)\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.351     0.667     0.460        57 20/19901/10/37\n",
      "                      activity     0.999      0.000       nan     0.000        19 0/19949/0/19\n",
      "                       battery     1.000      0.000       nan     0.000         7 0/19961/0/7\n",
      "                        button     1.000      0.643     0.750     0.692        14 9/19951/3/5\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         6 4/19962/0/2\n",
      "                       contact     0.995      0.580     0.857     0.692       176 102/19775/17/74\n",
      "                         level     0.999      0.222     0.500     0.308        27 6/19935/6/21\n",
      "                          lock     0.998      0.771     0.409     0.535        35 27/19894/39/8\n",
      "                        motion     0.981      0.003     0.100     0.005       371 1/19588/9/370\n",
      "                          ping     0.997      0.998     0.989     0.993      4842 4832/15070/56/10\n",
      "                        status     0.997      0.765     0.784     0.774       119 91/19824/25/28\n",
      "                        switch     1.000      0.667     0.933     0.778        21 14/19946/1/7\n",
      "                   temperature     0.941      0.000     0.000     0.000      1168 0/18797/3/1168\n",
      "                     threeAxis     0.997      0.476     0.508     0.492        63 30/19876/29/33\n",
      "                       unknown     0.890      0.991     0.864     0.923     13305 13181/4590/2073/124\n",
      "                         water     1.000        nan       nan       nan         0 0/19968/0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.987      0.446     0.523     0.466     19968 0/0/0/0\n",
      "Exact Match ACC : 0.88442 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 92 (0.005)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n",
      "(9109, 16)\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.280     0.778     0.412        25 7/9082/2/18\n",
      "                      activity     0.998      0.000       nan     0.000        21 0/9088/0/21\n",
      "                       battery     1.000      0.000       nan     0.000         4 0/9105/0/4\n",
      "                        button     1.000      0.667     0.500     0.571         3 2/9104/2/1\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/9109/0/0\n",
      "                       contact     0.996      0.564     0.880     0.688        78 44/9025/6/34\n",
      "                         level     0.999      0.250     0.600     0.353        12 3/9095/2/9\n",
      "                          lock     0.997      0.545     0.429     0.480        22 12/9071/16/10\n",
      "                        motion     0.976      0.000     0.000     0.000       218 0/8887/4/218\n",
      "                          ping     0.995      0.997     0.985     0.991      2237 2230/6837/35/7\n",
      "                        status     0.996      0.640     0.653     0.646        50 32/9042/17/18\n",
      "                        switch     1.000      0.500     1.000     0.667         6 3/9103/0/3\n",
      "                   temperature     0.931      0.000     0.000     0.000       630 0/8478/1/630\n",
      "                     threeAxis     0.997      0.440     0.407     0.423        25 11/9068/16/14\n",
      "                       unknown     0.879      0.991     0.849     0.914      5948 5892/2112/1049/56\n",
      "                         water     1.000        nan       nan       nan         0 0/9109/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.985      0.367     0.443     0.384      9109 0/0/0/0\n",
      "Exact Match ACC : 0.87232 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Records : 9109 \n",
      "Total ZXeros in True : 168 (0.018)%\n",
      "Total ZXeros in Test : 48 (0.005)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "(6404, 16)\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.375     0.789     0.508        40 15/6360/4/25\n",
      "                      activity     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "                       battery     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                        button     0.997      0.700     1.000     0.824        60 42/6344/0/18\n",
      "              colorTemperature     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                       contact     0.986      0.486     1.000     0.654       175 85/6229/0/90\n",
      "                         level     0.991      0.212     0.824     0.337        66 14/6335/3/52\n",
      "                          lock     0.999        nan     0.000     0.000         0 0/6399/5/0\n",
      "                        motion     0.977      0.000     0.000     0.000       145 0/6254/5/145\n",
      "                          ping     0.998      0.998     0.995     0.997      2307 2303/4085/12/4\n",
      "                        status     0.997      0.835     1.000     0.910       103 86/6301/0/17\n",
      "                        switch     0.998      0.500     0.750     0.600        24 12/6376/4/12\n",
      "                   temperature     0.967      0.000     0.000     0.000       203 0/6195/6/203\n",
      "                     threeAxis     0.994      0.478     0.579     0.524        46 22/6342/16/24\n",
      "                       unknown     0.913      0.996     0.868     0.928      3558 3544/2306/540/14\n",
      "                         water     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.988      0.349     0.488     0.393      6404 0/0/0/0\n",
      "Exact Match ACC : 0.90053 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 80 (0.012)%\n",
      "Total ZXeros in Test : 21 (0.003)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    makeReadable( classes=classes, confidance=0.5,data=lstm_tests[i][0],gt=lstm_tests[i][1],model=model2,path=test_names[i],x=lstm_tests[i][0])\n",
    "    \n",
    "#     lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ------------- do not go any further :) ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[1][0])\n",
    "lstm_pred__ = np.array(list(lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred__ = np.array(list(lstm_pred))\n",
    "print_info( lstm_tests[1][1], lstm_pred__, classes , confidance=0.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1] :\n",
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [1] :\n",
    "# for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.992)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_train, y_lstm_prossed_train, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in lstm_pred  if  np.sum(x) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM_withSigmoid_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( y_lstm_prossed_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1]), len(y_lstm_prossed_test  ) , len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1])/len(y_lstm_prossed_test  ) *1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x  in  pred if np.sum(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lstm_prossed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_for_raun( pred   ):\n",
    "    pp = pred\n",
    "    pp[pp>=0.5] = 1\n",
    "    pp[pp<0.5] = 0\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if np.sum( do_for_raun(x) )==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if  do_for_raun(x)[20] ==1 or do_for_raun(x)[21] ==1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_test) + len(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
