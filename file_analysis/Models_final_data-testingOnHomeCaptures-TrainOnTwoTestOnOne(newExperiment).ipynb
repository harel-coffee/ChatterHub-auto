{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp, includeDirection = False , TrimAt= 15 ):\n",
    "    if includeDirection:\n",
    "        return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1)  for x in inp ][:15])\n",
    "    else:\n",
    "        return np.array([ int(x[\"packet_length\"])  for x in inp ][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S'):\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "58958 57867\n",
      "loading from test files\n",
      "found files :  3\n",
      "32069 32069\n",
      "19968 19968\n",
      "6404 6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57867, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "        \n",
    "#     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "#         y_data = json.load(f)\n",
    "\n",
    "#     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "#         x_data = json.load(f)\n",
    "  \n",
    "    if len( y_data ) != len(x_data) :\n",
    "        print( pick )\n",
    "        \n",
    "    \n",
    "    x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , Mapping=Mapper )\n",
    "    \n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    test_files = sorted(glob.glob( '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' ))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/', fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/', fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "\n",
    "        x_test.append(t_x)\n",
    "        y_test.append(t_y)\n",
    "        y_test_service.append(t_z)\n",
    "            \n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58958"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acceleration',\n",
       " 'activity',\n",
       " 'battery',\n",
       " 'button',\n",
       " 'colorTemperature',\n",
       " 'contact',\n",
       " 'level',\n",
       " 'lock',\n",
       " 'motion',\n",
       " 'ping',\n",
       " 'status',\n",
       " 'switch',\n",
       " 'temperature',\n",
       " 'threeAxis',\n",
       " 'unknown',\n",
       " 'water']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.unique(  np.concatenate( y_train  )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'acceleration'), (1, 'activity'), (2, 'battery'), (3, 'button'), (4, 'colorTemperature'), (5, 'contact'), (6, 'level'), (7, 'lock'), (8, 'motion'), (9, 'ping'), (10, 'status'), (11, 'switch'), (12, 'temperature'), (13, 'threeAxis'), (14, 'unknown'), (15, 'water')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'ping'),\n",
       " (10, 'status'),\n",
       " (11, 'switch'),\n",
       " (12, 'temperature'),\n",
       " (13, 'threeAxis'),\n",
       " (14, 'unknown'),\n",
       " (15, 'water')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (i , classes[i]) for i in range( len(classes) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean_event( inp, return_clean= True  ):\n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'lock-unlocked' not in inp and 'on/off-XXX' not in inp and 'raw-XXX' not in inp and 'read_attr_-_raw-XXX' not in inp\n",
    "    else:\n",
    "        return  'lock-locked' in inp or 'lock-unlocked'  in inp or 'on/off-XXX' in inp or  'raw-XXX' in inp  or 'read_attr_-_raw-XXX' in inp \n",
    "    \n",
    "def is_clean_service( inp, return_clean= True  ):\n",
    "    \n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'unknown' not in inp and 'read_attr_-_raw' not in inp #and 'ping' not in inp \n",
    "    else:\n",
    "        return  'no_logs' in inp or  'unknown' in inp  or 'read_attr_-_raw' in inp #or 'ping' in inp \n",
    "#     return  \"contact-open\" not in inp and 'contact-closed' not in inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toKeep = [ i for i in range(len(y_train)) if is_clean_event( y_train[i]) ] if Mapper=='SE' else [ i for i in range(len(y_train)) if is_clean_service( y_train[i]) ]\n",
    "x_train= [ x_train[i] for i in toKeep ]\n",
    "y_train= [ y_train[i] for i in toKeep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(x_test)):\n",
    "    toChange= [ i for i in range(len(y_test[j])) if is_clean_service( y_test[j][i], False) ]\n",
    "    y_test[j] = [ (y_test[j][i] if i not in toChange else np.array( ['none'])) for i in range(len(y_test[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.remove('read_attr_-_raw-XXX')\n",
    "# classes.remove('on/off-XXX')\n",
    "# classes.remove('raw-XXX')\n",
    "# classes.remove('lock-unlocked')\n",
    "# classes.remove('lock-locked')\n",
    "\n",
    "\n",
    "# classes.remove('read_attr_-_raw')\n",
    "# classes.remove('on/off')\n",
    "# classes.remove('raw')\n",
    "classes.remove('unknown')\n",
    "\n",
    "# classes.remove('lock')\n",
    "# # classes.remove('lock')\n",
    "\n",
    "\n",
    "# classes.remove('switch-on')\n",
    "\n",
    "\n",
    "\n",
    "service_classes= [\"\",\"\",\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,classes=None, twoD= False ):\n",
    "#  y data \n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    for x in y_data:\n",
    "        temp = np.zeros( len(classes) )\n",
    "        for y in x : \n",
    "            if y in classes:\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "        y_data_categorical.append( temp )\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        if twoD:\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size**2 - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size**2:\n",
    "                    temp.append( 0 )\n",
    "\n",
    "                x_data_temp.append(np.array( temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "            x_data_temp = np.array( x_data_temp )\n",
    "            x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "        else: \n",
    "            temp = [] \n",
    "            lst = list(x)\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size:\n",
    "                    temp.append( 0 )\n",
    "                \n",
    "                x_data_temp.append(np.array( temp))\n",
    "            \n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / 1500.0\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[1][1]\n",
    "    tn = inp[0][0]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "#     F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "\n",
    "def acc_match( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    " \n",
    "    return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "\n",
    "\n",
    "# def acc_none_zero ( true, pred ):\n",
    "    \n",
    "\n",
    "def acc_match_wierd( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    "    level = 6 \n",
    "    switch = 11\n",
    "    threeAxis=13\n",
    "    accel = 0 \n",
    "    status=10\n",
    "    contact=5\n",
    "    \n",
    "    counter  = 0 \n",
    "    for i in range( len (true) ):\n",
    "        if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "            counter+=1\n",
    "        else : \n",
    "            t_rec = np.array(list( pred[i]))\n",
    "            \n",
    "            if true[i][level]==1 and true[i][switch]==1 and t_rec[level]==1 :\n",
    "                t_rec[switch]=1\n",
    "            \n",
    "            if true[i][threeAxis]==1 and true[i][accel]==1 and t_rec[threeAxis]==1:\n",
    "                t_rec[accel] =1\n",
    "            \n",
    "            if true[i][status]==1 and true[i][contact]==1 and t_rec[status]==1:\n",
    "                t_rec[contact]=1\n",
    "#             print(t_rec , true[i])    \n",
    "            if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                counter+=1   \n",
    "            \n",
    "             \n",
    "            \n",
    "    \n",
    "    return counter*1.0 / len(true)\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidance=0.5 ):\n",
    "    \n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidance] = 1\n",
    "    pred[pred<confidance] = 0\n",
    "    \n",
    "#     acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %16s\"  %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    \n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn ))\n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "#     print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_readable_results ( inp , classes , conffidance=True):\n",
    "    ret = [] \n",
    "    inp =inp.astype(int)\n",
    "    for xx in range(len(inp)) :\n",
    "        u = inp[xx]\n",
    "        temp = []\n",
    "        for j in range(len(u)) : \n",
    "            if u[j] >0:\n",
    "                temp.append(classes[j])\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def makeReadable( model , data, gt, path , classes, x, confidance=0.7):\n",
    "    pred_temp = model.predict(data)\n",
    "    print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "    print( len(classes ), len( pred_temp[0] ) )\n",
    "    xcc= make_readable_results(pred_temp , classes)\n",
    "    y_gt = make_readable_results( gt, classes )\n",
    "    temp_dic = {} \n",
    "    for pick in range(len(xcc)): \n",
    "        temp_dic[ pick +1 ] =  { 'seq': str(data[pick]),\n",
    "                               'pred': xcc[pick],\n",
    "                                'true':y_gt[pick]\n",
    "                               }   \n",
    "\n",
    "    with open(path , 'w') as f:\n",
    "        json.dump(temp_dic , f, indent=4)\n",
    "\n",
    "\n",
    "# def makeReadable( model , data, gt, path , classes, confidance=0.7, x):\n",
    "#     pred_temp = model.predict( data)\n",
    "#     print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "#     xcc= make_readable_results( pred_temp , classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] = xcc[pick]  \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "# x_random_forest_test,y_random_forest_test, _ = pre_process_raw( x_test[0], y_test[0] , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "# x,y, classes = pre_process_raw( x_data, y_data , dim_size, zero_pad=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_random_forest_train, y_random_forest_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))\n",
    "# from sklearn import metrics\n",
    "# scores = cross_val_score(clf, x_random_forest_train, y_random_forest_train, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_tests[i][0])\n",
    "    print_info( rf_tests[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeReadable( data=rf_tests[0][0], model=clf, classes=classes, confidance=0.7,gt=rf_tests[0][1], path='sk_home_out.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( \"mean : %f \\nstd: %f\\nmax:%f\" %( scores.mean(), scores.std(), scores.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts  = np.unique(np.array([ len(x) for x  in x_train ]), return_counts=True)\n",
    "# # np.sort( cnts[1] )\n",
    "# cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =15\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=False, classes=service_classes) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([290,  99, 412,  99, 290,  99, 412,  99, 290,  99, 412,  99,   0,\n",
       "         0,   0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lstm_prossed_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32069 32069\n",
      "19968 19968\n",
      "6404 6404\n"
     ]
    }
   ],
   "source": [
    "for i in range( len(lstm_tests) ):\n",
    "    print( len( lstm_tests[i][0] ), len( lstm_tests_services[i][0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_lstm_prossed_train,axis=1)\n",
    "\n",
    "for tt  in range( len(lstm_tests) ):\n",
    "    lstm_tests[tt]= (lstm_tests[tt][0].reshape(len(lstm_tests[tt][0]),dim_size,1) , lstm_tests[tt][1],lstm_tests_services[tt][1] )\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_lstm_prossed_train.reshape(len(x_lstm_prossed_train),dim_size,1)\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60562.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_s_lstm_processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 15, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)               (None, 15, 128)       512         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 15, 128)       512         conv1d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 15, 128)       0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)               (None, 15, 128)       512         input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 15, 128)       0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 15, 128)       512         conv1d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)               (None, 15, 128)       49280       dropout_50[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 15, 128)       0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)               (None, 15, 128)       49280       conv1d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)             (None, 15, 128)       0           activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 15, 128)       512         conv1d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)               (None, 15, 128)       49280       dropout_45[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 15, 128)       0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                   (None, 15, 100)       40800       input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                   (None, 15, 100)       91600       conv1d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 15, 128)       0           activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                   (None, 15, 40)        22560       lstm_15[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 15, 128)       12928       lstm_14[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)               (None, 15, 128)       49280       dropout_51[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 15, 128)       5248        lstm_16[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 15, 128)       16512       dense_59[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)               (None, 15, 128)       49280       conv1d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 15, 128)       16512       dense_63[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 15, 128)       16512       dense_60[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 15, 128)       512         conv1d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 15, 128)       16512       dense_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)             (None, 15, 128)       0           dense_61[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 15, 128)       0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)             (None, 15, 128)       0           dense_65[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 1920)          0           dropout_46[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 15, 128)       0           activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 1920)          0           dropout_48[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 128)           245888      flatten_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)               (None, 15, 128)       49280       dropout_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_66 (Dense)                 (None, 128)           245888      flatten_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 128)           0           dense_62[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)             (None, 1920)          0           conv1d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 128)           0           dense_66[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)          (None, 2176)          0           dropout_47[0][0]                 \n",
      "                                                                   flatten_19[0][0]                 \n",
      "                                                                   dropout_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_67 (Dense)                 (None, 128)           278656      mergerguy[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_68 (Dense)                 (None, 128)           16512       dense_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_69 (Dense)                 (None, 128)           16512       dense_68[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "to_service1 (Dense)              (None, 130)           16770       dense_69[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "to_service2 (Dense)              (None, 130)           17030       to_service1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "service_output (Dense)           (None, 16)            2096        to_service2[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,377,288\n",
      "Trainable params: 1,376,264\n",
      "Non-trainable params: 1,024\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 22s - loss: 49.1524 - f1_perRow: 0.0933 - f1_perClass: 0.1965 - acc: 0.3774    \n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 3s - loss: 30.8489 - f1_perRow: 0.1142 - f1_perClass: 0.4948 - acc: 0.5391     \n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 3s - loss: 27.8990 - f1_perRow: 0.1516 - f1_perClass: 0.5125 - acc: 0.5869     \n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 3s - loss: 26.7529 - f1_perRow: 0.1892 - f1_perClass: 0.5164 - acc: 0.4659     \n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 3s - loss: 25.9082 - f1_perRow: 0.2148 - f1_perClass: 0.5348 - acc: 0.4661     \n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 3s - loss: 25.3332 - f1_perRow: 0.2447 - f1_perClass: 0.5361 - acc: 0.4667     \n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 3s - loss: 24.7458 - f1_perRow: 0.2643 - f1_perClass: 0.5444 - acc: 0.4668     \n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 3s - loss: 21.3852 - f1_perRow: 0.2949 - f1_perClass: 0.6257 - acc: 0.4668     \n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 3s - loss: 20.2604 - f1_perRow: 0.3063 - f1_perClass: 0.6381 - acc: 0.4668     \n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 3s - loss: 19.7270 - f1_perRow: 0.3191 - f1_perClass: 0.6535 - acc: 0.4668     \n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 3s - loss: 19.3881 - f1_perRow: 0.3182 - f1_perClass: 0.6570 - acc: 0.4668     \n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 3s - loss: 19.0961 - f1_perRow: 0.3356 - f1_perClass: 0.6626 - acc: 0.4668     \n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.9244 - f1_perRow: 0.3384 - f1_perClass: 0.6625 - acc: 0.4668     \n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.8106 - f1_perRow: 0.3415 - f1_perClass: 0.6651 - acc: 0.4668     \n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.6817 - f1_perRow: 0.3486 - f1_perClass: 0.6670 - acc: 0.4668     \n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.5726 - f1_perRow: 0.3475 - f1_perClass: 0.6663 - acc: 0.4668     \n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.6102 - f1_perRow: 0.3502 - f1_perClass: 0.6644 - acc: 0.4668     \n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.4613 - f1_perRow: 0.3507 - f1_perClass: 0.6645 - acc: 0.4664     \n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.3901 - f1_perRow: 0.3553 - f1_perClass: 0.6681 - acc: 0.4611     \n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.2092 - f1_perRow: 0.3616 - f1_perClass: 0.6719 - acc: 0.4493     \n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.1503 - f1_perRow: 0.3644 - f1_perClass: 0.6695 - acc: 0.4345     \n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.3288 - f1_perRow: 0.3629 - f1_perClass: 0.6671 - acc: 0.4261     \n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.5151 - f1_perRow: 0.3601 - f1_perClass: 0.6676 - acc: 0.4162     \n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.2811 - f1_perRow: 0.3641 - f1_perClass: 0.6716 - acc: 0.4127     \n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.1296 - f1_perRow: 0.3729 - f1_perClass: 0.6725 - acc: 0.3966     \n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.0205 - f1_perRow: 0.3688 - f1_perClass: 0.6698 - acc: 0.3975     \n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.9548 - f1_perRow: 0.3766 - f1_perClass: 0.6714 - acc: 0.3942     \n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.8951 - f1_perRow: 0.3801 - f1_perClass: 0.6759 - acc: 0.3916     \n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.8784 - f1_perRow: 0.3826 - f1_perClass: 0.6742 - acc: 0.3923     \n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.9859 - f1_perRow: 0.3802 - f1_perClass: 0.6705 - acc: 0.3910     \n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7933 - f1_perRow: 0.3805 - f1_perClass: 0.6754 - acc: 0.3895     \n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7837 - f1_perRow: 0.3876 - f1_perClass: 0.6764 - acc: 0.3881     \n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7477 - f1_perRow: 0.3872 - f1_perClass: 0.6741 - acc: 0.3945     \n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7010 - f1_perRow: 0.3860 - f1_perClass: 0.6744 - acc: 0.3957     \n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.0405 - f1_perRow: 0.3885 - f1_perClass: 0.6727 - acc: 0.3900     \n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.9037 - f1_perRow: 0.3831 - f1_perClass: 0.6756 - acc: 0.3884     \n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.0578 - f1_perRow: 0.3847 - f1_perClass: 0.6715 - acc: 0.4012     \n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.9087 - f1_perRow: 0.3813 - f1_perClass: 0.6728 - acc: 0.3888     \n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.6762 - f1_perRow: 0.3932 - f1_perClass: 0.6764 - acc: 0.4008     \n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.6124 - f1_perRow: 0.3922 - f1_perClass: 0.6769 - acc: 0.4063     \n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7053 - f1_perRow: 0.3961 - f1_perClass: 0.6749 - acc: 0.4023     \n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.5882 - f1_perRow: 0.3936 - f1_perClass: 0.6789 - acc: 0.4061     \n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7691 - f1_perRow: 0.4027 - f1_perClass: 0.6775 - acc: 0.4281     \n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7901 - f1_perRow: 0.3906 - f1_perClass: 0.6751 - acc: 0.4184     \n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7848 - f1_perRow: 0.3865 - f1_perClass: 0.6746 - acc: 0.4368     \n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7167 - f1_perRow: 0.3971 - f1_perClass: 0.6771 - acc: 0.4261     \n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.6398 - f1_perRow: 0.3960 - f1_perClass: 0.6749 - acc: 0.4207     \n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.6101 - f1_perRow: 0.3965 - f1_perClass: 0.6775 - acc: 0.4174     \n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.5413 - f1_perRow: 0.4001 - f1_perClass: 0.6767 - acc: 0.4261     \n",
      "Epoch 50/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.3944 - f1_perRow: 0.4029 - f1_perClass: 0.6783 - acc: 0.4268     \n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.9363 - f1_perRow: 0.4017 - f1_perClass: 0.6617 - acc: 0.4342     \n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 3s - loss: 22.7714 - f1_perRow: 0.3468 - f1_perClass: 0.6205 - acc: 0.6536     \n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 3s - loss: 22.8420 - f1_perRow: 0.3252 - f1_perClass: 0.5952 - acc: 0.6809     \n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 3s - loss: 22.4774 - f1_perRow: 0.3170 - f1_perClass: 0.5941 - acc: 0.6842     \n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 3s - loss: 22.0080 - f1_perRow: 0.3424 - f1_perClass: 0.5981 - acc: 0.6831     \n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 3s - loss: 19.9162 - f1_perRow: 0.3391 - f1_perClass: 0.6491 - acc: 0.6823     \n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.7395 - f1_perRow: 0.3668 - f1_perClass: 0.6664 - acc: 0.6818     \n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.8767 - f1_perRow: 0.3671 - f1_perClass: 0.6626 - acc: 0.6825     \n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 3s - loss: 18.7099 - f1_perRow: 0.3546 - f1_perClass: 0.6616 - acc: 0.6839     \n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.4368 - f1_perRow: 0.3675 - f1_perClass: 0.6660 - acc: 0.6844     \n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.1959 - f1_perRow: 0.3793 - f1_perClass: 0.6691 - acc: 0.6991     \n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.1669 - f1_perRow: 0.3714 - f1_perClass: 0.6670 - acc: 0.6989     \n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.3938 - f1_perRow: 0.3752 - f1_perClass: 0.6660 - acc: 0.7337     \n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.2279 - f1_perRow: 0.3702 - f1_perClass: 0.6715 - acc: 0.7424     \n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.4350 - f1_perRow: 0.3781 - f1_perClass: 0.6883 - acc: 0.7731     \n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.6222 - f1_perRow: 0.3671 - f1_perClass: 0.6670 - acc: 0.6713     \n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.3043 - f1_perRow: 0.3687 - f1_perClass: 0.6630 - acc: 0.6884     \n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.3785 - f1_perRow: 0.3732 - f1_perClass: 0.6672 - acc: 0.6882     \n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.0372 - f1_perRow: 0.3856 - f1_perClass: 0.6719 - acc: 0.6887     \n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.0296 - f1_perRow: 0.3776 - f1_perClass: 0.6673 - acc: 0.6886     \n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.9588 - f1_perRow: 0.3854 - f1_perClass: 0.6692 - acc: 0.6887     \n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7014 - f1_perRow: 0.3847 - f1_perClass: 0.6746 - acc: 0.6896     \n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.8625 - f1_perRow: 0.3875 - f1_perClass: 0.6674 - acc: 0.6912     \n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 3s - loss: 18.0353 - f1_perRow: 0.3851 - f1_perClass: 0.6704 - acc: 0.6904     \n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.8312 - f1_perRow: 0.3757 - f1_perClass: 0.6688 - acc: 0.6899     \n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.6818 - f1_perRow: 0.3909 - f1_perClass: 0.6734 - acc: 0.6912     \n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.5633 - f1_perRow: 0.3968 - f1_perClass: 0.6731 - acc: 0.6917     \n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.5694 - f1_perRow: 0.3980 - f1_perClass: 0.6742 - acc: 0.6906     \n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.4798 - f1_perRow: 0.3980 - f1_perClass: 0.6764 - acc: 0.6927     \n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.7364 - f1_perRow: 0.3863 - f1_perClass: 0.6678 - acc: 0.6915     \n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.8684 - f1_perRow: 0.3991 - f1_perClass: 0.6754 - acc: 0.6941     \n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.6780 - f1_perRow: 0.3878 - f1_perClass: 0.6719 - acc: 0.6947     \n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 3s - loss: 17.5412 - f1_perRow: 0.3915 - f1_perClass: 0.6741 - acc: 0.7128     \n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.8309 - f1_perRow: 0.3914 - f1_perClass: 0.6894 - acc: 0.7485     \n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.8838 - f1_perRow: 0.3979 - f1_perClass: 0.6941 - acc: 0.7500     \n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.8584 - f1_perRow: 0.4072 - f1_perClass: 0.6962 - acc: 0.7494     \n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.7119 - f1_perRow: 0.3918 - f1_perClass: 0.6895 - acc: 0.7526     \n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.6096 - f1_perRow: 0.4103 - f1_perClass: 0.6975 - acc: 0.7496     \n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.8455 - f1_perRow: 0.4068 - f1_perClass: 0.6905 - acc: 0.7521     \n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.8120 - f1_perRow: 0.4022 - f1_perClass: 0.6931 - acc: 0.7509     \n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.7785 - f1_perRow: 0.4047 - f1_perClass: 0.6958 - acc: 0.7519     \n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.6085 - f1_perRow: 0.3964 - f1_perClass: 0.6933 - acc: 0.7513     \n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.5412 - f1_perRow: 0.4101 - f1_perClass: 0.6964 - acc: 0.7529     \n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.6330 - f1_perRow: 0.4079 - f1_perClass: 0.6932 - acc: 0.7512     \n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.6225 - f1_perRow: 0.4161 - f1_perClass: 0.7000 - acc: 0.7524     \n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.5948 - f1_perRow: 0.4040 - f1_perClass: 0.6912 - acc: 0.7553     \n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.6850 - f1_perRow: 0.4091 - f1_perClass: 0.6974 - acc: 0.7575     \n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.5858 - f1_perRow: 0.4041 - f1_perClass: 0.6953 - acc: 0.7666     \n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.3745 - f1_perRow: 0.4107 - f1_perClass: 0.6984 - acc: 0.7671     \n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 3s - loss: 16.1949 - f1_perRow: 0.4214 - f1_perClass: 0.7039 - acc: 0.7665     \n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perClass ,\n",
    "#     \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "#     \"service_output\": 20\n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=5e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.4411 - f1_perRow: 0.4736 - f1_perClass: 0.7360 - acc: 0.8492     \n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.1966 - f1_perRow: 0.4610 - f1_perClass: 0.7253 - acc: 0.8418     \n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 2s - loss: 15.0918 - f1_perRow: 0.4485 - f1_perClass: 0.7257 - acc: 0.8406     \n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.3799 - f1_perRow: 0.4503 - f1_perClass: 0.7259 - acc: 0.8362     \n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.3288 - f1_perRow: 0.4605 - f1_perClass: 0.7332 - acc: 0.8216     \n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.2638 - f1_perRow: 0.4578 - f1_perClass: 0.7269 - acc: 0.8212     \n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.2455 - f1_perRow: 0.4728 - f1_perClass: 0.7335 - acc: 0.8229     \n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.1573 - f1_perRow: 0.4782 - f1_perClass: 0.7270 - acc: 0.8373     \n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.3353 - f1_perRow: 0.4695 - f1_perClass: 0.7321 - acc: 0.8531     \n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0393 - f1_perRow: 0.4765 - f1_perClass: 0.7329 - acc: 0.8251     \n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.3316 - f1_perRow: 0.4770 - f1_perClass: 0.7296 - acc: 0.8288     \n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.4015 - f1_perRow: 0.4663 - f1_perClass: 0.7296 - acc: 0.8445     \n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.6708 - f1_perRow: 0.4631 - f1_perClass: 0.7282 - acc: 0.8387     \n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.3301 - f1_perRow: 0.4435 - f1_perClass: 0.7276 - acc: 0.8229     \n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3285 - f1_perRow: 0.4565 - f1_perClass: 0.7282 - acc: 0.7839     \n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.2862 - f1_perRow: 0.4664 - f1_perClass: 0.7306 - acc: 0.7383     \n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3719 - f1_perRow: 0.4833 - f1_perClass: 0.7364 - acc: 0.8504     \n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1010 - f1_perRow: 0.4719 - f1_perClass: 0.7300 - acc: 0.8443     \n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3549 - f1_perRow: 0.4616 - f1_perClass: 0.7248 - acc: 0.8310     \n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.7966 - f1_perRow: 0.4393 - f1_perClass: 0.7228 - acc: 0.7300     \n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.5492 - f1_perRow: 0.4481 - f1_perClass: 0.7329 - acc: 0.7483     \n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.4086 - f1_perRow: 0.4455 - f1_perClass: 0.7307 - acc: 0.7683     \n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4156 - f1_perRow: 0.4545 - f1_perClass: 0.7352 - acc: 0.8208     \n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 2s - loss: 14.5523 - f1_perRow: 0.4700 - f1_perClass: 0.7367 - acc: 0.7512     \n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3830 - f1_perRow: 0.4530 - f1_perClass: 0.7323 - acc: 0.7825     \n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3265 - f1_perRow: 0.4518 - f1_perClass: 0.7376 - acc: 0.8201     \n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.5511 - f1_perRow: 0.4553 - f1_perClass: 0.7286 - acc: 0.8199     \n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2484 - f1_perRow: 0.4724 - f1_perClass: 0.7407 - acc: 0.8225     \n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2123 - f1_perRow: 0.4699 - f1_perClass: 0.7352 - acc: 0.8209     \n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1427 - f1_perRow: 0.4663 - f1_perClass: 0.7354 - acc: 0.7399     \n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4949 - f1_perRow: 0.4561 - f1_perClass: 0.7360 - acc: 0.7643     \n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4720 - f1_perRow: 0.4688 - f1_perClass: 0.7360 - acc: 0.7909     \n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2547 - f1_perRow: 0.4642 - f1_perClass: 0.7338 - acc: 0.8021     \n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2089 - f1_perRow: 0.4582 - f1_perClass: 0.7353 - acc: 0.8266     \n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1519 - f1_perRow: 0.4687 - f1_perClass: 0.7376 - acc: 0.7774     \n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0720 - f1_perRow: 0.4760 - f1_perClass: 0.7419 - acc: 0.7841     \n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1453 - f1_perRow: 0.4710 - f1_perClass: 0.7378 - acc: 0.7276     \n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2246 - f1_perRow: 0.4622 - f1_perClass: 0.7331 - acc: 0.6997     \n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4581 - f1_perRow: 0.4649 - f1_perClass: 0.7368 - acc: 0.7131     \n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3013 - f1_perRow: 0.4767 - f1_perClass: 0.7356 - acc: 0.8037     \n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1515 - f1_perRow: 0.4668 - f1_perClass: 0.7358 - acc: 0.7358     \n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2313 - f1_perRow: 0.4724 - f1_perClass: 0.7383 - acc: 0.7432     \n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0708 - f1_perRow: 0.4820 - f1_perClass: 0.7363 - acc: 0.8310     \n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0529 - f1_perRow: 0.4829 - f1_perClass: 0.7372 - acc: 0.8163     \n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0933 - f1_perRow: 0.4795 - f1_perClass: 0.7363 - acc: 0.7857     \n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1550 - f1_perRow: 0.4788 - f1_perClass: 0.7402 - acc: 0.7224     \n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4146 - f1_perRow: 0.4688 - f1_perClass: 0.7274 - acc: 0.8094     \n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1799 - f1_perRow: 0.4744 - f1_perClass: 0.7405 - acc: 0.7798     \n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1940 - f1_perRow: 0.4806 - f1_perClass: 0.7367 - acc: 0.7524     \n",
      "Epoch 50/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.5081 - f1_perRow: 0.4627 - f1_perClass: 0.7290 - acc: 0.8074     \n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.8229 - f1_perRow: 0.4601 - f1_perClass: 0.7321 - acc: 0.7251     \n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3762 - f1_perRow: 0.4521 - f1_perClass: 0.7276 - acc: 0.6637     \n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4279 - f1_perRow: 0.4468 - f1_perClass: 0.7334 - acc: 0.8322     \n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2756 - f1_perRow: 0.4530 - f1_perClass: 0.7263 - acc: 0.7203     \n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1406 - f1_perRow: 0.4661 - f1_perClass: 0.7348 - acc: 0.7991     \n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1401 - f1_perRow: 0.4730 - f1_perClass: 0.7370 - acc: 0.8114     \n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1420 - f1_perRow: 0.4703 - f1_perClass: 0.7359 - acc: 0.6731     \n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2928 - f1_perRow: 0.4671 - f1_perClass: 0.7390 - acc: 0.8138     \n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 3s - loss: 14.4538 - f1_perRow: 0.4692 - f1_perClass: 0.7309 - acc: 0.7926     \n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2929 - f1_perRow: 0.4607 - f1_perClass: 0.7327 - acc: 0.7227     \n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.5188 - f1_perRow: 0.4578 - f1_perClass: 0.7333 - acc: 0.8266     \n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2372 - f1_perRow: 0.4613 - f1_perClass: 0.7332 - acc: 0.7148     \n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3521 - f1_perRow: 0.4679 - f1_perClass: 0.7297 - acc: 0.7573     \n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2517 - f1_perRow: 0.4773 - f1_perClass: 0.7370 - acc: 0.8131     \n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0156 - f1_perRow: 0.4834 - f1_perClass: 0.7367 - acc: 0.6622     \n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.9965 - f1_perRow: 0.4772 - f1_perClass: 0.7359 - acc: 0.6354     \n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1183 - f1_perRow: 0.4717 - f1_perClass: 0.7396 - acc: 0.7803     \n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2835 - f1_perRow: 0.4682 - f1_perClass: 0.7301 - acc: 0.7018     \n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4032 - f1_perRow: 0.4799 - f1_perClass: 0.7413 - acc: 0.8020     \n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1199 - f1_perRow: 0.4750 - f1_perClass: 0.7350 - acc: 0.8511     \n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1040 - f1_perRow: 0.4711 - f1_perClass: 0.7337 - acc: 0.7681     \n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1171 - f1_perRow: 0.4765 - f1_perClass: 0.7357 - acc: 0.8211     \n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1543 - f1_perRow: 0.4760 - f1_perClass: 0.7319 - acc: 0.7714     \n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2033 - f1_perRow: 0.4870 - f1_perClass: 0.7369 - acc: 0.7380     \n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4197 - f1_perRow: 0.4671 - f1_perClass: 0.7329 - acc: 0.7548     \n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2080 - f1_perRow: 0.4625 - f1_perClass: 0.7293 - acc: 0.7682     \n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1521 - f1_perRow: 0.4741 - f1_perClass: 0.7328 - acc: 0.6241     \n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0172 - f1_perRow: 0.4802 - f1_perClass: 0.7396 - acc: 0.7742     \n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2518 - f1_perRow: 0.4785 - f1_perClass: 0.7314 - acc: 0.6408     \n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1480 - f1_perRow: 0.4728 - f1_perClass: 0.7331 - acc: 0.7696     \n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0767 - f1_perRow: 0.4732 - f1_perClass: 0.7394 - acc: 0.8388     \n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0888 - f1_perRow: 0.4637 - f1_perClass: 0.7338 - acc: 0.8180     \n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3429 - f1_perRow: 0.4653 - f1_perClass: 0.7352 - acc: 0.7571     \n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4105 - f1_perRow: 0.4632 - f1_perClass: 0.7288 - acc: 0.7652     \n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2441 - f1_perRow: 0.4604 - f1_perClass: 0.7318 - acc: 0.8524     \n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.2480 - f1_perRow: 0.4558 - f1_perClass: 0.7332 - acc: 0.8357     \n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.3694 - f1_perRow: 0.4569 - f1_perClass: 0.7313 - acc: 0.8028     \n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0508 - f1_perRow: 0.4795 - f1_perClass: 0.7391 - acc: 0.6282     \n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.9416 - f1_perRow: 0.4803 - f1_perClass: 0.7346 - acc: 0.6756     \n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0098 - f1_perRow: 0.4762 - f1_perClass: 0.7356 - acc: 0.7006     \n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.9552 - f1_perRow: 0.4773 - f1_perClass: 0.7371 - acc: 0.7889     \n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.7563 - f1_perRow: 0.4893 - f1_perClass: 0.7396 - acc: 0.8314     \n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.8259 - f1_perRow: 0.4900 - f1_perClass: 0.7369 - acc: 0.7985     \n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.9010 - f1_perRow: 0.4878 - f1_perClass: 0.7362 - acc: 0.6930     \n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 3s - loss: 13.8071 - f1_perRow: 0.4919 - f1_perClass: 0.7417 - acc: 0.6589     \n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.1024 - f1_perRow: 0.4878 - f1_perClass: 0.7362 - acc: 0.7705     \n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.0030 - f1_perRow: 0.4786 - f1_perClass: 0.7371 - acc: 0.6125     \n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.6674 - f1_perRow: 0.4550 - f1_perClass: 0.7231 - acc: 0.7015     \n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.5004 - f1_perRow: 0.4518 - f1_perClass: 0.7233 - acc: 0.7619     \n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 3s - loss: 14.4819 - f1_perRow: 0.4616 - f1_perClass: 0.7374 - acc: 0.7997     \n"
     ]
    }
   ],
   "source": [
    "# model2.compile(loss=losses,loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=5e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=13500, shuffle=True, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=f1_loss, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=3500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM-sigmoid-withRemovedClasses\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "# plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-c4aedb9b3813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot_new/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=load_model( \"LSTM_withSigmoid_LargeData_F1_E100_B500_MSE_False\"  \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    makeReadable( classes=classes, confidance=0.7,data=lstm_tests[i][0],gt=lstm_tests[i][1],model=model2,path=test_names[i],x=lstm_tests[i][0])\n",
    "    \n",
    "#     lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.500     0.333     0.400         6 3/32057/6/3\n",
      "                      activity     0.999      0.625     0.638     0.632        48 30/32004/17/18\n",
      "                       battery     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "                        button     1.000      0.714     0.625     0.667         7 5/32059/3/2\n",
      "              colorTemperature     1.000        nan     0.000     0.000         0 0/32066/3/0\n",
      "                       contact     0.999      0.603     0.810     0.691        78 47/31980/11/31\n",
      "                         level     0.999      0.481     0.500     0.491        27 13/32029/13/14\n",
      "                          lock     0.989      0.786     0.030     0.058        14 11/31700/355/3\n",
      "                        motion     0.966      0.016     0.720     0.032      1099 18/30963/7/1081\n",
      "                          ping     0.994      0.999     0.975     0.987      6975 6965/24915/179/10\n",
      "                        status     0.999      0.840     0.764     0.800        50 42/32006/13/8\n",
      "                        switch     1.000      0.870     0.741     0.800        23 20/32039/7/3\n",
      "                   temperature     0.953      0.013     0.400     0.026      1512 20/30527/30/1492\n",
      "                     threeAxis     0.999      0.500     0.235     0.320         8 4/32048/13/4\n",
      "                       unknown     0.698      0.997     0.699     0.822     22337 22267/129/9603/70\n",
      "                         water     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.975      0.496     0.467     0.420     32069 0/0/0/0\n",
      "Exact Match ACC : 0.68331 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 811 (0.025)%\n",
      "Total ZXeros in Test : 54 (0.002)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.351     0.488     0.408        57 20/19890/21/37\n",
      "                      activity     0.999      0.632     0.706     0.667        19 12/19944/5/7\n",
      "                       battery     1.000      0.000     0.000     0.000         7 0/19959/2/7\n",
      "                        button     0.999      0.286     0.800     0.421        14 4/19953/1/10\n",
      "              colorTemperature     1.000      0.667     0.800     0.727         6 4/19961/1/2\n",
      "                       contact     0.996      0.597     0.882     0.712       176 105/19778/14/71\n",
      "                         level     0.998      0.296     0.364     0.327        27 8/19927/14/19\n",
      "                          lock     0.987      0.743     0.097     0.172        35 26/19691/242/9\n",
      "                        motion     0.981      0.003     0.071     0.005       371 1/19584/13/370\n",
      "                          ping     0.995      0.999     0.983     0.990      4842 4835/15040/86/7\n",
      "                        status     0.997      0.773     0.793     0.783       119 92/19825/24/27\n",
      "                        switch     0.999      0.905     0.704     0.792        21 19/19939/8/2\n",
      "                   temperature     0.941      0.000     0.000     0.000      1168 0/18795/5/1168\n",
      "                     threeAxis     0.996      0.476     0.441     0.458        63 30/19867/38/33\n",
      "                       unknown     0.673      0.995     0.672     0.802     13305 13244/204/6459/61\n",
      "                         water     1.000        nan     0.000     0.000         0 0/19966/2/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.973      0.483     0.488     0.454     19968 0/0/0/0\n",
      "Exact Match ACC : 0.65715 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 34 (0.002)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.375     0.714     0.492        40 15/6358/6/25\n",
      "                      activity     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "                       battery     1.000      0.000     0.000     0.000         2 0/6401/1/2\n",
      "                        button     0.992      0.133     1.000     0.235        60 8/6344/0/52\n",
      "              colorTemperature     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                       contact     0.986      0.503     0.989     0.667       175 88/6228/1/87\n",
      "                         level     0.991      0.167     0.688     0.268        66 11/6333/5/55\n",
      "                          lock     0.988        nan     0.000     0.000         0 0/6324/80/0\n",
      "                        motion     0.977      0.000     0.000     0.000       145 0/6257/2/145\n",
      "                          ping     0.996      0.999     0.991     0.995      2307 2304/4075/22/3\n",
      "                        status     0.997      0.835     0.989     0.905       103 86/6300/1/17\n",
      "                        switch     0.997      0.708     0.607     0.654        24 17/6369/11/7\n",
      "                   temperature     0.968      0.000       nan     0.000       203 0/6201/0/203\n",
      "                     threeAxis     0.994      0.457     0.568     0.506        46 21/6342/16/25\n",
      "                       unknown     0.577      0.997     0.568     0.724      3558 3549/144/2702/9\n",
      "                         water     1.000        nan     0.000     0.000         0 0/6403/1/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.966      0.323     0.445     0.340      6404 0/0/0/0\n",
      "Exact Match ACC : 0.55387 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 80 (0.012)%\n",
      "Total ZXeros in Test : 15 (0.002)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "# for i in [1] :\n",
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.351     0.741     0.476        57 20/19904/7/37\n",
      "                      activity     1.000      0.632     0.857     0.727        19 12/19947/2/7\n",
      "                       battery     1.000      0.000       nan     0.000         7 0/19961/0/7\n",
      "                        button     1.000      0.571     0.889     0.696        14 8/19953/1/6\n",
      "              colorTemperature     1.000      0.667     0.800     0.727         6 4/19961/1/2\n",
      "                       contact     0.995      0.580     0.857     0.692       176 102/19775/17/74\n",
      "                         level     0.999      0.222     0.545     0.316        27 6/19936/5/21\n",
      "                          lock     0.997      0.771     0.325     0.458        35 27/19877/56/8\n",
      "                        motion     0.981      0.000     0.000     0.000       371 0/19596/1/371\n",
      "                          ping     0.996      0.995     0.989     0.992      4842 4820/15071/55/22\n",
      "                        status     0.997      0.773     0.780     0.776       119 92/19823/26/27\n",
      "                        switch     1.000      0.714     0.882     0.789        21 15/19945/2/6\n",
      "                   temperature     0.942      0.000       nan     0.000      1168 0/18800/0/1168\n",
      "                     threeAxis     0.997      0.460     0.617     0.527        63 29/19887/18/34\n",
      "                       unknown     0.662      0.992     0.665     0.796     13305 13198/16/6647/107\n",
      "                         water     1.000        nan       nan       nan         0 0/19968/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.973      0.483     0.559     0.498     19968 0/0/0/0\n",
      "Exact Match ACC : 0.65660 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 123 (0.006)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in [1] :\n",
    "# for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.992)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_train, y_lstm_prossed_train, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in lstm_pred  if  np.sum(x) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM_withSigmoid_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( y_lstm_prossed_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1]), len(y_lstm_prossed_test  ) , len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1])/len(y_lstm_prossed_test  ) *1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x  in  pred if np.sum(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lstm_prossed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_for_raun( pred   ):\n",
    "    pp = pred\n",
    "    pp[pp>=0.5] = 1\n",
    "    pp[pp<0.5] = 0\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if np.sum( do_for_raun(x) )==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if  do_for_raun(x)[20] ==1 or do_for_raun(x)[21] ==1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_test) + len(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(new_iot)",
   "language": "python",
   "name": "iot_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
