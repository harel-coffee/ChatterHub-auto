{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp, includeDirection = False , TrimAt= 15 ):\n",
    "    if includeDirection:\n",
    "        return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1)  for x in inp ][:15])\n",
    "    else:\n",
    "        return np.array([ int(x[\"packet_length\"])  for x in inp ][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S'):\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "58958 57867\n",
      "loading from test files\n",
      "found files :  3\n",
      "32069 32069\n",
      "19968 19968\n",
      "6404 6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57867, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "        \n",
    "#     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "#         y_data = json.load(f)\n",
    "\n",
    "#     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "#         x_data = json.load(f)\n",
    "  \n",
    "    if len( y_data ) != len(x_data) :\n",
    "        print( pick )\n",
    "        \n",
    "    \n",
    "    x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , Mapping=Mapper )\n",
    "    \n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    test_files = sorted(glob.glob( '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' ))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/', fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/', fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "\n",
    "        x_test.append(t_x)\n",
    "        y_test.append(t_y)\n",
    "        y_test_service.append(t_z)\n",
    "            \n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.unique(  np.concatenate( y_train  )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'acceleration'), (1, 'activity'), (2, 'battery'), (3, 'button'), (4, 'colorTemperature'), (5, 'contact'), (6, 'level'), (7, 'lock'), (8, 'motion'), (9, 'ping'), (10, 'status'), (11, 'switch'), (12, 'temperature'), (13, 'threeAxis'), (14, 'unknown'), (15, 'water')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'ping'),\n",
       " (10, 'status'),\n",
       " (11, 'switch'),\n",
       " (12, 'temperature'),\n",
       " (13, 'threeAxis'),\n",
       " (14, 'unknown'),\n",
       " (15, 'water')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (i , classes[i]) for i in range( len(classes) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean_event( inp, return_clean= True  ):\n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'lock-unlocked' not in inp and 'on/off-XXX' not in inp and 'raw-XXX' not in inp and 'read_attr_-_raw-XXX' not in inp\n",
    "    else:\n",
    "        return  'lock-locked' in inp or 'lock-unlocked'  in inp or 'on/off-XXX' in inp or  'raw-XXX' in inp  or 'read_attr_-_raw-XXX' in inp \n",
    "    \n",
    "def is_clean_service( inp, return_clean= True  ):\n",
    "    \n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'unknown' not in inp and 'read_attr_-_raw' not in inp #and 'ping' not in inp \n",
    "    else:\n",
    "        return  'no_logs' in inp or  'unknown' in inp  or 'read_attr_-_raw' in inp #or 'ping' in inp \n",
    "#     return  \"contact-open\" not in inp and 'contact-closed' not in inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toKeep = [ i for i in range(len(y_train)) if is_clean_event( y_train[i]) ] if Mapper=='SE' else [ i for i in range(len(y_train)) if is_clean_service( y_train[i]) ]\n",
    "x_train= [ x_train[i] for i in toKeep ]\n",
    "y_train= [ y_train[i] for i in toKeep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(x_test)):\n",
    "    toChange= [ i for i in range(len(y_test[j])) if is_clean_service( y_test[j][i], False) ]\n",
    "    y_test[j] = [ (y_test[j][i] if i not in toChange else np.array( ['none'])) for i in range(len(y_test[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.remove('read_attr_-_raw-XXX')\n",
    "# classes.remove('on/off-XXX')\n",
    "# classes.remove('raw-XXX')\n",
    "# classes.remove('lock-unlocked')\n",
    "# classes.remove('lock-locked')\n",
    "\n",
    "\n",
    "# classes.remove('read_attr_-_raw')\n",
    "# classes.remove('on/off')\n",
    "# classes.remove('raw')\n",
    "classes.remove('unknown')\n",
    "\n",
    "# classes.remove('lock')\n",
    "# # classes.remove('lock')\n",
    "\n",
    "\n",
    "# classes.remove('switch-on')\n",
    "\n",
    "\n",
    "\n",
    "service_classes= [\"\",\"\",\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,classes=None, twoD= False ):\n",
    "#  y data \n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    for x in y_data:\n",
    "        temp = np.zeros( len(classes) )\n",
    "        for y in x : \n",
    "            if y in classes:\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "        y_data_categorical.append( temp )\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        if twoD:\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size**2 - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size**2:\n",
    "                    temp.append( 0 )\n",
    "\n",
    "                x_data_temp.append(np.array( temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "            x_data_temp = np.array( x_data_temp )\n",
    "            x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "        else: \n",
    "            temp = [] \n",
    "            lst = list(x)\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size:\n",
    "                    temp.append( 0 )\n",
    "                \n",
    "                x_data_temp.append(np.array( temp))\n",
    "            \n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / 1500.0\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[1][1]\n",
    "    tn = inp[0][0]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "#     F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "\n",
    "def acc_match( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    " \n",
    "    return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "\n",
    "\n",
    "# def acc_none_zero ( true, pred ):\n",
    "    \n",
    "\n",
    "def acc_match_wierd( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    "    level = 6 \n",
    "    switch = 11\n",
    "    threeAxis=13\n",
    "    accel = 0 \n",
    "    status=10\n",
    "    contact=5\n",
    "    \n",
    "    counter  = 0 \n",
    "    for i in range( len (true) ):\n",
    "        if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "            counter+=1\n",
    "        else : \n",
    "            t_rec = np.array(list( pred[i]))\n",
    "            \n",
    "            if true[i][level]==1 and true[i][switch]==1 and t_rec[level]==1 :\n",
    "                t_rec[switch]=1\n",
    "            \n",
    "            if true[i][threeAxis]==1 and true[i][accel]==1 and t_rec[threeAxis]==1:\n",
    "                t_rec[accel] =1\n",
    "            \n",
    "            if true[i][status]==1 and true[i][contact]==1 and t_rec[status]==1:\n",
    "                t_rec[contact]=1\n",
    "#             print(t_rec , true[i])    \n",
    "            if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                counter+=1   \n",
    "            \n",
    "             \n",
    "            \n",
    "    \n",
    "    return counter*1.0 / len(true)\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidance=0.5 ):\n",
    "    \n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidance] = 1\n",
    "    pred[pred<confidance] = 0\n",
    "    \n",
    "#     acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %16s\"  %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    \n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn ))\n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "#     print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_readable_results ( inp , classes , conffidance=True):\n",
    "    ret = [] \n",
    "    inp =inp.astype(int)\n",
    "    for xx in range(len(inp)) :\n",
    "        u = inp[xx]\n",
    "        temp = []\n",
    "        for j in range(len(u)) : \n",
    "            if u[j] >0:\n",
    "                temp.append(classes[j])\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def makeReadable( model , data, gt, path , classes, x, confidance=0.7):\n",
    "    pred_temp = model.predict(data)\n",
    "    print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "    print( len(classes ), len( pred_temp[0] ) )\n",
    "    xcc= make_readable_results(pred_temp , classes)\n",
    "    y_gt = make_readable_results( gt, classes )\n",
    "    temp_dic = {} \n",
    "    for pick in range(len(xcc)): \n",
    "        temp_dic[ pick +1 ] =  { 'seq': str(data[pick]),\n",
    "                               'pred': xcc[pick],\n",
    "                                'true':y_gt[pick]\n",
    "                               }   \n",
    "\n",
    "    with open(path , 'w') as f:\n",
    "        json.dump(temp_dic , f, indent=4)\n",
    "\n",
    "\n",
    "# def makeReadable( model , data, gt, path , classes, confidance=0.7, x):\n",
    "#     pred_temp = model.predict( data)\n",
    "#     print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "#     xcc= make_readable_results( pred_temp , classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] = xcc[pick]  \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "# x_random_forest_test,y_random_forest_test, _ = pre_process_raw( x_test[0], y_test[0] , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "# x,y, classes = pre_process_raw( x_data, y_data , dim_size, zero_pad=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_random_forest_train, y_random_forest_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))\n",
    "# from sklearn import metrics\n",
    "# scores = cross_val_score(clf, x_random_forest_train, y_random_forest_train, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_tests[i][0])\n",
    "    print_info( rf_tests[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeReadable( data=rf_tests[0][0], model=clf, classes=classes, confidance=0.7,gt=rf_tests[0][1], path='sk_home_out.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( \"mean : %f \\nstd: %f\\nmax:%f\" %( scores.mean(), scores.std(), scores.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts  = np.unique(np.array([ len(x) for x  in x_train ]), return_counts=True)\n",
    "# # np.sort( cnts[1] )\n",
    "# cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =15\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=False, classes=service_classes) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([290,  99, 412,  99, 290,  99, 412,  99, 290,  99, 412,  99,   0,\n",
       "         0,   0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lstm_prossed_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32069 32069\n",
      "19968 19968\n",
      "6404 6404\n"
     ]
    }
   ],
   "source": [
    "for i in range( len(lstm_tests) ):\n",
    "    print( len( lstm_tests[i][0] ), len( lstm_tests_services[i][0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_lstm_prossed_train,axis=1)\n",
    "\n",
    "for tt  in range( len(lstm_tests) ):\n",
    "    lstm_tests[tt]= (lstm_tests[tt][0].reshape(len(lstm_tests[tt][0]),dim_size,1) , lstm_tests[tt][1],lstm_tests_services[tt][1] )\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_lstm_prossed_train.reshape(len(x_lstm_prossed_train),dim_size,1)\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60562.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_s_lstm_processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 15, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)                (None, 15, 128)       512         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 15, 128)       512         conv1d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 15, 128)       0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 15, 128)       0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)                (None, 15, 128)       49280       dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)                (None, 15, 128)       49280       conv1d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 15, 128)       512         conv1d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 15, 128)       0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 15, 60)        14880       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 15, 128)       0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 15, 128)       7808        lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)               (None, 15, 128)       49280       dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 15, 128)       16512       dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)               (None, 15, 128)       49280       conv1d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 15, 128)       16512       dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 15, 128)       512         conv1d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 15, 128)       0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 15, 128)       0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1920)          0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 15, 128)       0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 128)           245888      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)               (None, 15, 128)       49280       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 128)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 1920)          0           conv1d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)          (None, 2048)          0           dropout_7[0][0]                  \n",
      "                                                                   flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 128)           262272      mergerguy[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 128)           16512       dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 128)           16512       dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "to_service1 (Dense)              (None, 130)           16770       dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "to_service2 (Dense)              (None, 130)           17030       to_service1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "service_output (Dense)           (None, 16)            2096        to_service2[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 881,240\n",
      "Trainable params: 880,472\n",
      "Non-trainable params: 768\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 3s - loss: 38.0026 - f1_perRow: 0.1059 - f1_perClass: 0.3952 - acc: 0.4091     \n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 1s - loss: 23.7287 - f1_perRow: 0.1736 - f1_perClass: 0.6043 - acc: 0.4668     \n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 1s - loss: 21.6652 - f1_perRow: 0.2219 - f1_perClass: 0.6265 - acc: 0.4668     \n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 1s - loss: 20.5785 - f1_perRow: 0.2619 - f1_perClass: 0.6399 - acc: 0.4668     \n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 1s - loss: 19.9150 - f1_perRow: 0.2904 - f1_perClass: 0.6483 - acc: 0.4668     \n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 1s - loss: 19.4656 - f1_perRow: 0.3131 - f1_perClass: 0.6561 - acc: 0.4668     \n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 1s - loss: 19.1244 - f1_perRow: 0.3283 - f1_perClass: 0.6613 - acc: 0.4668     \n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 1s - loss: 18.8676 - f1_perRow: 0.3363 - f1_perClass: 0.6650 - acc: 0.4668     \n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 18.2062 - f1_perRow: 0.3459 - f1_perClass: 0.6794 - acc: 0.4668     \n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 1s - loss: 17.8389 - f1_perRow: 0.3517 - f1_perClass: 0.6852 - acc: 0.4668     \n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 1s - loss: 17.5457 - f1_perRow: 0.3581 - f1_perClass: 0.6893 - acc: 0.4668     \n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 1s - loss: 17.5431 - f1_perRow: 0.3574 - f1_perClass: 0.6960 - acc: 0.4666     \n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 1s - loss: 17.0502 - f1_perRow: 0.3675 - f1_perClass: 0.6996 - acc: 0.4665     \n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.7822 - f1_perRow: 0.3742 - f1_perClass: 0.7050 - acc: 0.4666     \n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.5824 - f1_perRow: 0.3799 - f1_perClass: 0.7061 - acc: 0.4665     \n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.4473 - f1_perRow: 0.3870 - f1_perClass: 0.7089 - acc: 0.4665     \n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.4347 - f1_perRow: 0.3899 - f1_perClass: 0.7087 - acc: 0.4665     \n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.3320 - f1_perRow: 0.3907 - f1_perClass: 0.7097 - acc: 0.4665     \n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.3570 - f1_perRow: 0.3950 - f1_perClass: 0.7099 - acc: 0.4665     \n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.4267 - f1_perRow: 0.3925 - f1_perClass: 0.7106 - acc: 0.4666     \n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.3634 - f1_perRow: 0.3943 - f1_perClass: 0.7092 - acc: 0.4666     \n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2749 - f1_perRow: 0.3983 - f1_perClass: 0.7105 - acc: 0.4666     \n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2414 - f1_perRow: 0.4017 - f1_perClass: 0.7106 - acc: 0.4666     \n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2061 - f1_perRow: 0.4010 - f1_perClass: 0.7116 - acc: 0.4667     \n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.0727 - f1_perRow: 0.4065 - f1_perClass: 0.7131 - acc: 0.4667     \n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.3325 - f1_perRow: 0.4057 - f1_perClass: 0.7105 - acc: 0.4667     \n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.4496 - f1_perRow: 0.3980 - f1_perClass: 0.7102 - acc: 0.4667     \n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2052 - f1_perRow: 0.4052 - f1_perClass: 0.7108 - acc: 0.4668     \n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2512 - f1_perRow: 0.4038 - f1_perClass: 0.7125 - acc: 0.4667     \n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.0755 - f1_perRow: 0.4090 - f1_perClass: 0.7125 - acc: 0.4668     \n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2713 - f1_perRow: 0.4056 - f1_perClass: 0.7110 - acc: 0.4668     \n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.1152 - f1_perRow: 0.4068 - f1_perClass: 0.7137 - acc: 0.4667     \n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.0396 - f1_perRow: 0.4135 - f1_perClass: 0.7138 - acc: 0.4670     \n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.1479 - f1_perRow: 0.4082 - f1_perClass: 0.7122 - acc: 0.4670     \n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9719 - f1_perRow: 0.4185 - f1_perClass: 0.7150 - acc: 0.4673     \n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9133 - f1_perRow: 0.4170 - f1_perClass: 0.7157 - acc: 0.4668     \n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9613 - f1_perRow: 0.4185 - f1_perClass: 0.7147 - acc: 0.4669     \n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.0036 - f1_perRow: 0.4133 - f1_perClass: 0.7137 - acc: 0.4673     \n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9322 - f1_perRow: 0.4232 - f1_perClass: 0.7164 - acc: 0.4669     \n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9486 - f1_perRow: 0.4190 - f1_perClass: 0.7137 - acc: 0.4671     \n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.0272 - f1_perRow: 0.4179 - f1_perClass: 0.7147 - acc: 0.4676     \n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9574 - f1_perRow: 0.4200 - f1_perClass: 0.7151 - acc: 0.4674     \n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9179 - f1_perRow: 0.4228 - f1_perClass: 0.7157 - acc: 0.4687     \n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.4510 - f1_perRow: 0.4166 - f1_perClass: 0.7109 - acc: 0.4678     \n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.2423 - f1_perRow: 0.4030 - f1_perClass: 0.7126 - acc: 0.4694     \n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.0045 - f1_perRow: 0.4232 - f1_perClass: 0.7149 - acc: 0.4699     \n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.8530 - f1_perRow: 0.4189 - f1_perClass: 0.7152 - acc: 0.4701     \n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.8759 - f1_perRow: 0.4290 - f1_perClass: 0.7159 - acc: 0.4675     \n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.1703 - f1_perRow: 0.4235 - f1_perClass: 0.7134 - acc: 0.4694     \n",
      "Epoch 50/100\n",
      "57867/57867 [==============================] - 1s - loss: 16.1164 - f1_perRow: 0.4157 - f1_perClass: 0.7138 - acc: 0.4741     \n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.8851 - f1_perRow: 0.4297 - f1_perClass: 0.7159 - acc: 0.4854     \n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.8900 - f1_perRow: 0.4310 - f1_perClass: 0.7145 - acc: 0.4724     \n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.9354 - f1_perRow: 0.4272 - f1_perClass: 0.7160 - acc: 0.4735     \n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.8610 - f1_perRow: 0.4294 - f1_perClass: 0.7161 - acc: 0.4732     \n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.6997 - f1_perRow: 0.4315 - f1_perClass: 0.7179 - acc: 0.4702     \n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.8346 - f1_perRow: 0.4379 - f1_perClass: 0.7166 - acc: 0.4719     \n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.7152 - f1_perRow: 0.4278 - f1_perClass: 0.7173 - acc: 0.4710     \n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.5514 - f1_perRow: 0.4413 - f1_perClass: 0.7181 - acc: 0.4718     \n",
      "Epoch 59/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.6052 - f1_perRow: 0.4377 - f1_perClass: 0.7185 - acc: 0.4775     \n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.6992 - f1_perRow: 0.4365 - f1_perClass: 0.7179 - acc: 0.4781     \n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.6611 - f1_perRow: 0.4324 - f1_perClass: 0.7177 - acc: 0.4757     \n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.5075 - f1_perRow: 0.4394 - f1_perClass: 0.7188 - acc: 0.4929     \n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.4634 - f1_perRow: 0.4442 - f1_perClass: 0.7199 - acc: 0.4771     \n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.7257 - f1_perRow: 0.4355 - f1_perClass: 0.7164 - acc: 0.4800     \n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.7039 - f1_perRow: 0.4261 - f1_perClass: 0.7170 - acc: 0.4815     \n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.6369 - f1_perRow: 0.4379 - f1_perClass: 0.7189 - acc: 0.4858     \n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 15.4967 - f1_perRow: 0.4371 - f1_perClass: 0.7172 - acc: 0.4967     \n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.3494 - f1_perRow: 0.4369 - f1_perClass: 0.7183 - acc: 0.5214     \n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.3190 - f1_perRow: 0.4185 - f1_perClass: 0.7123 - acc: 0.5397     \n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.0083 - f1_perRow: 0.4110 - f1_perClass: 0.7235 - acc: 0.5291     \n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.8657 - f1_perRow: 0.4272 - f1_perClass: 0.7206 - acc: 0.5562     \n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.8186 - f1_perRow: 0.4349 - f1_perClass: 0.7151 - acc: 0.5321     \n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.6137 - f1_perRow: 0.4378 - f1_perClass: 0.7179 - acc: 0.5288     \n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5251 - f1_perRow: 0.4423 - f1_perClass: 0.7139 - acc: 0.5314     \n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.6643 - f1_perRow: 0.4443 - f1_perClass: 0.7121 - acc: 0.5444     \n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.7102 - f1_perRow: 0.4419 - f1_perClass: 0.7094 - acc: 0.5335     \n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.9822 - f1_perRow: 0.4341 - f1_perClass: 0.7167 - acc: 0.5301     \n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 1s - loss: 15.1081 - f1_perRow: 0.4257 - f1_perClass: 0.7184 - acc: 0.5334     \n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.8570 - f1_perRow: 0.4234 - f1_perClass: 0.7198 - acc: 0.5309     \n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.7937 - f1_perRow: 0.4340 - f1_perClass: 0.7132 - acc: 0.5310     \n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.6285 - f1_perRow: 0.4357 - f1_perClass: 0.7116 - acc: 0.5505     \n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5773 - f1_perRow: 0.4399 - f1_perClass: 0.7141 - acc: 0.5539     \n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.9106 - f1_perRow: 0.4232 - f1_perClass: 0.7098 - acc: 0.5455     \n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.8310 - f1_perRow: 0.4260 - f1_perClass: 0.7205 - acc: 0.5619     \n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.7545 - f1_perRow: 0.4341 - f1_perClass: 0.7186 - acc: 0.5736     \n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.6623 - f1_perRow: 0.4382 - f1_perClass: 0.7232 - acc: 0.5369     \n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.8757 - f1_perRow: 0.4372 - f1_perClass: 0.7224 - acc: 0.6129     \n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.6505 - f1_perRow: 0.4226 - f1_perClass: 0.7215 - acc: 0.5532     \n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.4724 - f1_perRow: 0.4415 - f1_perClass: 0.7196 - acc: 0.5480     \n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.4216 - f1_perRow: 0.4496 - f1_perClass: 0.7202 - acc: 0.5368     \n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.3489 - f1_perRow: 0.4487 - f1_perClass: 0.7250 - acc: 0.5327     \n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5749 - f1_perRow: 0.4488 - f1_perClass: 0.7223 - acc: 0.5458     \n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.4283 - f1_perRow: 0.4479 - f1_perClass: 0.7228 - acc: 0.5351     \n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5505 - f1_perRow: 0.4555 - f1_perClass: 0.7232 - acc: 0.5350     \n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5195 - f1_perRow: 0.4480 - f1_perClass: 0.7256 - acc: 0.5577     \n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5072 - f1_perRow: 0.4522 - f1_perClass: 0.7224 - acc: 0.5529     \n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.9623 - f1_perRow: 0.4430 - f1_perClass: 0.7243 - acc: 0.5590     \n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.7180 - f1_perRow: 0.4195 - f1_perClass: 0.7243 - acc: 0.5451     \n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.5115 - f1_perRow: 0.4493 - f1_perClass: 0.7252 - acc: 0.5717     \n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 1s - loss: 14.4934 - f1_perRow: 0.4443 - f1_perClass: 0.7268 - acc: 0.5456     \n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "weights =np.array([1.0/(50.0/50358.0),\n",
    "1.0/(52.0/50358.0),\n",
    "1.0/(3.0/50358.0),\n",
    "1.0/(5.0/50358.0),\n",
    "1.0/(4.0/50358.0),\n",
    "1.0/(11.0/50358.0),\n",
    "1.0/(58.0/50358.0),\n",
    "1.0/(210.0/50358.0),\n",
    "1.0/(376.0/50358.0),\n",
    "1.0/(118.0/50358.0),\n",
    "1.0/(121.0/50358.0),\n",
    "1.0/(694.0/50358.0),\n",
    "1.0/(230.0/50358.0),\n",
    "1.0/(221.0/50358.0),\n",
    "1.0/(105.0/50358.0),\n",
    "1.0/(98.0/50358.0),\n",
    "1.0/(16560.0/50358.0),\n",
    "1.0/(30490.0/50358.0),\n",
    "1.0/(94.0/50358.0),\n",
    "1.0/(96.0/50358.0),\n",
    "1.0/(452.0/50358.0),\n",
    "1.0/(68.0/50358.0),\n",
    "1.0/(50.0/50358.0),\n",
    "1.0/(45.0/50358.0),])\n",
    "# weights = weights/ np.max(weights)\n",
    "\n",
    "# model2.add(LSTM(50, input_shape=(dim_size, 1), return_sequences=True))\n",
    "# model2.add(TimeDistributed(Dense(1, activation='relu')))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(127, activation='relu'))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "# # model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "\n",
    "# # model2.add(Embedding(word_count, dim_size, input_length=dim_size))\n",
    "# # model2.add(Dropout(0.1))\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [dout_2, fl_out_cnn] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=7500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "57867/57867 [==============================] - 2s - loss: 13.8575 - f1_perRow: 0.4838 - f1_perClass: 0.7169 - acc: 0.7773     \n",
      "Epoch 2/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8491 - f1_perRow: 0.4781 - f1_perClass: 0.7164 - acc: 0.7929     \n",
      "Epoch 3/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8577 - f1_perRow: 0.4780 - f1_perClass: 0.7180 - acc: 0.7817     \n",
      "Epoch 4/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7948 - f1_perRow: 0.4813 - f1_perClass: 0.7165 - acc: 0.7916     \n",
      "Epoch 5/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9823 - f1_perRow: 0.4755 - f1_perClass: 0.7141 - acc: 0.7516     \n",
      "Epoch 6/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8702 - f1_perRow: 0.4823 - f1_perClass: 0.7197 - acc: 0.7405     \n",
      "Epoch 7/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7650 - f1_perRow: 0.4781 - f1_perClass: 0.7179 - acc: 0.7446     \n",
      "Epoch 8/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9901 - f1_perRow: 0.4747 - f1_perClass: 0.7136 - acc: 0.7131     \n",
      "Epoch 9/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9916 - f1_perRow: 0.4829 - f1_perClass: 0.7185 - acc: 0.7425     \n",
      "Epoch 10/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7757 - f1_perRow: 0.4826 - f1_perClass: 0.7174 - acc: 0.7740     \n",
      "Epoch 11/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8160 - f1_perRow: 0.4725 - f1_perClass: 0.7142 - acc: 0.7700     \n",
      "Epoch 12/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8375 - f1_perRow: 0.4794 - f1_perClass: 0.7187 - acc: 0.7463     \n",
      "Epoch 13/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8840 - f1_perRow: 0.4809 - f1_perClass: 0.7150 - acc: 0.7403     \n",
      "Epoch 14/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8305 - f1_perRow: 0.4793 - f1_perClass: 0.7148 - acc: 0.7514     \n",
      "Epoch 15/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8774 - f1_perRow: 0.4780 - f1_perClass: 0.7157 - acc: 0.7348     \n",
      "Epoch 16/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8396 - f1_perRow: 0.4791 - f1_perClass: 0.7152 - acc: 0.7388     \n",
      "Epoch 17/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8310 - f1_perRow: 0.4774 - f1_perClass: 0.7144 - acc: 0.7343     \n",
      "Epoch 18/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8954 - f1_perRow: 0.4785 - f1_perClass: 0.7154 - acc: 0.7582     \n",
      "Epoch 19/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8352 - f1_perRow: 0.4811 - f1_perClass: 0.7155 - acc: 0.7547     \n",
      "Epoch 20/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8031 - f1_perRow: 0.4780 - f1_perClass: 0.7123 - acc: 0.6917     \n",
      "Epoch 21/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8600 - f1_perRow: 0.4796 - f1_perClass: 0.7144 - acc: 0.6851     \n",
      "Epoch 22/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7715 - f1_perRow: 0.4858 - f1_perClass: 0.7151 - acc: 0.7688     \n",
      "Epoch 23/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8952 - f1_perRow: 0.4759 - f1_perClass: 0.7144 - acc: 0.7560     \n",
      "Epoch 24/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8678 - f1_perRow: 0.4786 - f1_perClass: 0.7143 - acc: 0.7201     \n",
      "Epoch 25/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7861 - f1_perRow: 0.4877 - f1_perClass: 0.7165 - acc: 0.7521     \n",
      "Epoch 26/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7647 - f1_perRow: 0.4840 - f1_perClass: 0.7187 - acc: 0.7519     \n",
      "Epoch 27/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8461 - f1_perRow: 0.4815 - f1_perClass: 0.7141 - acc: 0.7482     \n",
      "Epoch 28/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7803 - f1_perRow: 0.4821 - f1_perClass: 0.7201 - acc: 0.6969     \n",
      "Epoch 29/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.1291 - f1_perRow: 0.4813 - f1_perClass: 0.7139 - acc: 0.7431     \n",
      "Epoch 30/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8080 - f1_perRow: 0.4843 - f1_perClass: 0.7148 - acc: 0.7699     \n",
      "Epoch 31/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0297 - f1_perRow: 0.4759 - f1_perClass: 0.7180 - acc: 0.7581     \n",
      "Epoch 32/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8517 - f1_perRow: 0.4735 - f1_perClass: 0.7150 - acc: 0.7627     \n",
      "Epoch 33/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7690 - f1_perRow: 0.4796 - f1_perClass: 0.7162 - acc: 0.7687     \n",
      "Epoch 34/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8091 - f1_perRow: 0.4811 - f1_perClass: 0.7175 - acc: 0.7950     \n",
      "Epoch 35/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8339 - f1_perRow: 0.4810 - f1_perClass: 0.7176 - acc: 0.7999     \n",
      "Epoch 36/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8279 - f1_perRow: 0.4818 - f1_perClass: 0.7183 - acc: 0.7888     \n",
      "Epoch 37/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8056 - f1_perRow: 0.4845 - f1_perClass: 0.7163 - acc: 0.7939     \n",
      "Epoch 38/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9047 - f1_perRow: 0.4789 - f1_perClass: 0.7128 - acc: 0.7892     \n",
      "Epoch 39/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8446 - f1_perRow: 0.4869 - f1_perClass: 0.7192 - acc: 0.8030     \n",
      "Epoch 40/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7877 - f1_perRow: 0.4819 - f1_perClass: 0.7177 - acc: 0.8017     \n",
      "Epoch 41/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8100 - f1_perRow: 0.4803 - f1_perClass: 0.7142 - acc: 0.7612     \n",
      "Epoch 42/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7719 - f1_perRow: 0.4768 - f1_perClass: 0.7163 - acc: 0.7671     \n",
      "Epoch 43/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8393 - f1_perRow: 0.4850 - f1_perClass: 0.7198 - acc: 0.7864     \n",
      "Epoch 44/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9078 - f1_perRow: 0.4762 - f1_perClass: 0.7135 - acc: 0.7846     \n",
      "Epoch 45/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8506 - f1_perRow: 0.4796 - f1_perClass: 0.7123 - acc: 0.7769     \n",
      "Epoch 46/300\n",
      "57867/57867 [==============================] - 2s - loss: 13.7545 - f1_perRow: 0.4858 - f1_perClass: 0.7197 - acc: 0.7527     \n",
      "Epoch 47/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0355 - f1_perRow: 0.4780 - f1_perClass: 0.7153 - acc: 0.7751     \n",
      "Epoch 48/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7604 - f1_perRow: 0.4874 - f1_perClass: 0.7161 - acc: 0.7616     \n",
      "Epoch 49/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7634 - f1_perRow: 0.4753 - f1_perClass: 0.7163 - acc: 0.7576     \n",
      "Epoch 50/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8557 - f1_perRow: 0.4764 - f1_perClass: 0.7145 - acc: 0.7923     \n",
      "Epoch 51/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8698 - f1_perRow: 0.4801 - f1_perClass: 0.7161 - acc: 0.7630     \n",
      "Epoch 52/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7497 - f1_perRow: 0.4883 - f1_perClass: 0.7173 - acc: 0.7564     \n",
      "Epoch 53/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8180 - f1_perRow: 0.4792 - f1_perClass: 0.7163 - acc: 0.7546     \n",
      "Epoch 54/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7997 - f1_perRow: 0.4805 - f1_perClass: 0.7174 - acc: 0.7739     \n",
      "Epoch 55/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8359 - f1_perRow: 0.4825 - f1_perClass: 0.7192 - acc: 0.7550     \n",
      "Epoch 56/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7844 - f1_perRow: 0.4820 - f1_perClass: 0.7216 - acc: 0.7721     \n",
      "Epoch 57/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9463 - f1_perRow: 0.4760 - f1_perClass: 0.7189 - acc: 0.7209     \n",
      "Epoch 58/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8290 - f1_perRow: 0.4834 - f1_perClass: 0.7200 - acc: 0.7507     \n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 13.8340 - f1_perRow: 0.4815 - f1_perClass: 0.7189 - acc: 0.7907     \n",
      "Epoch 60/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8814 - f1_perRow: 0.4833 - f1_perClass: 0.7181 - acc: 0.7789     \n",
      "Epoch 61/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7531 - f1_perRow: 0.4818 - f1_perClass: 0.7179 - acc: 0.7637     \n",
      "Epoch 62/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9827 - f1_perRow: 0.4738 - f1_perClass: 0.7141 - acc: 0.7614     \n",
      "Epoch 63/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8301 - f1_perRow: 0.4785 - f1_perClass: 0.7145 - acc: 0.7324     \n",
      "Epoch 64/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7750 - f1_perRow: 0.4876 - f1_perClass: 0.7205 - acc: 0.7849     \n",
      "Epoch 65/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7935 - f1_perRow: 0.4830 - f1_perClass: 0.7181 - acc: 0.7768     \n",
      "Epoch 66/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0967 - f1_perRow: 0.4714 - f1_perClass: 0.7134 - acc: 0.7129     \n",
      "Epoch 67/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9141 - f1_perRow: 0.4753 - f1_perClass: 0.7170 - acc: 0.7277     \n",
      "Epoch 68/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7819 - f1_perRow: 0.4843 - f1_perClass: 0.7192 - acc: 0.7815     \n",
      "Epoch 69/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8263 - f1_perRow: 0.4779 - f1_perClass: 0.7161 - acc: 0.7669     \n",
      "Epoch 70/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8723 - f1_perRow: 0.4756 - f1_perClass: 0.7155 - acc: 0.7631     \n",
      "Epoch 71/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7481 - f1_perRow: 0.4822 - f1_perClass: 0.7179 - acc: 0.7924     \n",
      "Epoch 72/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7727 - f1_perRow: 0.4835 - f1_perClass: 0.7153 - acc: 0.8028     \n",
      "Epoch 73/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9407 - f1_perRow: 0.4817 - f1_perClass: 0.7168 - acc: 0.7636     \n",
      "Epoch 74/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9216 - f1_perRow: 0.4768 - f1_perClass: 0.7155 - acc: 0.7748     \n",
      "Epoch 75/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7730 - f1_perRow: 0.4838 - f1_perClass: 0.7144 - acc: 0.7515     \n",
      "Epoch 76/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7585 - f1_perRow: 0.4889 - f1_perClass: 0.7167 - acc: 0.7674     \n",
      "Epoch 77/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8277 - f1_perRow: 0.4799 - f1_perClass: 0.7167 - acc: 0.8092     \n",
      "Epoch 78/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0486 - f1_perRow: 0.4762 - f1_perClass: 0.7137 - acc: 0.7793     \n",
      "Epoch 79/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7919 - f1_perRow: 0.4831 - f1_perClass: 0.7149 - acc: 0.7808     \n",
      "Epoch 80/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8564 - f1_perRow: 0.4815 - f1_perClass: 0.7147 - acc: 0.7692     \n",
      "Epoch 81/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8427 - f1_perRow: 0.4842 - f1_perClass: 0.7158 - acc: 0.7563     \n",
      "Epoch 82/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7314 - f1_perRow: 0.4861 - f1_perClass: 0.7169 - acc: 0.8007     \n",
      "Epoch 83/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8113 - f1_perRow: 0.4734 - f1_perClass: 0.7157 - acc: 0.7465     \n",
      "Epoch 84/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7431 - f1_perRow: 0.4745 - f1_perClass: 0.7162 - acc: 0.7195     \n",
      "Epoch 85/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0901 - f1_perRow: 0.4738 - f1_perClass: 0.7155 - acc: 0.7475     \n",
      "Epoch 86/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8582 - f1_perRow: 0.4799 - f1_perClass: 0.7142 - acc: 0.7432     \n",
      "Epoch 87/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8221 - f1_perRow: 0.4859 - f1_perClass: 0.7187 - acc: 0.7279     \n",
      "Epoch 88/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8011 - f1_perRow: 0.4796 - f1_perClass: 0.7166 - acc: 0.7223     \n",
      "Epoch 89/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7837 - f1_perRow: 0.4789 - f1_perClass: 0.7174 - acc: 0.7371     \n",
      "Epoch 90/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7529 - f1_perRow: 0.4761 - f1_perClass: 0.7159 - acc: 0.7621     \n",
      "Epoch 91/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0712 - f1_perRow: 0.4720 - f1_perClass: 0.7118 - acc: 0.7803     \n",
      "Epoch 92/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7355 - f1_perRow: 0.4818 - f1_perClass: 0.7174 - acc: 0.7747     \n",
      "Epoch 93/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9296 - f1_perRow: 0.4782 - f1_perClass: 0.7151 - acc: 0.7698     \n",
      "Epoch 94/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8102 - f1_perRow: 0.4883 - f1_perClass: 0.7179 - acc: 0.7846     \n",
      "Epoch 95/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8169 - f1_perRow: 0.4903 - f1_perClass: 0.7220 - acc: 0.7769     \n",
      "Epoch 96/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0161 - f1_perRow: 0.4701 - f1_perClass: 0.7167 - acc: 0.7653     \n",
      "Epoch 97/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8447 - f1_perRow: 0.4771 - f1_perClass: 0.7200 - acc: 0.7590     \n",
      "Epoch 98/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7811 - f1_perRow: 0.4822 - f1_perClass: 0.7207 - acc: 0.7717     \n",
      "Epoch 99/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8373 - f1_perRow: 0.4836 - f1_perClass: 0.7192 - acc: 0.7691     \n",
      "Epoch 100/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7086 - f1_perRow: 0.4862 - f1_perClass: 0.7208 - acc: 0.7683     \n",
      "Epoch 101/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7807 - f1_perRow: 0.4853 - f1_perClass: 0.7200 - acc: 0.7848     \n",
      "Epoch 102/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8050 - f1_perRow: 0.4824 - f1_perClass: 0.7205 - acc: 0.7910     \n",
      "Epoch 103/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.0013 - f1_perRow: 0.4711 - f1_perClass: 0.7143 - acc: 0.7659     \n",
      "Epoch 104/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8905 - f1_perRow: 0.4853 - f1_perClass: 0.7200 - acc: 0.7445     \n",
      "Epoch 105/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8400 - f1_perRow: 0.4810 - f1_perClass: 0.7182 - acc: 0.7406     \n",
      "Epoch 106/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9098 - f1_perRow: 0.4781 - f1_perClass: 0.7169 - acc: 0.7209     \n",
      "Epoch 107/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8396 - f1_perRow: 0.4756 - f1_perClass: 0.7163 - acc: 0.7390     \n",
      "Epoch 108/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8938 - f1_perRow: 0.4817 - f1_perClass: 0.7184 - acc: 0.7451     \n",
      "Epoch 109/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8393 - f1_perRow: 0.4768 - f1_perClass: 0.7167 - acc: 0.7534     \n",
      "Epoch 110/300\n",
      "57867/57867 [==============================] - 1s - loss: 14.1015 - f1_perRow: 0.4742 - f1_perClass: 0.7158 - acc: 0.7650     \n",
      "Epoch 111/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8083 - f1_perRow: 0.4809 - f1_perClass: 0.7168 - acc: 0.7680     \n",
      "Epoch 112/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8569 - f1_perRow: 0.4718 - f1_perClass: 0.7161 - acc: 0.7544     \n",
      "Epoch 113/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8031 - f1_perRow: 0.4781 - f1_perClass: 0.7183 - acc: 0.7624     \n",
      "Epoch 114/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7464 - f1_perRow: 0.4759 - f1_perClass: 0.7180 - acc: 0.7946     \n",
      "Epoch 115/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8540 - f1_perRow: 0.4738 - f1_perClass: 0.7163 - acc: 0.7666     \n",
      "Epoch 116/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8063 - f1_perRow: 0.4791 - f1_perClass: 0.7165 - acc: 0.7702     \n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 13.7395 - f1_perRow: 0.4785 - f1_perClass: 0.7201 - acc: 0.7765     \n",
      "Epoch 118/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7728 - f1_perRow: 0.4834 - f1_perClass: 0.7184 - acc: 0.7672     \n",
      "Epoch 119/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8119 - f1_perRow: 0.4794 - f1_perClass: 0.7165 - acc: 0.7466     \n",
      "Epoch 120/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7180 - f1_perRow: 0.4808 - f1_perClass: 0.7180 - acc: 0.7480     \n",
      "Epoch 121/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8033 - f1_perRow: 0.4788 - f1_perClass: 0.7170 - acc: 0.7797     \n",
      "Epoch 122/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7070 - f1_perRow: 0.4756 - f1_perClass: 0.7174 - acc: 0.7773     \n",
      "Epoch 123/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8152 - f1_perRow: 0.4575 - f1_perClass: 0.7106 - acc: 0.7740     \n",
      "Epoch 124/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7504 - f1_perRow: 0.4473 - f1_perClass: 0.7047 - acc: 0.7972     \n",
      "Epoch 125/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7352 - f1_perRow: 0.4489 - f1_perClass: 0.7020 - acc: 0.8077     \n",
      "Epoch 126/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7221 - f1_perRow: 0.4498 - f1_perClass: 0.7081 - acc: 0.8056     \n",
      "Epoch 127/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7013 - f1_perRow: 0.4517 - f1_perClass: 0.7089 - acc: 0.8024     \n",
      "Epoch 128/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5871 - f1_perRow: 0.4501 - f1_perClass: 0.7103 - acc: 0.7587     \n",
      "Epoch 129/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6913 - f1_perRow: 0.4509 - f1_perClass: 0.7107 - acc: 0.7363     \n",
      "Epoch 130/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5579 - f1_perRow: 0.4599 - f1_perClass: 0.7127 - acc: 0.7387     \n",
      "Epoch 131/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7832 - f1_perRow: 0.4527 - f1_perClass: 0.7076 - acc: 0.7540     \n",
      "Epoch 132/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7800 - f1_perRow: 0.4543 - f1_perClass: 0.7080 - acc: 0.7608     \n",
      "Epoch 133/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6249 - f1_perRow: 0.4594 - f1_perClass: 0.7132 - acc: 0.7334     \n",
      "Epoch 134/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8603 - f1_perRow: 0.4620 - f1_perClass: 0.7104 - acc: 0.7320     \n",
      "Epoch 135/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6770 - f1_perRow: 0.4541 - f1_perClass: 0.7118 - acc: 0.7442     \n",
      "Epoch 136/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7336 - f1_perRow: 0.4556 - f1_perClass: 0.7116 - acc: 0.7626     \n",
      "Epoch 137/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7251 - f1_perRow: 0.4548 - f1_perClass: 0.7129 - acc: 0.7685     \n",
      "Epoch 138/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6778 - f1_perRow: 0.4587 - f1_perClass: 0.7117 - acc: 0.7897     \n",
      "Epoch 139/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7228 - f1_perRow: 0.4637 - f1_perClass: 0.7122 - acc: 0.7881     \n",
      "Epoch 140/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6407 - f1_perRow: 0.4667 - f1_perClass: 0.7109 - acc: 0.7731     \n",
      "Epoch 141/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7394 - f1_perRow: 0.4521 - f1_perClass: 0.7093 - acc: 0.7505     \n",
      "Epoch 142/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6728 - f1_perRow: 0.4573 - f1_perClass: 0.7127 - acc: 0.7884     \n",
      "Epoch 143/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7785 - f1_perRow: 0.4658 - f1_perClass: 0.7132 - acc: 0.8107     \n",
      "Epoch 144/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6349 - f1_perRow: 0.4609 - f1_perClass: 0.7111 - acc: 0.8038     \n",
      "Epoch 145/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5452 - f1_perRow: 0.4628 - f1_perClass: 0.7104 - acc: 0.7803     \n",
      "Epoch 146/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6229 - f1_perRow: 0.4617 - f1_perClass: 0.7126 - acc: 0.7787     \n",
      "Epoch 147/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5356 - f1_perRow: 0.4633 - f1_perClass: 0.7100 - acc: 0.8032     \n",
      "Epoch 148/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7414 - f1_perRow: 0.4555 - f1_perClass: 0.7056 - acc: 0.8205     \n",
      "Epoch 149/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6486 - f1_perRow: 0.4635 - f1_perClass: 0.7089 - acc: 0.8240     \n",
      "Epoch 150/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7305 - f1_perRow: 0.4642 - f1_perClass: 0.7122 - acc: 0.7900     \n",
      "Epoch 151/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5695 - f1_perRow: 0.4689 - f1_perClass: 0.7105 - acc: 0.7593     \n",
      "Epoch 152/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5979 - f1_perRow: 0.4701 - f1_perClass: 0.7133 - acc: 0.7715     \n",
      "Epoch 153/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6502 - f1_perRow: 0.4660 - f1_perClass: 0.7139 - acc: 0.7888     \n",
      "Epoch 154/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5449 - f1_perRow: 0.4709 - f1_perClass: 0.7119 - acc: 0.7617     \n",
      "Epoch 155/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5905 - f1_perRow: 0.4643 - f1_perClass: 0.7105 - acc: 0.7759     \n",
      "Epoch 156/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5870 - f1_perRow: 0.4632 - f1_perClass: 0.7105 - acc: 0.7871     \n",
      "Epoch 157/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5325 - f1_perRow: 0.4677 - f1_perClass: 0.7117 - acc: 0.7788     \n",
      "Epoch 158/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7080 - f1_perRow: 0.4624 - f1_perClass: 0.7072 - acc: 0.7765     \n",
      "Epoch 159/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6325 - f1_perRow: 0.4695 - f1_perClass: 0.7102 - acc: 0.7988     \n",
      "Epoch 160/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8355 - f1_perRow: 0.4634 - f1_perClass: 0.7081 - acc: 0.7945     \n",
      "Epoch 161/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8476 - f1_perRow: 0.4621 - f1_perClass: 0.7127 - acc: 0.8094     \n",
      "Epoch 162/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5319 - f1_perRow: 0.4767 - f1_perClass: 0.7137 - acc: 0.8075     \n",
      "Epoch 163/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5790 - f1_perRow: 0.4660 - f1_perClass: 0.7113 - acc: 0.7762     \n",
      "Epoch 164/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8123 - f1_perRow: 0.4599 - f1_perClass: 0.7117 - acc: 0.7949     \n",
      "Epoch 165/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6245 - f1_perRow: 0.4646 - f1_perClass: 0.7114 - acc: 0.8151     \n",
      "Epoch 166/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6552 - f1_perRow: 0.4661 - f1_perClass: 0.7098 - acc: 0.8001     \n",
      "Epoch 167/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5949 - f1_perRow: 0.4653 - f1_perClass: 0.7098 - acc: 0.7981     \n",
      "Epoch 168/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7094 - f1_perRow: 0.4658 - f1_perClass: 0.7125 - acc: 0.8074     \n",
      "Epoch 169/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5370 - f1_perRow: 0.4739 - f1_perClass: 0.7101 - acc: 0.8154     \n",
      "Epoch 170/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6226 - f1_perRow: 0.4672 - f1_perClass: 0.7111 - acc: 0.7963     \n",
      "Epoch 171/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6943 - f1_perRow: 0.4687 - f1_perClass: 0.7094 - acc: 0.7821     \n",
      "Epoch 172/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5424 - f1_perRow: 0.4711 - f1_perClass: 0.7137 - acc: 0.7585     \n",
      "Epoch 173/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7122 - f1_perRow: 0.4606 - f1_perClass: 0.7126 - acc: 0.7623     \n",
      "Epoch 174/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6226 - f1_perRow: 0.4734 - f1_perClass: 0.7151 - acc: 0.7772     \n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 13.7229 - f1_perRow: 0.4704 - f1_perClass: 0.7112 - acc: 0.7642     \n",
      "Epoch 176/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5327 - f1_perRow: 0.4740 - f1_perClass: 0.7105 - acc: 0.7530     \n",
      "Epoch 177/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6322 - f1_perRow: 0.4694 - f1_perClass: 0.7134 - acc: 0.8043     \n",
      "Epoch 178/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5115 - f1_perRow: 0.4700 - f1_perClass: 0.7096 - acc: 0.8283     \n",
      "Epoch 179/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5763 - f1_perRow: 0.4720 - f1_perClass: 0.7087 - acc: 0.7994     \n",
      "Epoch 180/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.9433 - f1_perRow: 0.4551 - f1_perClass: 0.7054 - acc: 0.8004     \n",
      "Epoch 181/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6773 - f1_perRow: 0.4761 - f1_perClass: 0.7143 - acc: 0.8103     \n",
      "Epoch 182/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6589 - f1_perRow: 0.4716 - f1_perClass: 0.7119 - acc: 0.8229     \n",
      "Epoch 183/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5737 - f1_perRow: 0.4752 - f1_perClass: 0.7110 - acc: 0.8137     \n",
      "Epoch 184/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8435 - f1_perRow: 0.4727 - f1_perClass: 0.7116 - acc: 0.7846     \n",
      "Epoch 185/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5198 - f1_perRow: 0.4755 - f1_perClass: 0.7107 - acc: 0.7522     \n",
      "Epoch 186/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7007 - f1_perRow: 0.4654 - f1_perClass: 0.7063 - acc: 0.7855     \n",
      "Epoch 187/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7202 - f1_perRow: 0.4681 - f1_perClass: 0.7080 - acc: 0.7811     \n",
      "Epoch 188/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6661 - f1_perRow: 0.4690 - f1_perClass: 0.7098 - acc: 0.7953     \n",
      "Epoch 189/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6961 - f1_perRow: 0.4667 - f1_perClass: 0.7076 - acc: 0.7942     \n",
      "Epoch 190/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6447 - f1_perRow: 0.4608 - f1_perClass: 0.7063 - acc: 0.7254     \n",
      "Epoch 191/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7490 - f1_perRow: 0.4615 - f1_perClass: 0.7093 - acc: 0.7025     \n",
      "Epoch 192/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7224 - f1_perRow: 0.4685 - f1_perClass: 0.7095 - acc: 0.7387     \n",
      "Epoch 193/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5916 - f1_perRow: 0.4688 - f1_perClass: 0.7119 - acc: 0.7701     \n",
      "Epoch 194/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5620 - f1_perRow: 0.4707 - f1_perClass: 0.7115 - acc: 0.8071     \n",
      "Epoch 195/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6435 - f1_perRow: 0.4654 - f1_perClass: 0.7103 - acc: 0.7966     \n",
      "Epoch 196/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5733 - f1_perRow: 0.4686 - f1_perClass: 0.7106 - acc: 0.7705     \n",
      "Epoch 197/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7335 - f1_perRow: 0.4634 - f1_perClass: 0.7068 - acc: 0.7696     \n",
      "Epoch 198/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8405 - f1_perRow: 0.4644 - f1_perClass: 0.7100 - acc: 0.7829     \n",
      "Epoch 199/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5772 - f1_perRow: 0.4768 - f1_perClass: 0.7126 - acc: 0.8013     \n",
      "Epoch 200/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7366 - f1_perRow: 0.4629 - f1_perClass: 0.7066 - acc: 0.7774     \n",
      "Epoch 201/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6507 - f1_perRow: 0.4737 - f1_perClass: 0.7111 - acc: 0.7621     \n",
      "Epoch 202/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8444 - f1_perRow: 0.4688 - f1_perClass: 0.7090 - acc: 0.7603     \n",
      "Epoch 203/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6111 - f1_perRow: 0.4617 - f1_perClass: 0.7110 - acc: 0.7813     \n",
      "Epoch 204/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5967 - f1_perRow: 0.4701 - f1_perClass: 0.7135 - acc: 0.7994     \n",
      "Epoch 205/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6912 - f1_perRow: 0.4631 - f1_perClass: 0.7106 - acc: 0.7817     \n",
      "Epoch 206/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6508 - f1_perRow: 0.4684 - f1_perClass: 0.7116 - acc: 0.7661     \n",
      "Epoch 207/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5445 - f1_perRow: 0.4751 - f1_perClass: 0.7153 - acc: 0.7416     \n",
      "Epoch 208/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5486 - f1_perRow: 0.4722 - f1_perClass: 0.7106 - acc: 0.7367     \n",
      "Epoch 209/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6551 - f1_perRow: 0.4790 - f1_perClass: 0.7121 - acc: 0.7593     \n",
      "Epoch 210/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6115 - f1_perRow: 0.4692 - f1_perClass: 0.7118 - acc: 0.7529     \n",
      "Epoch 211/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5400 - f1_perRow: 0.4733 - f1_perClass: 0.7135 - acc: 0.7739     \n",
      "Epoch 212/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6003 - f1_perRow: 0.4738 - f1_perClass: 0.7149 - acc: 0.7924     \n",
      "Epoch 213/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5426 - f1_perRow: 0.4773 - f1_perClass: 0.7113 - acc: 0.7670     \n",
      "Epoch 214/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6433 - f1_perRow: 0.4658 - f1_perClass: 0.7141 - acc: 0.7572     \n",
      "Epoch 215/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5939 - f1_perRow: 0.4794 - f1_perClass: 0.7156 - acc: 0.7442     \n",
      "Epoch 216/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7201 - f1_perRow: 0.4686 - f1_perClass: 0.7100 - acc: 0.7537     \n",
      "Epoch 217/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5070 - f1_perRow: 0.4740 - f1_perClass: 0.7155 - acc: 0.7684     \n",
      "Epoch 218/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6169 - f1_perRow: 0.4747 - f1_perClass: 0.7143 - acc: 0.8017     \n",
      "Epoch 219/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5052 - f1_perRow: 0.4734 - f1_perClass: 0.7142 - acc: 0.8092     \n",
      "Epoch 220/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6564 - f1_perRow: 0.4689 - f1_perClass: 0.7101 - acc: 0.7917     \n",
      "Epoch 221/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5379 - f1_perRow: 0.4791 - f1_perClass: 0.7109 - acc: 0.7514     \n",
      "Epoch 222/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7373 - f1_perRow: 0.4719 - f1_perClass: 0.7095 - acc: 0.7438     \n",
      "Epoch 223/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6668 - f1_perRow: 0.4722 - f1_perClass: 0.7093 - acc: 0.7438     \n",
      "Epoch 224/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8745 - f1_perRow: 0.4688 - f1_perClass: 0.7135 - acc: 0.7713     \n",
      "Epoch 225/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5950 - f1_perRow: 0.4811 - f1_perClass: 0.7158 - acc: 0.7935     \n",
      "Epoch 226/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6065 - f1_perRow: 0.4747 - f1_perClass: 0.7135 - acc: 0.7839     \n",
      "Epoch 227/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8086 - f1_perRow: 0.4669 - f1_perClass: 0.7139 - acc: 0.7720     \n",
      "Epoch 228/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6418 - f1_perRow: 0.4722 - f1_perClass: 0.7129 - acc: 0.7743     \n",
      "Epoch 229/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7067 - f1_perRow: 0.4701 - f1_perClass: 0.7101 - acc: 0.7694     \n",
      "Epoch 230/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6185 - f1_perRow: 0.4756 - f1_perClass: 0.7154 - acc: 0.7772     \n",
      "Epoch 231/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6065 - f1_perRow: 0.4772 - f1_perClass: 0.7137 - acc: 0.7888     \n",
      "Epoch 232/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7975 - f1_perRow: 0.4667 - f1_perClass: 0.7102 - acc: 0.7654     \n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 13.6242 - f1_perRow: 0.4738 - f1_perClass: 0.7105 - acc: 0.7775     \n",
      "Epoch 234/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8852 - f1_perRow: 0.4573 - f1_perClass: 0.7080 - acc: 0.8013     \n",
      "Epoch 235/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6034 - f1_perRow: 0.4772 - f1_perClass: 0.7145 - acc: 0.8145     \n",
      "Epoch 236/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5952 - f1_perRow: 0.4752 - f1_perClass: 0.7137 - acc: 0.8105     \n",
      "Epoch 237/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5306 - f1_perRow: 0.4699 - f1_perClass: 0.7115 - acc: 0.7789     \n",
      "Epoch 238/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7386 - f1_perRow: 0.4665 - f1_perClass: 0.7106 - acc: 0.8000     \n",
      "Epoch 239/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8527 - f1_perRow: 0.4677 - f1_perClass: 0.7080 - acc: 0.8244     \n",
      "Epoch 240/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7788 - f1_perRow: 0.4666 - f1_perClass: 0.7072 - acc: 0.7889     \n",
      "Epoch 241/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6906 - f1_perRow: 0.4747 - f1_perClass: 0.7117 - acc: 0.7511     \n",
      "Epoch 242/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6587 - f1_perRow: 0.4742 - f1_perClass: 0.7140 - acc: 0.7502     \n",
      "Epoch 243/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6911 - f1_perRow: 0.4705 - f1_perClass: 0.7118 - acc: 0.7762     \n",
      "Epoch 244/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8557 - f1_perRow: 0.4586 - f1_perClass: 0.7080 - acc: 0.7771     \n",
      "Epoch 245/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5246 - f1_perRow: 0.4801 - f1_perClass: 0.7141 - acc: 0.7914     \n",
      "Epoch 246/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5716 - f1_perRow: 0.4780 - f1_perClass: 0.7147 - acc: 0.7712     \n",
      "Epoch 247/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5306 - f1_perRow: 0.4761 - f1_perClass: 0.7150 - acc: 0.7895     \n",
      "Epoch 248/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6250 - f1_perRow: 0.4758 - f1_perClass: 0.7148 - acc: 0.7744     \n",
      "Epoch 249/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6333 - f1_perRow: 0.4739 - f1_perClass: 0.7135 - acc: 0.7644     \n",
      "Epoch 250/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5869 - f1_perRow: 0.4719 - f1_perClass: 0.7143 - acc: 0.7653     \n",
      "Epoch 251/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6627 - f1_perRow: 0.4744 - f1_perClass: 0.7147 - acc: 0.7665     \n",
      "Epoch 252/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5901 - f1_perRow: 0.4746 - f1_perClass: 0.7135 - acc: 0.7789     \n",
      "Epoch 253/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5356 - f1_perRow: 0.4746 - f1_perClass: 0.7148 - acc: 0.7885     \n",
      "Epoch 254/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5943 - f1_perRow: 0.4767 - f1_perClass: 0.7149 - acc: 0.7827     \n",
      "Epoch 255/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5769 - f1_perRow: 0.4717 - f1_perClass: 0.7115 - acc: 0.8033     \n",
      "Epoch 256/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7612 - f1_perRow: 0.4763 - f1_perClass: 0.7142 - acc: 0.7918     \n",
      "Epoch 257/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6329 - f1_perRow: 0.4767 - f1_perClass: 0.7125 - acc: 0.7645     \n",
      "Epoch 258/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5222 - f1_perRow: 0.4769 - f1_perClass: 0.7123 - acc: 0.7732     \n",
      "Epoch 259/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6737 - f1_perRow: 0.4652 - f1_perClass: 0.7098 - acc: 0.8219     \n",
      "Epoch 260/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5043 - f1_perRow: 0.4798 - f1_perClass: 0.7164 - acc: 0.7856     \n",
      "Epoch 261/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6258 - f1_perRow: 0.4714 - f1_perClass: 0.7097 - acc: 0.7321     \n",
      "Epoch 262/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7476 - f1_perRow: 0.4725 - f1_perClass: 0.7134 - acc: 0.7310     \n",
      "Epoch 263/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5751 - f1_perRow: 0.4785 - f1_perClass: 0.7136 - acc: 0.7749     \n",
      "Epoch 264/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7685 - f1_perRow: 0.4729 - f1_perClass: 0.7119 - acc: 0.7828     \n",
      "Epoch 265/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6103 - f1_perRow: 0.4850 - f1_perClass: 0.7143 - acc: 0.7854     \n",
      "Epoch 266/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5430 - f1_perRow: 0.4791 - f1_perClass: 0.7121 - acc: 0.7645     \n",
      "Epoch 267/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5086 - f1_perRow: 0.4740 - f1_perClass: 0.7146 - acc: 0.7429     \n",
      "Epoch 268/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5658 - f1_perRow: 0.4758 - f1_perClass: 0.7154 - acc: 0.7508     \n",
      "Epoch 269/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6970 - f1_perRow: 0.4762 - f1_perClass: 0.7082 - acc: 0.7368     \n",
      "Epoch 270/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6217 - f1_perRow: 0.4737 - f1_perClass: 0.7122 - acc: 0.7304     \n",
      "Epoch 271/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.4535 - f1_perRow: 0.4822 - f1_perClass: 0.7171 - acc: 0.7607     \n",
      "Epoch 272/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5218 - f1_perRow: 0.4824 - f1_perClass: 0.7143 - acc: 0.7211     \n",
      "Epoch 273/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6150 - f1_perRow: 0.4791 - f1_perClass: 0.7137 - acc: 0.7151     \n",
      "Epoch 274/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5074 - f1_perRow: 0.4804 - f1_perClass: 0.7131 - acc: 0.7868     \n",
      "Epoch 275/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5676 - f1_perRow: 0.4854 - f1_perClass: 0.7157 - acc: 0.7769     \n",
      "Epoch 276/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5619 - f1_perRow: 0.4848 - f1_perClass: 0.7158 - acc: 0.7868     \n",
      "Epoch 277/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5634 - f1_perRow: 0.4760 - f1_perClass: 0.7149 - acc: 0.8061     \n",
      "Epoch 278/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6464 - f1_perRow: 0.4803 - f1_perClass: 0.7132 - acc: 0.8008     \n",
      "Epoch 279/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6352 - f1_perRow: 0.4750 - f1_perClass: 0.7131 - acc: 0.8105     \n",
      "Epoch 280/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6359 - f1_perRow: 0.4753 - f1_perClass: 0.7151 - acc: 0.7933     \n",
      "Epoch 281/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6051 - f1_perRow: 0.4836 - f1_perClass: 0.7175 - acc: 0.7710     \n",
      "Epoch 282/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6582 - f1_perRow: 0.4844 - f1_perClass: 0.7170 - acc: 0.7791     \n",
      "Epoch 283/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.8664 - f1_perRow: 0.4690 - f1_perClass: 0.7118 - acc: 0.7559     \n",
      "Epoch 284/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5589 - f1_perRow: 0.4878 - f1_perClass: 0.7209 - acc: 0.7412     \n",
      "Epoch 285/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6619 - f1_perRow: 0.4718 - f1_perClass: 0.7189 - acc: 0.7758     \n",
      "Epoch 286/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5059 - f1_perRow: 0.4803 - f1_perClass: 0.7171 - acc: 0.7806     \n",
      "Epoch 287/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.4941 - f1_perRow: 0.4817 - f1_perClass: 0.7173 - acc: 0.7813     \n",
      "Epoch 288/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5620 - f1_perRow: 0.4757 - f1_perClass: 0.7190 - acc: 0.7570     \n",
      "Epoch 289/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5849 - f1_perRow: 0.4788 - f1_perClass: 0.7143 - acc: 0.7527     \n",
      "Epoch 290/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6687 - f1_perRow: 0.4746 - f1_perClass: 0.7135 - acc: 0.7761     \n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 1s - loss: 13.6385 - f1_perRow: 0.4801 - f1_perClass: 0.7154 - acc: 0.7976     \n",
      "Epoch 292/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5728 - f1_perRow: 0.4806 - f1_perClass: 0.7183 - acc: 0.7750     \n",
      "Epoch 293/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5715 - f1_perRow: 0.4802 - f1_perClass: 0.7181 - acc: 0.7694     \n",
      "Epoch 294/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.6090 - f1_perRow: 0.4848 - f1_perClass: 0.7160 - acc: 0.7492     \n",
      "Epoch 295/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5882 - f1_perRow: 0.4855 - f1_perClass: 0.7211 - acc: 0.7556     \n",
      "Epoch 296/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7393 - f1_perRow: 0.4711 - f1_perClass: 0.7123 - acc: 0.7517     \n",
      "Epoch 297/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5580 - f1_perRow: 0.4848 - f1_perClass: 0.7166 - acc: 0.7270     \n",
      "Epoch 298/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5437 - f1_perRow: 0.4864 - f1_perClass: 0.7165 - acc: 0.7350     \n",
      "Epoch 299/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.7655 - f1_perRow: 0.4751 - f1_perClass: 0.7096 - acc: 0.7245     \n",
      "Epoch 300/300\n",
      "57867/57867 [==============================] - 1s - loss: 13.5382 - f1_perRow: 0.4808 - f1_perClass: 0.7143 - acc: 0.7451     \n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=10500, shuffle=True, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=f1_loss, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=3500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM-sigmoid-withRemovedClasses\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "# plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=load_model( \"LSTM_withSigmoid_LargeData_F1_E100_B500_MSE_False\"  \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    makeReadable( classes=classes, confidance=0.7,data=lstm_tests[i][0],gt=lstm_tests[i][1],model=model2,path=test_names[i],x=lstm_tests[i][0])\n",
    "    \n",
    "#     lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( lstm_pred[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.316     0.783     0.450        57 18/19906/5/39\n",
      "                      activity     1.000      0.632     0.857     0.727        19 12/19947/2/7\n",
      "                       battery     1.000      0.000       nan     0.000         7 0/19961/0/7\n",
      "                        button     0.999      0.071     0.500     0.125        14 1/19953/1/13\n",
      "              colorTemperature     1.000      0.000       nan     0.000         6 0/19962/0/6\n",
      "                       contact     0.996      0.568     0.901     0.697       176 100/19781/11/76\n",
      "                         level     0.999      0.222     0.429     0.293        27 6/19933/8/21\n",
      "                          lock     0.998      0.714     0.439     0.543        35 25/19901/32/10\n",
      "                        motion     0.981      0.000       nan     0.000       371 0/19597/0/371\n",
      "                          ping     0.996      0.997     0.986     0.992      4842 4829/15058/68/13\n",
      "                        status     0.997      0.739     0.815     0.775       119 88/19829/20/31\n",
      "                        switch     0.999      0.714     0.750     0.732        21 15/19942/5/6\n",
      "                   temperature     0.941      0.000     0.000     0.000      1168 0/18799/1/1168\n",
      "                     threeAxis     0.997      0.460     0.630     0.532        63 29/19888/17/34\n",
      "                       unknown     0.575      0.835     0.639     0.724     13305 11113/373/6290/2192\n",
      "                         water     1.000        nan       nan       nan         0 0/19968/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.967      0.392     0.483     0.412     19968 0/0/0/0\n",
      "Exact Match ACC : 0.56711 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 2357 (0.118)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in [1] :\n",
    "# for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.85)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_train, y_lstm_prossed_train, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in lstm_pred  if  np.sum(x) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM_withSigmoid_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( y_lstm_prossed_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1]), len(y_lstm_prossed_test  ) , len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1])/len(y_lstm_prossed_test  ) *1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x  in  pred if np.sum(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lstm_prossed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_for_raun( pred   ):\n",
    "    pp = pred\n",
    "    pp[pp>=0.5] = 1\n",
    "    pp[pp<0.5] = 0\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if np.sum( do_for_raun(x) )==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if  do_for_raun(x)[20] ==1 or do_for_raun(x)[21] ==1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_test) + len(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(new_iot)",
   "language": "python",
   "name": "iot_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
