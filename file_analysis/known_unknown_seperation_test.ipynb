{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def purturb( x_inp , y_inp  ,percentage= 0.5, ignore_empty=False, overlap_count = 1 ):\n",
    "    \n",
    "    if ignore_empty :\n",
    "        indexes= [ i for i in range(len(y_inp)) if  len( x_inp[i] )>overlap_count and  'none' not in  y_inp[i]  and 'unknown'  not in y_inp[i] ]\n",
    "    else :\n",
    "        indexes=  [ i for i in range(len(y_inp)) if  len( x_inp[i] )>overlap_count ]\n",
    "    \n",
    "    assert len(indexes)> overlap_count\n",
    "    \n",
    "    pickable_len =int( len(indexes) * percentage)\n",
    "    if pickable_len %2 != 0 :\n",
    "        pickable_len+=1\n",
    "    \n",
    "    indexes =  random.sample(indexes, pickable_len)\n",
    "    \n",
    "    set_1 = np.array( random.sample( indexes, int(pickable_len/2) ), dtype=int )\n",
    "    indexes = np.array(indexes, dtype=int)\n",
    "    set_2 = np.array(  indexes[ ~np.isin(indexes, set_1) ], dtype=int )\n",
    "    \n",
    "    x_new = list(x_inp) \n",
    "    y_new = list(y_inp)\n",
    "    for i in range(len(set_1)):\n",
    "        a= x_inp[set_1[i]]\n",
    "        b= x_inp[set_2[i]]\n",
    "        a_y =list( y_inp[set_1[i]])\n",
    "        b_y = list(y_inp[set_2[i]])\n",
    "        \n",
    "        ret = [ a[:-1* overlap_count] , b[:overlap_count] ,a[-1*overlap_count:],b[overlap_count:]]\n",
    "        ret  = [  i if type(i)==np.ndarray else np.array([i]) for i in ret ]      \n",
    "        ret =np.array(list(np.concatenate(ret)))\n",
    "#         print(a,b, ret)\n",
    "\n",
    "        x_new.append( ret)\n",
    "        y_new.append( list(set(b_y + a_y))) \n",
    "\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp, includeDirection = False , TrimAt= 15 ):\n",
    "    if includeDirection:\n",
    "        return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1)  for x in inp ][:15])\n",
    "    else:\n",
    "        return np.array([ int(x[\"packet_length\"])  for x in inp ][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S'):\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "58958 57867\n",
      "loading from test files\n",
      "found files :  4\n",
      "32069 32069\n",
      "19968 19968\n",
      "9109 9109\n",
      "6404 6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57867, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "        \n",
    "#     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "#         y_data = json.load(f)\n",
    "\n",
    "#     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "#         x_data = json.load(f)\n",
    "  \n",
    "    if len( y_data ) != len(x_data) :\n",
    "        print( pick )\n",
    "        \n",
    "    \n",
    "    x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , Mapping=Mapper )\n",
    "    \n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    test_files = sorted(glob.glob( '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' ))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/', fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/', fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "\n",
    "        x_test.append(t_x)\n",
    "        y_test.append(t_y)\n",
    "        y_test_service.append(t_z)\n",
    "            \n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_x, tt_y = purturb(  x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72081, 57867)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( tt_x ) , len( x_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-2ea8091fb471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (4,) "
     ]
    }
   ],
   "source": [
    "np.unique( np.array(x_train).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Mittigation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# d_sum = 0\n",
    "# import math\n",
    "# for ii in range(len(x_test)):\n",
    "\n",
    "#     p = x_test[ii]\n",
    "#     for i in p : \n",
    "#         t_sum += math.ceil(np.sum(i) / 2000)\n",
    "#         d_sum+= np.sum( i )\n",
    "# total_fixed  =  t_sum* 2000 / 15\n",
    "\n",
    "# print ( total_fixed , d_sum, d_sum-t_sum*2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sets the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'acceleration'), (1, 'activity'), (2, 'battery'), (3, 'button'), (4, 'colorTemperature'), (5, 'contact'), (6, 'level'), (7, 'lock'), (8, 'motion'), (9, 'ping'), (10, 'status'), (11, 'switch'), (12, 'temperature'), (13, 'threeAxis'), (14, 'unknown'), (15, 'water')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'ping'),\n",
       " (10, 'status'),\n",
       " (11, 'switch'),\n",
       " (12, 'temperature'),\n",
       " (13, 'threeAxis'),\n",
       " (14, 'unknown'),\n",
       " (15, 'water')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section controls wheather the unknown packets are removed or not, this should be tested with and without removed unknowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean_event( inp, return_clean= True  ):\n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'lock-unlocked' not in inp and 'on/off-XXX' not in inp and 'raw-XXX' not in inp and 'read_attr_-_raw-XXX' not in inp\n",
    "    else:\n",
    "        return  'lock-locked' in inp or 'lock-unlocked'  in inp or 'on/off-XXX' in inp or  'raw-XXX' in inp  or 'read_attr_-_raw-XXX' in inp \n",
    "    \n",
    "def is_clean_service( inp, return_clean= True  ):\n",
    "    \n",
    "    if return_clean:\n",
    "        return  'no_logs' not in inp and 'unknown' not in inp and 'read_attr_-_raw' not in inp #and 'ping' not in inp \n",
    "    else:\n",
    "        return  'no_logs' in inp or  'unknown' in inp  or 'read_attr_-_raw' in inp #or 'ping' in inp \n",
    "#     return  \"contact-open\" not in inp and 'contact-closed' not in inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "toKeep = [ i for i in range(len(y_train)) if is_clean_event( y_train[i]) ] if Mapper=='SE' else [ i for i in range(len(y_train)) if is_clean_service( y_train[i]) ]\n",
    "x_train= [ x_train[i] for i in toKeep ]\n",
    "y_train= [ y_train[i] for i in toKeep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_x , tt_y = purturb( x_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(x_test)):\n",
    "    toChange= [ i for i in range(len(y_test[j])) if is_clean_service( y_test[j][i], False) ]\n",
    "    y_test[j] = [ (y_test[j][i] if i not in toChange else np.array( ['none'])) for i in range(len(y_test[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.remove('read_attr_-_raw-XXX')\n",
    "# classes.remove('on/off-XXX')\n",
    "# classes.remove('raw-XXX')\n",
    "# classes.remove('lock-unlocked')\n",
    "# classes.remove('lock-locked')\n",
    "\n",
    "\n",
    "# classes.remove('read_attr_-_raw')\n",
    "# classes.remove('on/off')\n",
    "# classes.remove('raw')\n",
    "classes.remove('unknown')\n",
    "\n",
    "# classes.remove('lock')\n",
    "# # classes.remove('lock')\n",
    "\n",
    "\n",
    "# classes.remove('switch-on')\n",
    "\n",
    "\n",
    "\n",
    "service_classes= [\"\",\"\",\"\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== end of unknown packet control====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,classes=None, twoD= False ):\n",
    "#  y data \n",
    "# \"\"\"\n",
    "# this functino is in charge of preprocessing the records , the sourc e json contains a lot of extra stuff, this function tailors\n",
    "# the data and it fixes their lenghth\n",
    "# \"\"\"\n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    for x in y_data:\n",
    "        temp = np.zeros( len(classes) )\n",
    "        for y in x : \n",
    "            if y in classes:\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "        y_data_categorical.append( temp )\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        if twoD:\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size**2 - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size**2:\n",
    "                    temp.append( 0 )\n",
    "\n",
    "                x_data_temp.append(np.array( temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "            x_data_temp = np.array( x_data_temp )\n",
    "            x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "        else: \n",
    "            temp = [] \n",
    "            lst = list(x)\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size:\n",
    "                    temp.append( 0 )\n",
    "                \n",
    "                x_data_temp.append(np.array( temp))\n",
    "            \n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / (np.amax( x_data_temp) + 0.000000000001)\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,_=pre_process_raw( x_train, y_train , 15, zero_pad=True, normalize=True, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999997, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(x), np.amin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[1][1]\n",
    "    tn = inp[0][0]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "#     F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "\n",
    "def acc_match( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    " \n",
    "    return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "\n",
    "\n",
    "# def acc_none_zero ( true, pred ):\n",
    "    \n",
    "\n",
    "def acc_match_wierd( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    "    level = 6 \n",
    "    switch = 11\n",
    "    threeAxis=13\n",
    "    accel = 0 \n",
    "    status=10\n",
    "    contact=5\n",
    "    \n",
    "    counter  = 0 \n",
    "    for i in range( len (true) ):\n",
    "        if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "            counter+=1\n",
    "        else : \n",
    "            t_rec = np.array(list( pred[i]))\n",
    "            \n",
    "            if true[i][level]==1 and true[i][switch]==1 and t_rec[level]==1 :\n",
    "                t_rec[switch]=1\n",
    "            \n",
    "            if true[i][threeAxis]==1 and true[i][accel]==1 and t_rec[threeAxis]==1:\n",
    "                t_rec[accel] =1\n",
    "            \n",
    "            if true[i][status]==1 and true[i][contact]==1 and t_rec[status]==1:\n",
    "                t_rec[contact]=1\n",
    "#             print(t_rec , true[i])    \n",
    "            if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                counter+=1   \n",
    "            \n",
    "             \n",
    "            \n",
    "    \n",
    "    return counter*1.0 / len(true)\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidance=0.5 ):\n",
    "    \n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidance] = 1\n",
    "    pred[pred<confidance] = 0\n",
    "    \n",
    "#     acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %16s\"  %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    \n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn ))\n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %d/%d/%d/%d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "#     print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def make_readable_results ( inp , classes , conffidance=True):\n",
    "    ret = [] \n",
    "    inp =inp.astype(int)\n",
    "    for xx in range(len(inp)) :\n",
    "        u = inp[xx]\n",
    "        temp = []\n",
    "        for j in range(len(u)) : \n",
    "            if u[j] >0:\n",
    "                temp.append(classes[j])\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def makeReadable( model , data, gt, path , classes, x, confidance=0.5):\n",
    "    #collect across multi models\n",
    "    from keras.models import load_model\n",
    "    x=[]\n",
    "    for i in range(0,16):\n",
    "        model=load_model('number'+str(i)+'.h5',custom_objects={'f1_perRow':f1_perRow,'f1_perClass':f1_perClass,'f1_loss_perRow':f1_loss_perRow,'f1_loss_perClass':f1_loss_perClass})\n",
    "        x.append(model.predict(data))\n",
    "    x=np.array(x)\n",
    "    x=np.transpose(x)\n",
    "    x=np.squeeze(x)\n",
    "    print(x.shape)\n",
    "        \n",
    "        \n",
    "    pred_temp  = x\n",
    "    #pred_temp = model.predict(data)\n",
    "    print_info(gt, x, classes , confidance=confidance)\n",
    "    print( len(classes ), len( pred_temp[0] ) )\n",
    "    xcc= make_readable_results(pred_temp , classes)\n",
    "    y_gt = make_readable_results( gt, classes )\n",
    "    temp_dic = {} \n",
    "    for pick in range(len(xcc)): \n",
    "        temp_dic[ pick +1 ] =  { 'seq': str(data[pick]),\n",
    "                               'pred': xcc[pick],\n",
    "                                'true':y_gt[pick]\n",
    "                               }   \n",
    "\n",
    "    with open(path , 'w') as f:\n",
    "        json.dump(temp_dic , f, indent=4)\n",
    "\n",
    "\n",
    "# def makeReadable( model , data, gt, path , classes, confidance=0.7, x):\n",
    "#     pred_temp = model.predict( data)\n",
    "#     print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "#     xcc= make_readable_results( pred_temp , classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] = xcc[pick]  \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( tt_x, tt_y , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "# x_random_forest_test,y_random_forest_test, _ = pre_process_raw( x_test[0], y_test[0] , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "# x,y, classes = pre_process_raw( x_data, y_data , dim_size, zero_pad=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_random_forest_train_binary = [ [int(x[-2]==0),int( x[-2]!=0)] for x in y_random_forest_train ]\n",
    "\n",
    "re_tests_binary = []\n",
    "for pick in rf_tests:\n",
    "    pick_done= [ [int(x[-2]==0),int(x[-2]!=0) ]  for x in pick[1] ]\n",
    "    re_tests_binary.append( ( pick[0], pick_done, pick[2] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_all = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist_all = clf_all.fit(x_random_forest_train, y_random_forest_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes), len( y_random_forest_train[0] ), len(rf_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.500     0.214     0.300         6 3/32052/11/3\n",
      "                      activity     0.995      0.812     0.210     0.333        48 39/31874/147/9\n",
      "                       battery     1.000        nan     0.000     0.000         0 0/32058/11/0\n",
      "                        button     0.999      0.857     0.154     0.261         7 6/32029/33/1\n",
      "              colorTemperature     0.999        nan     0.000     0.000         0 0/32030/39/0\n",
      "                       contact     0.996      0.795     0.346     0.482        78 62/31874/117/16\n",
      "                         level     0.956      0.889     0.017     0.033        27 24/30648/1394/3\n",
      "                          lock     0.943      0.786     0.006     0.012        14 11/30224/1831/3\n",
      "                        motion     0.857      0.920     0.183     0.306      1099 1011/26462/4508/88\n",
      "                          ping     0.994      1.000     0.969     0.984      6175 6175/25697/197/0\n",
      "                        status     0.999      0.920     0.719     0.807        50 46/32001/18/4\n",
      "                        switch     1.000      0.957     0.667     0.786        23 22/32035/11/1\n",
      "                   temperature     0.742      0.941     0.148     0.256      1512 1423/22371/8186/89\n",
      "                     threeAxis     0.997      0.750     0.055     0.102         8 6/31957/104/2\n",
      "                         water     0.999        nan     0.000     0.000         0 0/32022/47/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.965      0.675     0.246     0.311     32069 0/0/0/0\n",
      "Exact Match ACC : 0.48127 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 23148 (0.722)%\n",
      "Total ZXeros in Test : 6813 (0.212)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.298     0.500     0.374        57 17/19894/17/40\n",
      "                      activity     0.999      0.684     0.684     0.684        19 13/19943/6/6\n",
      "                       battery     0.999      0.000     0.000     0.000         7 0/19947/14/7\n",
      "                        button     0.999      0.071     0.500     0.125        14 1/19953/1/13\n",
      "              colorTemperature     0.999      0.667     0.250     0.364         6 4/19950/12/2\n",
      "                       contact     0.995      0.710     0.683     0.696       176 125/19734/58/51\n",
      "                         level     0.985      0.741     0.063     0.116        27 20/19643/298/7\n",
      "                          lock     0.938      0.857     0.024     0.046        35 30/18693/1240/5\n",
      "                        motion     0.860      0.844     0.103     0.183       371 313/16866/2731/58\n",
      "                          ping     0.997      1.000     0.988     0.994      4368 4367/15548/52/1\n",
      "                        status     0.997      0.739     0.752     0.746       119 88/19820/29/31\n",
      "                        switch     0.999      0.619     0.619     0.619        21 13/19939/8/8\n",
      "                   temperature     0.728      0.916     0.167     0.283      1168 1070/13469/5331/98\n",
      "                     threeAxis     0.996      0.524     0.440     0.478        63 33/19863/42/30\n",
      "                         water     0.999        nan     0.000     0.000         0 0/19944/24/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.966      0.578     0.385     0.381     19968 0/0/0/0\n",
      "Exact Match ACC : 0.50321 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 13757 (0.689)%\n",
      "Total ZXeros in Test : 4227 (0.212)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.200     0.500     0.286        25 5/9079/5/20\n",
      "                      activity     0.998      0.381     0.800     0.516        21 8/9086/2/13\n",
      "                       battery     0.999      0.000     0.000     0.000         4 0/9098/7/4\n",
      "                        button     1.000      0.000     0.000     0.000         3 0/9105/1/3\n",
      "              colorTemperature     1.000        nan     0.000     0.000         0 0/9105/4/0\n",
      "                       contact     0.994      0.641     0.685     0.662        78 50/9008/23/28\n",
      "                         level     0.985      0.833     0.068     0.125        12 10/8959/138/2\n",
      "                          lock     0.939      0.636     0.025     0.048        22 14/8539/548/8\n",
      "                        motion     0.859      0.729     0.115     0.198       218 159/7664/1227/59\n",
      "                          ping     0.997      1.000     0.987     0.994      2014 2014/7069/26/0\n",
      "                        status     0.995      0.600     0.577     0.588        50 30/9037/22/20\n",
      "                        switch     0.999      0.500     0.429     0.462         6 3/9099/4/3\n",
      "                   temperature     0.728      0.843     0.182     0.300       630 531/6099/2380/99\n",
      "                     threeAxis     0.996      0.480     0.387     0.429        25 12/9065/19/13\n",
      "                         water     0.999        nan     0.000     0.000         0 0/9101/8/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.966      0.456     0.317     0.307      9109 0/0/0/0\n",
      "Exact Match ACC : 0.50664 \n",
      "Total Records : 9109 \n",
      "Total ZXeros in True : 6116 (0.671)%\n",
      "Total ZXeros in Test : 1949 (0.214)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.275     0.846     0.415        40 11/6362/2/29\n",
      "                      activity     1.000        nan     0.000     0.000         0 0/6403/1/0\n",
      "                       battery     0.999      0.000     0.000     0.000         2 0/6399/3/2\n",
      "                        button     0.991      0.050     0.750     0.094        60 3/6343/1/57\n",
      "              colorTemperature     0.999      0.000     0.000     0.000         2 0/6397/5/2\n",
      "                       contact     0.988      0.646     0.890     0.748       175 113/6215/14/62\n",
      "                         level     0.993      0.576     0.731     0.644        66 38/6324/14/28\n",
      "                          lock     0.993        nan     0.000     0.000         0 0/6356/48/0\n",
      "                        motion     0.935      0.862     0.240     0.375       145 125/5863/396/20\n",
      "                          ping     0.995      1.000     0.987     0.993      2138 2138/4237/29/0\n",
      "                        status     0.996      0.777     0.988     0.870       103 80/6300/1/23\n",
      "                        switch     0.997      0.417     0.667     0.513        24 10/6375/5/14\n",
      "                   temperature     0.724      0.921     0.096     0.175       203 187/4449/1752/16\n",
      "                     threeAxis     0.997      0.804     0.740     0.771        46 37/6345/13/9\n",
      "                         water     0.999        nan     0.000     0.000         0 0/6400/4/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.973      0.422     0.462     0.373      6404 0/0/0/0\n",
      "Exact Match ACC : 0.62742 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 3638 (0.568)%\n",
      "Total ZXeros in Test : 1515 (0.237)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf_all.predict( rf_tests[i][0])\n",
    "    print_info( rf_tests[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.500     0.750     0.600         6 3/32062/1/3\n",
      "                      activity     0.999      0.729     0.854     0.787        48 35/32015/6/13\n",
      "                       battery     1.000        nan     0.000     0.000         0 0/32067/2/0\n",
      "                        button     1.000      0.857     0.857     0.857         7 6/32061/1/1\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "                       contact     0.999      0.718     0.862     0.783        78 56/31982/9/22\n",
      "                         level     0.995      0.815     0.129     0.222        27 22/31893/149/5\n",
      "                          lock     0.999      0.786     0.234     0.361        14 11/32019/36/3\n",
      "                        motion     0.971      0.183     0.834     0.300      1099 201/30930/40/898\n",
      "                          ping     0.997      0.997     0.992     0.994      6975 6951/25037/57/24\n",
      "                        status     1.000      0.920     0.920     0.920        50 46/32015/4/4\n",
      "                        switch     1.000      0.957     1.000     0.978        23 22/32046/0/1\n",
      "                   temperature     0.955      0.095     0.706     0.168      1512 144/30497/60/1368\n",
      "                     threeAxis     0.999      0.625     0.250     0.357         8 5/32046/15/3\n",
      "                       unknown     0.897      0.984     0.882     0.930     22337 21990/6785/2947/347\n",
      "                         water     1.000        nan     0.000     0.000         0 0/32066/3/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.988      0.573     0.579     0.516     32069 0/0/0/0\n",
      "Exact Match ACC : 0.89304 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 811 (0.025)%\n",
      "Total ZXeros in Test : 173 (0.005)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.298     0.850     0.442        57 17/19908/3/40\n",
      "                      activity     0.999      0.684     0.684     0.684        19 13/19943/6/6\n",
      "                       battery     0.999      0.000     0.000     0.000         7 0/19958/3/7\n",
      "                        button     0.999      0.000     0.000     0.000        14 0/19953/1/14\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         6 4/19962/0/2\n",
      "                       contact     0.997      0.670     0.922     0.776       176 118/19782/10/58\n",
      "                         level     0.986      0.704     0.065     0.119        27 19/19668/273/8\n",
      "                          lock     0.997      0.771     0.386     0.514        35 27/19890/43/8\n",
      "                        motion     0.981      0.186     0.486     0.269       371 69/19524/73/302\n",
      "                          ping     0.997      0.994     0.992     0.993      4842 4814/15087/39/28\n",
      "                        status     0.998      0.723     0.851     0.782       119 86/19834/15/33\n",
      "                        switch     0.999      0.619     0.867     0.722        21 13/19945/2/8\n",
      "                   temperature     0.938      0.054     0.330     0.093      1168 63/18672/128/1105\n",
      "                     threeAxis     0.998      0.460     0.744     0.569        63 29/19895/10/34\n",
      "                       unknown     0.883      0.951     0.883     0.915     13305 12649/4983/1680/656\n",
      "                         water     1.000        nan     0.000     0.000         0 0/19964/4/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.986      0.486     0.566     0.480     19968 0/0/0/0\n",
      "Exact Match ACC : 0.86704 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 396 (0.020)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.200     1.000     0.333        25 5/9084/0/20\n",
      "                      activity     0.998      0.381     0.800     0.516        21 8/9086/2/13\n",
      "                       battery     1.000      0.000       nan     0.000         4 0/9105/0/4\n",
      "                        button     1.000      0.000     0.000     0.000         3 0/9105/1/3\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/9109/0/0\n",
      "                       contact     0.996      0.615     0.923     0.738        78 48/9027/4/30\n",
      "                         level     0.986      0.583     0.053     0.097        12 7/8972/125/5\n",
      "                          lock     0.997      0.545     0.414     0.471        22 12/9070/17/10\n",
      "                        motion     0.976      0.156     0.507     0.239       218 34/8858/33/184\n",
      "                          ping     0.996      0.993     0.989     0.991      2237 2222/6848/24/15\n",
      "                        status     0.996      0.580     0.674     0.624        50 29/9045/14/21\n",
      "                        switch     1.000      0.500     0.750     0.600         6 3/9102/1/3\n",
      "                   temperature     0.929      0.044     0.378     0.080       630 28/8433/46/602\n",
      "                     threeAxis     0.998      0.440     0.786     0.564        25 11/9081/3/14\n",
      "                       unknown     0.873      0.955     0.865     0.908      5948 5679/2276/885/269\n",
      "                         water     1.000        nan     0.000     0.000         0 0/9108/1/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.984      0.375     0.509     0.385      9109 0/0/0/0\n",
      "Exact Match ACC : 0.85772 \n",
      "Total Records : 9109 \n",
      "Total ZXeros in True : 168 (0.018)%\n",
      "Total ZXeros in Test : 158 (0.017)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.300     0.857     0.444        40 12/6362/2/28\n",
      "                      activity     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "                       battery     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                        button     0.991      0.067     1.000     0.125        60 4/6344/0/56\n",
      "              colorTemperature     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                       contact     0.987      0.526     0.989     0.687       175 92/6228/1/83\n",
      "                         level     0.993      0.424     0.757     0.544        66 28/6329/9/38\n",
      "                          lock     0.999        nan     0.000     0.000         0 0/6399/5/0\n",
      "                        motion     0.980      0.248     0.692     0.365       145 36/6243/16/109\n",
      "                          ping     0.998      0.997     0.997     0.997      2307 2300/4089/8/7\n",
      "                        status     0.996      0.786     0.988     0.876       103 81/6300/1/22\n",
      "                        switch     0.997      0.500     0.706     0.585        24 12/6375/5/12\n",
      "                   temperature     0.967      0.064     0.351     0.108       203 13/6177/24/190\n",
      "                     threeAxis     0.996      0.543     0.806     0.649        46 25/6352/6/21\n",
      "                       unknown     0.926      0.984     0.894     0.937      3558 3500/2433/413/58\n",
      "                         water     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.989      0.340     0.565     0.395      6404 0/0/0/0\n",
      "Exact Match ACC : 0.90256 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 80 (0.012)%\n",
      "Total ZXeros in Test : 105 (0.016)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf_all.predict( rf_tests[i][0])\n",
    "    print_info( np.array(rf_tests[i][1]), rf_pred,  classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_random_forest_train, y_random_forest_train_binary)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))\n",
    "# from sklearn import metrics\n",
    "# scores = cross_val_score(clf, x_random_forest_train, y_random_forest_train, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.750     0.750     0.750         4 3/7128/1/1\n",
      "                      activity     0.999      1.000     0.854     0.921        35 35/7092/6/0\n",
      "                       battery     1.000        nan     0.000     0.000         0 0/7131/2/0\n",
      "                        button     1.000      0.857     0.857     0.857         7 6/7125/1/1\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/7133/0/0\n",
      "                       contact     0.998      0.966     0.862     0.911        58 56/7066/9/2\n",
      "                         level     0.979      0.880     0.129     0.224        25 22/6959/149/3\n",
      "                          lock     0.995      0.917     0.234     0.373        12 11/7085/36/1\n",
      "                        motion     0.991      0.905     0.834     0.868       222 201/6871/40/21\n",
      "                          ping     0.997      0.996     1.000     0.998      6199 6175/934/0/24\n",
      "                        status     0.999      1.000     0.920     0.958        46 46/7083/4/0\n",
      "                        switch     1.000      0.957     1.000     0.978        23 22/7110/0/1\n",
      "                   temperature     0.981      0.655     0.706     0.679       220 144/6853/60/76\n",
      "                     threeAxis     0.998      1.000     0.250     0.400         5 5/7113/15/0\n",
      "                       unknown     0.951      0.009     0.750     0.017       350 3/6782/1/347\n",
      "                         water     1.000        nan     0.000     0.000         0 0/7130/3/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.993      0.681     0.572     0.558      7133 0/0/0/0\n",
      "Exact Match ACC : 0.93215 \n",
      "Total Records : 7133 \n",
      "Total ZXeros in True : 50 (0.007)%\n",
      "Total ZXeros in Test : 170 (0.024)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.994      0.370     0.850     0.515        46 17/5596/3/29\n",
      "                      activity     0.999      0.929     0.684     0.788        14 13/5625/6/1\n",
      "                       battery     0.999        nan     0.000     0.000         0 0/5642/3/0\n",
      "                        button     0.997      0.000     0.000     0.000        14 0/5630/1/14\n",
      "              colorTemperature     1.000      1.000     1.000     1.000         4 4/5641/0/0\n",
      "                       contact     0.993      0.797     0.922     0.855       148 118/5487/10/30\n",
      "                         level     0.951      0.760     0.065     0.120        25 19/5347/273/6\n",
      "                          lock     0.991      0.818     0.386     0.524        33 27/5569/43/6\n",
      "                        motion     0.982      0.697     0.486     0.573        99 69/5473/73/30\n",
      "                          ping     0.996      0.995     1.000     0.997      4390 4367/1255/0/23\n",
      "                        status     0.993      0.782     0.851     0.815       110 86/5520/15/24\n",
      "                        switch     0.998      0.619     0.867     0.722        21 13/5622/2/8\n",
      "                   temperature     0.948      0.270     0.324     0.295       226 61/5292/127/165\n",
      "                     threeAxis     0.995      0.617     0.744     0.674        47 29/5588/10/18\n",
      "                       unknown     0.883      0.012     0.533     0.024       660 8/4978/7/652\n",
      "                         water     0.999        nan     0.000     0.000         0 0/5641/4/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.982      0.542     0.545     0.494      5645 0/0/0/0\n",
      "Exact Match ACC : 0.82764 \n",
      "Total Records : 5645 \n",
      "Total ZXeros in True : 46 (0.008)%\n",
      "Total ZXeros in Test : 390 (0.069)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.294     1.000     0.455        17 5/2534/0/12\n",
      "                      activity     0.998      0.800     0.800     0.800        10 8/2539/2/2\n",
      "                       battery     1.000        nan       nan       nan         0 0/2551/0/0\n",
      "                        button     0.999      0.000     0.000     0.000         2 0/2548/1/2\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/2551/0/0\n",
      "                       contact     0.993      0.774     0.923     0.842        62 48/2485/4/14\n",
      "                         level     0.950      0.778     0.053     0.099         9 7/2417/125/2\n",
      "                          lock     0.992      0.750     0.414     0.533        16 12/2518/17/4\n",
      "                        motion     0.981      0.694     0.507     0.586        49 34/2469/33/15\n",
      "                          ping     0.995      0.994     1.000     0.997      2026 2014/525/0/12\n",
      "                        status     0.991      0.744     0.674     0.707        39 29/2498/14/10\n",
      "                        switch     0.999      0.600     0.750     0.667         5 3/2545/1/2\n",
      "                   temperature     0.952      0.267     0.378     0.313       105 28/2400/46/77\n",
      "                     threeAxis     0.997      0.733     0.786     0.759        15 11/2533/3/4\n",
      "                       unknown     0.893      0.015     0.444     0.028       272 4/2274/5/268\n",
      "                         water     1.000        nan     0.000     0.000         0 0/2550/1/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.983      0.465     0.483     0.424      2551 0/0/0/0\n",
      "Exact Match ACC : 0.83928 \n",
      "Total Records : 2551 \n",
      "Total ZXeros in True : 15 (0.006)%\n",
      "Total ZXeros in Test : 155 (0.061)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.994      0.462     0.857     0.600        26 12/2462/2/14\n",
      "                      activity     1.000        nan       nan       nan         0 0/2490/0/0\n",
      "                       battery     1.000        nan       nan       nan         0 0/2490/0/0\n",
      "                        button     0.978      0.069     1.000     0.129        58 4/2432/0/54\n",
      "              colorTemperature     0.999      0.000       nan     0.000         2 0/2488/0/2\n",
      "                       contact     0.988      0.767     0.989     0.864       120 92/2369/1/28\n",
      "                         level     0.984      0.467     0.757     0.577        60 28/2421/9/32\n",
      "                          lock     0.998        nan     0.000     0.000         0 0/2486/4/0\n",
      "                        motion     0.988      0.706     0.692     0.699        51 36/2423/16/15\n",
      "                          ping     0.998      0.997     1.000     0.999      2144 2138/346/0/6\n",
      "                        status     0.991      0.794     0.988     0.880       102 81/2387/1/21\n",
      "                        switch     0.994      0.522     0.706     0.600        23 12/2462/5/11\n",
      "                   temperature     0.979      0.310     0.351     0.329        42 13/2424/24/29\n",
      "                     threeAxis     0.996      0.862     0.806     0.833        29 25/2455/6/4\n",
      "                       unknown     0.977      0.017     1.000     0.034        58 1/2432/0/57\n",
      "                         water     1.000        nan       nan       nan         0 0/2490/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.991      0.373     0.572     0.409      2490 0/0/0/0\n",
      "Exact Match ACC : 0.91647 \n",
      "Total Records : 2490 \n",
      "Total ZXeros in True : 8 (0.003)%\n",
      "Total ZXeros in Test : 104 (0.042)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    \n",
    "    sample_y_gt = []\n",
    "    sample_y = []\n",
    "    sample_x = []\n",
    "    rf_pred= clf.predict( re_tests_binary[i][0])\n",
    "    \n",
    "    for x in range( len(rf_pred)):\n",
    "        if rf_pred[ x ][0]:\n",
    "            sample_y_gt.append( rf_tests[i][1][x] )\n",
    "            sample_x.append( re_tests_binary[i][0][x] )\n",
    "#             sample_y.append( reuslt )\n",
    "    \n",
    "    \n",
    "    result = clf_all.predict( sample_x )\n",
    "    print_info( np.array(sample_y_gt), result,  classes)\n",
    "#         print_info( np.array(re_tests_binary[i][1]), rf_pred,  ['known','unknown'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_y_gt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.897      0.697     0.951     0.804      9732 6783/21987/350/2949\n",
      "                       unknown     0.897      0.984     0.882     0.930     22337 21987/6784/2948/350\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.897      0.841     0.916     0.867     32069 0/0/0/0\n",
      "Exact Match ACC : 0.89713 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.883      0.748     0.883     0.810      6663 4985/12645/660/1678\n",
      "                       unknown     0.883      0.950     0.883     0.915     13305 12645/4985/1678/660\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.883      0.849     0.883     0.863     19968 0/0/0/0\n",
      "Exact Match ACC : 0.88291 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.873      0.721     0.893     0.798      3161 2279/5676/272/882\n",
      "                       unknown     0.873      0.954     0.866     0.908      5948 5676/2279/882/272\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.873      0.838     0.879     0.853      9109 0/0/0/0\n",
      "Exact Match ACC : 0.87331 \n",
      "Total Records : 9109 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.926      0.855     0.977     0.912      2846 2432/3500/58/414\n",
      "                       unknown     0.926      0.984     0.894     0.937      3558 3500/2432/414/58\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.926      0.919     0.935     0.924      6404 0/0/0/0\n",
      "Exact Match ACC : 0.92630 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( re_tests_binary[i][0])\n",
    "    print_info( np.array(re_tests_binary[i][1]), rf_pred,  ['known','unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.500     0.750     0.600         6 3/32062/1/3\n",
      "                      activity     0.999      0.729     0.854     0.787        48 35/32015/6/13\n",
      "                       battery     1.000        nan     0.000     0.000         0 0/32067/2/0\n",
      "                        button     1.000      0.857     0.857     0.857         7 6/32061/1/1\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "                       contact     0.999      0.718     0.862     0.783        78 56/31982/9/22\n",
      "                         level     0.995      0.815     0.129     0.222        27 22/31893/149/5\n",
      "                          lock     0.999      0.786     0.234     0.361        14 11/32019/36/3\n",
      "                        motion     0.971      0.183     0.834     0.300      1099 201/30930/40/898\n",
      "                          ping     0.997      0.997     0.992     0.994      6975 6951/25037/57/24\n",
      "                        status     1.000      0.920     0.920     0.920        50 46/32015/4/4\n",
      "                        switch     1.000      0.957     1.000     0.978        23 22/32046/0/1\n",
      "                   temperature     0.955      0.095     0.706     0.168      1512 144/30497/60/1368\n",
      "                     threeAxis     0.999      0.625     0.250     0.357         8 5/32046/15/3\n",
      "                       unknown     0.897      0.984     0.882     0.930     22337 21990/6785/2947/347\n",
      "                         water     1.000        nan     0.000     0.000         0 0/32066/3/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.988      0.573     0.579     0.516     32069 0/0/0/0\n",
      "Exact Match ACC : 0.89304 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 811 (0.025)%\n",
      "Total ZXeros in Test : 173 (0.005)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.298     0.850     0.442        57 17/19908/3/40\n",
      "                      activity     0.999      0.684     0.684     0.684        19 13/19943/6/6\n",
      "                       battery     0.999      0.000     0.000     0.000         7 0/19958/3/7\n",
      "                        button     0.999      0.000     0.000     0.000        14 0/19953/1/14\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         6 4/19962/0/2\n",
      "                       contact     0.997      0.670     0.922     0.776       176 118/19782/10/58\n",
      "                         level     0.986      0.704     0.065     0.119        27 19/19668/273/8\n",
      "                          lock     0.997      0.771     0.386     0.514        35 27/19890/43/8\n",
      "                        motion     0.981      0.186     0.486     0.269       371 69/19524/73/302\n",
      "                          ping     0.997      0.994     0.992     0.993      4842 4814/15087/39/28\n",
      "                        status     0.998      0.723     0.851     0.782       119 86/19834/15/33\n",
      "                        switch     0.999      0.619     0.867     0.722        21 13/19945/2/8\n",
      "                   temperature     0.938      0.054     0.330     0.093      1168 63/18672/128/1105\n",
      "                     threeAxis     0.998      0.460     0.744     0.569        63 29/19895/10/34\n",
      "                       unknown     0.883      0.951     0.883     0.915     13305 12649/4983/1680/656\n",
      "                         water     1.000        nan     0.000     0.000         0 0/19964/4/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.986      0.486     0.566     0.480     19968 0/0/0/0\n",
      "Exact Match ACC : 0.86704 \n",
      "Total Records : 19968 \n",
      "Total ZXeros in True : 452 (0.023)%\n",
      "Total ZXeros in Test : 396 (0.020)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_os_final_reduced.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.998      0.200     1.000     0.333        25 5/9084/0/20\n",
      "                      activity     0.998      0.381     0.800     0.516        21 8/9086/2/13\n",
      "                       battery     1.000      0.000       nan     0.000         4 0/9105/0/4\n",
      "                        button     1.000      0.000     0.000     0.000         3 0/9105/1/3\n",
      "              colorTemperature     1.000        nan       nan       nan         0 0/9109/0/0\n",
      "                       contact     0.996      0.615     0.923     0.738        78 48/9027/4/30\n",
      "                         level     0.986      0.583     0.053     0.097        12 7/8972/125/5\n",
      "                          lock     0.997      0.545     0.414     0.471        22 12/9070/17/10\n",
      "                        motion     0.976      0.156     0.507     0.239       218 34/8858/33/184\n",
      "                          ping     0.996      0.993     0.989     0.991      2237 2222/6848/24/15\n",
      "                        status     0.996      0.580     0.674     0.624        50 29/9045/14/21\n",
      "                        switch     1.000      0.500     0.750     0.600         6 3/9102/1/3\n",
      "                   temperature     0.929      0.044     0.378     0.080       630 28/8433/46/602\n",
      "                     threeAxis     0.998      0.440     0.786     0.564        25 11/9081/3/14\n",
      "                       unknown     0.873      0.955     0.865     0.908      5948 5679/2276/885/269\n",
      "                         water     1.000        nan     0.000     0.000         0 0/9108/1/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.984      0.375     0.509     0.385      9109 0/0/0/0\n",
      "Exact Match ACC : 0.85772 \n",
      "Total Records : 9109 \n",
      "Total ZXeros in True : 168 (0.018)%\n",
      "Total ZXeros in Test : 158 (0.017)%\n",
      "=============================================================================\n",
      "==================HOME Case : home_sk_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.300     0.857     0.444        40 12/6362/2/28\n",
      "                      activity     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "                       battery     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                        button     0.991      0.067     1.000     0.125        60 4/6344/0/56\n",
      "              colorTemperature     1.000      0.000       nan     0.000         2 0/6402/0/2\n",
      "                       contact     0.987      0.526     0.989     0.687       175 92/6228/1/83\n",
      "                         level     0.993      0.424     0.757     0.544        66 28/6329/9/38\n",
      "                          lock     0.999        nan     0.000     0.000         0 0/6399/5/0\n",
      "                        motion     0.980      0.248     0.692     0.365       145 36/6243/16/109\n",
      "                          ping     0.998      0.997     0.997     0.997      2307 2300/4089/8/7\n",
      "                        status     0.996      0.786     0.988     0.876       103 81/6300/1/22\n",
      "                        switch     0.997      0.500     0.706     0.585        24 12/6375/5/12\n",
      "                   temperature     0.967      0.064     0.351     0.108       203 13/6177/24/190\n",
      "                     threeAxis     0.996      0.543     0.806     0.649        46 25/6352/6/21\n",
      "                       unknown     0.926      0.984     0.894     0.937      3558 3500/2433/413/58\n",
      "                         water     1.000        nan       nan       nan         0 0/6404/0/0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.989      0.340     0.565     0.395      6404 0/0/0/0\n",
      "Exact Match ACC : 0.90256 \n",
      "Total Records : 6404 \n",
      "Total ZXeros in True : 80 (0.012)%\n",
      "Total ZXeros in Test : 105 (0.016)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_tests[i][0])\n",
    "    print_info( rf_tests[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeReadable( data=rf_tests[0][0], model=clf, classes=classes, confidance=0.7,gt=rf_tests[0][1], path='sk_home_out.json' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( \"mean : %f \\nstd: %f\\nmax:%f\" %( scores.mean(), scores.std(), scores.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts  = np.unique(np.array([ len(x) for x  in x_train ]), return_counts=True)\n",
    "# # np.sort( cnts[1] )\n",
    "# cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =15\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32069 32069\n",
      "19968 19968\n",
      "9109 9109\n",
      "6404 6404\n"
     ]
    }
   ],
   "source": [
    "for i in range( len(lstm_tests) ):\n",
    "    print( len( lstm_tests[i][0] ), len( lstm_tests_services[i][0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_lstm_prossed_train,axis=1)\n",
    "\n",
    "for tt  in range( len(lstm_tests) ):\n",
    "    lstm_tests[tt]= (lstm_tests[tt][0].reshape(len(lstm_tests[tt][0]),dim_size,1) , lstm_tests[tt][1],lstm_tests_services[tt][1] )\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_lstm_prossed_train.reshape(len(x_lstm_prossed_train),dim_size,1)\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60562.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_s_lstm_processed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 15, 128)      512         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 15, 128)      512         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 128)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 15, 128)      512         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 15, 128)      0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 128)      512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 15, 128)      49280       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 128)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 15, 128)      49280       conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 15, 128)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 128)      512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 15, 128)      49280       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 128)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 15, 100)      91600       conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 15, 128)      0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (None, 15, 100)      40800       input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 15, 128)      12928       lstm_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 15, 128)      49280       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 15, 128)      12928       lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 15, 128)      16512       dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 15, 128)      49280       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 15, 128)      16512       dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 15, 128)      16512       dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 15, 128)      512         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 15, 128)      16512       dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 15, 128)      0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 15, 128)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 15, 128)      0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1920)         0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 15, 128)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1920)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          245888      flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 15, 128)      49280       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          245888      flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 128)          0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 1920)         0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 128)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)         (None, 2176)         0           dropout_23[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 128)          278656      mergerguy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          16512       dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          16512       dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service1 (Dense)             (None, 130)          16770       dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service2 (Dense)             (None, 130)          17030       to_service1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "service_output (Dense)          (None, 16)           2096        to_service2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,362,408\n",
      "Trainable params: 1,361,384\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 8s 142us/step - loss: 43.6971 - f1_perRow: 0.1063 - f1_perClass: 0.2686 - acc: 0.4095\n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 26.4622 - f1_perRow: 0.1756 - f1_perClass: 0.5600 - acc: 0.4668\n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 22.8054 - f1_perRow: 0.2088 - f1_perClass: 0.6177 - acc: 0.4668\n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 21.4111 - f1_perRow: 0.2358 - f1_perClass: 0.6313 - acc: 0.4668\n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 20.6156 - f1_perRow: 0.2643 - f1_perClass: 0.6402 - acc: 0.4668\n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 20.1501 - f1_perRow: 0.2864 - f1_perClass: 0.6498 - acc: 0.4668\n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 19.7205 - f1_perRow: 0.2919 - f1_perClass: 0.6507 - acc: 0.4668\n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 19.3537 - f1_perRow: 0.3191 - f1_perClass: 0.6596 - acc: 0.4668\n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 19.1065 - f1_perRow: 0.3276 - f1_perClass: 0.6619 - acc: 0.4668\n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.9657 - f1_perRow: 0.3374 - f1_perClass: 0.6640 - acc: 0.4668\n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.7443 - f1_perRow: 0.3372 - f1_perClass: 0.6650 - acc: 0.4668\n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.9449 - f1_perRow: 0.3446 - f1_perClass: 0.6653 - acc: 0.4668\n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 18.9606 - f1_perRow: 0.3470 - f1_perClass: 0.6644 - acc: 0.4668\n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 18.7136 - f1_perRow: 0.3380 - f1_perClass: 0.6656 - acc: 0.4668\n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 18.2103 - f1_perRow: 0.3466 - f1_perClass: 0.6789 - acc: 0.4668\n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 17.8727 - f1_perRow: 0.3567 - f1_perClass: 0.6861 - acc: 0.4668\n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 17.5389 - f1_perRow: 0.3617 - f1_perClass: 0.6902 - acc: 0.4668\n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 17.1680 - f1_perRow: 0.3642 - f1_perClass: 0.6961 - acc: 0.4668\n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.8942 - f1_perRow: 0.3675 - f1_perClass: 0.7006 - acc: 0.4668\n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.6934 - f1_perRow: 0.3763 - f1_perClass: 0.7056 - acc: 0.4668\n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.6418 - f1_perRow: 0.3795 - f1_perClass: 0.7060 - acc: 0.4668\n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.4750 - f1_perRow: 0.3785 - f1_perClass: 0.7070 - acc: 0.4668\n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.7826 - f1_perRow: 0.3826 - f1_perClass: 0.7065 - acc: 0.4668\n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.6849 - f1_perRow: 0.3831 - f1_perClass: 0.7064 - acc: 0.4668\n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.4770 - f1_perRow: 0.3829 - f1_perClass: 0.7051 - acc: 0.4668\n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.3737 - f1_perRow: 0.3915 - f1_perClass: 0.7104 - acc: 0.4668\n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2822 - f1_perRow: 0.3922 - f1_perClass: 0.7124 - acc: 0.4668\n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.1953 - f1_perRow: 0.3939 - f1_perClass: 0.7106 - acc: 0.4668\n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 16.1095 - f1_perRow: 0.4012 - f1_perClass: 0.7112 - acc: 0.4668\n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 16.2865 - f1_perRow: 0.3996 - f1_perClass: 0.7106 - acc: 0.4668\n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.1901 - f1_perRow: 0.3964 - f1_perClass: 0.7120 - acc: 0.4668\n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 16.2784 - f1_perRow: 0.4041 - f1_perClass: 0.7112 - acc: 0.4668\n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.1683 - f1_perRow: 0.3972 - f1_perClass: 0.7082 - acc: 0.4668\n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2135 - f1_perRow: 0.4063 - f1_perClass: 0.7113 - acc: 0.4668\n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.3622 - f1_perRow: 0.4040 - f1_perClass: 0.7142 - acc: 0.4668\n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.2537 - f1_perRow: 0.3961 - f1_perClass: 0.7115 - acc: 0.4668\n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 16.2493 - f1_perRow: 0.4074 - f1_perClass: 0.7093 - acc: 0.4667\n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.1494 - f1_perRow: 0.4021 - f1_perClass: 0.7140 - acc: 0.4668\n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.0783 - f1_perRow: 0.4111 - f1_perClass: 0.7150 - acc: 0.4668\n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2232 - f1_perRow: 0.4068 - f1_perClass: 0.7127 - acc: 0.4668\n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.2912 - f1_perRow: 0.4012 - f1_perClass: 0.7118 - acc: 0.4668\n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.1168 - f1_perRow: 0.4040 - f1_perClass: 0.7111 - acc: 0.4668\n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 16.0148 - f1_perRow: 0.4134 - f1_perClass: 0.7135 - acc: 0.4668\n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.9076 - f1_perRow: 0.4161 - f1_perClass: 0.7174 - acc: 0.4668\n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8050 - f1_perRow: 0.4193 - f1_perClass: 0.7149 - acc: 0.4668\n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.9886 - f1_perRow: 0.4173 - f1_perClass: 0.7142 - acc: 0.4667\n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.0075 - f1_perRow: 0.4144 - f1_perClass: 0.7144 - acc: 0.4669\n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.8299 - f1_perRow: 0.4137 - f1_perClass: 0.7147 - acc: 0.4668\n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.9007 - f1_perRow: 0.4193 - f1_perClass: 0.7161 - acc: 0.4669\n",
      "Epoch 50/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7005 - f1_perRow: 0.4253 - f1_perClass: 0.7172 - acc: 0.4668\n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7086 - f1_perRow: 0.4264 - f1_perClass: 0.7163 - acc: 0.4668\n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6868 - f1_perRow: 0.4285 - f1_perClass: 0.7177 - acc: 0.4668\n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.6149 - f1_perRow: 0.4327 - f1_perClass: 0.7182 - acc: 0.4668\n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8317 - f1_perRow: 0.4286 - f1_perClass: 0.7170 - acc: 0.4668\n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.6808 - f1_perRow: 0.4326 - f1_perClass: 0.7185 - acc: 0.4672\n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8240 - f1_perRow: 0.4285 - f1_perClass: 0.7167 - acc: 0.4668\n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8643 - f1_perRow: 0.4266 - f1_perClass: 0.7146 - acc: 0.4670\n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.9413 - f1_perRow: 0.4225 - f1_perClass: 0.7138 - acc: 0.4672\n",
      "Epoch 59/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7736 - f1_perRow: 0.4278 - f1_perClass: 0.7178 - acc: 0.4673\n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7154 - f1_perRow: 0.4320 - f1_perClass: 0.7187 - acc: 0.4670\n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6191 - f1_perRow: 0.4392 - f1_perClass: 0.7198 - acc: 0.4669\n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 15.6912 - f1_perRow: 0.4335 - f1_perClass: 0.7164 - acc: 0.4673\n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.9293 - f1_perRow: 0.4376 - f1_perClass: 0.7169 - acc: 0.4668\n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.1098 - f1_perRow: 0.4238 - f1_perClass: 0.7118 - acc: 0.4692\n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 16.1241 - f1_perRow: 0.4136 - f1_perClass: 0.7153 - acc: 0.4678\n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 16.0319 - f1_perRow: 0.4219 - f1_perClass: 0.7157 - acc: 0.4668\n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7968 - f1_perRow: 0.4259 - f1_perClass: 0.7177 - acc: 0.4671\n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7002 - f1_perRow: 0.4392 - f1_perClass: 0.7175 - acc: 0.4682\n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.9568 - f1_perRow: 0.4300 - f1_perClass: 0.7157 - acc: 0.4698\n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.8351 - f1_perRow: 0.4193 - f1_perClass: 0.7136 - acc: 0.4807\n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 16.0141 - f1_perRow: 0.4302 - f1_perClass: 0.7160 - acc: 0.4836\n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.7971 - f1_perRow: 0.4267 - f1_perClass: 0.7173 - acc: 0.4786\n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.6511 - f1_perRow: 0.4356 - f1_perClass: 0.7183 - acc: 0.4762\n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.5904 - f1_perRow: 0.4407 - f1_perClass: 0.7178 - acc: 0.4696\n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.5591 - f1_perRow: 0.4433 - f1_perClass: 0.7187 - acc: 0.4692\n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 16.2002 - f1_perRow: 0.4359 - f1_perClass: 0.7120 - acc: 0.4736\n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.8229 - f1_perRow: 0.4299 - f1_perClass: 0.7187 - acc: 0.4725\n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7039 - f1_perRow: 0.4298 - f1_perClass: 0.7183 - acc: 0.4732\n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5572 - f1_perRow: 0.4458 - f1_perClass: 0.7187 - acc: 0.4722\n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.6370 - f1_perRow: 0.4398 - f1_perClass: 0.7179 - acc: 0.4709\n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6581 - f1_perRow: 0.4419 - f1_perClass: 0.7174 - acc: 0.4735\n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 15.8257 - f1_perRow: 0.4398 - f1_perClass: 0.7186 - acc: 0.4718\n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6923 - f1_perRow: 0.4351 - f1_perClass: 0.7165 - acc: 0.4724\n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6567 - f1_perRow: 0.4406 - f1_perClass: 0.7174 - acc: 0.4724\n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 2s 38us/step - loss: 15.6021 - f1_perRow: 0.4503 - f1_perClass: 0.7235 - acc: 0.4692\n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5748 - f1_perRow: 0.4445 - f1_perClass: 0.7175 - acc: 0.4690\n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.8605 - f1_perRow: 0.4361 - f1_perClass: 0.7129 - acc: 0.4704\n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.9338 - f1_perRow: 0.4467 - f1_perClass: 0.7180 - acc: 0.4704\n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.7182 - f1_perRow: 0.4348 - f1_perClass: 0.7192 - acc: 0.4701\n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.7255 - f1_perRow: 0.4441 - f1_perClass: 0.7167 - acc: 0.4677\n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.8937 - f1_perRow: 0.4425 - f1_perClass: 0.7166 - acc: 0.4687\n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.8147 - f1_perRow: 0.4342 - f1_perClass: 0.7160 - acc: 0.4697\n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 2s 41us/step - loss: 15.5519 - f1_perRow: 0.4387 - f1_perClass: 0.7196 - acc: 0.4697\n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.4260 - f1_perRow: 0.4528 - f1_perClass: 0.7204 - acc: 0.4683\n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 2s 39us/step - loss: 15.4555 - f1_perRow: 0.4553 - f1_perClass: 0.7223 - acc: 0.4696\n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5181 - f1_perRow: 0.4539 - f1_perClass: 0.7178 - acc: 0.4711\n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 2s 40us/step - loss: 15.6191 - f1_perRow: 0.4518 - f1_perClass: 0.7180 - acc: 0.4731\n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.6876 - f1_perRow: 0.4580 - f1_perClass: 0.7223 - acc: 0.4706\n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.7191 - f1_perRow: 0.4363 - f1_perClass: 0.7134 - acc: 0.4714\n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 15.5555 - f1_perRow: 0.4467 - f1_perClass: 0.7206 - acc: 0.4693\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    " \n",
    "weights = [\n",
    "1.0/(57.0 / len(y_train)),\n",
    "1.0/(19.0 / len(y_train)),\n",
    "1.0/(7.0 / len(y_train)),\n",
    "1.0/(14.0 / len(y_train)),\n",
    "1.0/(6.0 / len(y_train)),\n",
    "1.0/(176.0 / len(y_train)),\n",
    "1.0/(27.0 / len(y_train)),\n",
    "1.0/(35.0 / len(y_train)),\n",
    "1.0/(371.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "1.0/(4842.0 / len(y_train)),\n",
    "1.0/(119.0 / len(y_train)),\n",
    "1.0/(21.0 / len(y_train)),\n",
    "1.0/(1168.0 / len(y_train)),\n",
    "1.0/(63.0 / len(y_train)),\n",
    "1.0/(13305.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dout_2)\n",
    "\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "#model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=1000, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(fl_out_cnn)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 15, 128)      512         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 15, 128)      512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 128)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 128)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 15, 128)      49280       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 15, 128)      49280       conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 128)      512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 15, 128)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 15, 100)      40800       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 15, 128)      49280       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 15, 128)      12928       lstm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 15, 128)      49280       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 15, 128)      16512       dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 128)      512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 15, 128)      16512       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 15, 128)      0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 15, 128)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1920)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 15, 128)      49280       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          245888      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1920)         0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)         (None, 2048)         0           flatten_5[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          262272      mergerguy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 128)          16512       dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          16512       dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "service_output (Dense)          (None, 16)           2064        dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 878,448\n",
      "Trainable params: 877,680\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "12500/57867 [=====>........................] - ETA: 12s - loss: 58.0834 - f1_perRow: 0.0828 - f1_perClass: 0.1178 - acc: 0.0189"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3e8e681da645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m \u001b[0mhist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1)) \n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [ fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(dens_out_3)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perClass ,\n",
    "#     \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "#     \"service_output\": 20\n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=1e-6  ), metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 15, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 15, 32)            4352      \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 15, 32)            8320      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               123136    \n",
      "_________________________________________________________________\n",
      "service_output (Dense)       (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 139,920\n",
      "Trainable params: 139,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 3s 59us/step - loss: 54.3017 - f1_perRow: 0.0879 - f1_perClass: 0.1406 - acc: 0.3632\n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 47.1223 - f1_perRow: 0.0956 - f1_perClass: 0.2038 - acc: 0.4668\n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 39.7733 - f1_perRow: 0.0966 - f1_perClass: 0.3015 - acc: 0.4668\n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 33.0610 - f1_perRow: 0.0932 - f1_perClass: 0.4503 - acc: 0.4668\n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 32.6438 - f1_perRow: 0.0903 - f1_perClass: 0.5036 - acc: 0.4668\n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 32.1282 - f1_perRow: 0.0925 - f1_perClass: 0.4915 - acc: 0.4668\n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.8512 - f1_perRow: 0.0952 - f1_perClass: 0.4680 - acc: 0.4668\n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.4738 - f1_perRow: 0.0958 - f1_perClass: 0.4722 - acc: 0.4668\n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.3429 - f1_perRow: 0.0955 - f1_perClass: 0.4815 - acc: 0.4668\n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 31.1962 - f1_perRow: 0.0963 - f1_perClass: 0.4835 - acc: 0.4668\n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.9905 - f1_perRow: 0.0981 - f1_perClass: 0.4819 - acc: 0.4668\n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.8031 - f1_perRow: 0.1006 - f1_perClass: 0.4811 - acc: 0.4668\n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.5949 - f1_perRow: 0.1034 - f1_perClass: 0.4844 - acc: 0.4668\n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.3951 - f1_perRow: 0.1065 - f1_perClass: 0.4871 - acc: 0.4668\n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 30.1728 - f1_perRow: 0.1096 - f1_perClass: 0.4891 - acc: 0.4668\n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 29.9330 - f1_perRow: 0.1128 - f1_perClass: 0.4896 - acc: 0.4668\n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 29.6195 - f1_perRow: 0.1157 - f1_perClass: 0.4937 - acc: 0.4668\n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 29.1599 - f1_perRow: 0.1192 - f1_perClass: 0.4997 - acc: 0.4668\n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 28.5980 - f1_perRow: 0.1217 - f1_perClass: 0.5073 - acc: 0.4668\n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 27.8934 - f1_perRow: 0.1213 - f1_perClass: 0.5159 - acc: 0.4668\n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 27.1718 - f1_perRow: 0.1213 - f1_perClass: 0.5316 - acc: 0.4668\n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 26.2048 - f1_perRow: 0.1297 - f1_perClass: 0.5424 - acc: 0.4668\n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 25.1793 - f1_perRow: 0.1331 - f1_perClass: 0.5678 - acc: 0.4668\n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 24.2777 - f1_perRow: 0.1398 - f1_perClass: 0.5797 - acc: 0.4668\n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 23.6299 - f1_perRow: 0.1451 - f1_perClass: 0.5943 - acc: 0.4668\n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 23.2823 - f1_perRow: 0.1513 - f1_perClass: 0.6024 - acc: 0.4668\n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 23.0039 - f1_perRow: 0.1580 - f1_perClass: 0.6064 - acc: 0.4669\n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.7532 - f1_perRow: 0.1621 - f1_perClass: 0.6110 - acc: 0.4751\n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.5807 - f1_perRow: 0.1665 - f1_perClass: 0.6133 - acc: 0.4993\n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.4469 - f1_perRow: 0.1709 - f1_perClass: 0.6153 - acc: 0.5263\n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.3040 - f1_perRow: 0.1726 - f1_perClass: 0.6186 - acc: 0.5407\n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.1971 - f1_perRow: 0.1759 - f1_perClass: 0.6193 - acc: 0.5559\n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.0964 - f1_perRow: 0.1783 - f1_perClass: 0.6213 - acc: 0.5711\n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 22.0149 - f1_perRow: 0.1800 - f1_perClass: 0.6207 - acc: 0.5895\n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 21.9273 - f1_perRow: 0.1822 - f1_perClass: 0.6237 - acc: 0.6037\n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.8773 - f1_perRow: 0.1843 - f1_perClass: 0.6246 - acc: 0.6143\n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 21.8034 - f1_perRow: 0.1863 - f1_perClass: 0.6249 - acc: 0.6295\n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.7496 - f1_perRow: 0.1882 - f1_perClass: 0.6257 - acc: 0.6379\n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.6688 - f1_perRow: 0.1897 - f1_perClass: 0.6277 - acc: 0.6502\n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.5968 - f1_perRow: 0.1910 - f1_perClass: 0.6277 - acc: 0.6609\n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.5437 - f1_perRow: 0.1930 - f1_perClass: 0.6277 - acc: 0.6709\n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 21.3841 - f1_perRow: 0.1937 - f1_perClass: 0.6304 - acc: 0.6785\n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.7072 - f1_perRow: 0.1955 - f1_perClass: 0.6458 - acc: 0.6830\n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.4598 - f1_perRow: 0.1957 - f1_perClass: 0.6494 - acc: 0.6855\n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 20.2493 - f1_perRow: 0.1972 - f1_perClass: 0.6533 - acc: 0.6856\n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.1383 - f1_perRow: 0.2001 - f1_perClass: 0.6546 - acc: 0.6857\n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 20.0533 - f1_perRow: 0.2018 - f1_perClass: 0.6577 - acc: 0.6865\n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.9764 - f1_perRow: 0.2036 - f1_perClass: 0.6547 - acc: 0.6873\n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.9065 - f1_perRow: 0.2043 - f1_perClass: 0.6606 - acc: 0.6885\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.8210 - f1_perRow: 0.2051 - f1_perClass: 0.6559 - acc: 0.6892\n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.7730 - f1_perRow: 0.2053 - f1_perClass: 0.6598 - acc: 0.6906\n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.6856 - f1_perRow: 0.2065 - f1_perClass: 0.6568 - acc: 0.6915\n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 0s 7us/step - loss: 19.6091 - f1_perRow: 0.2073 - f1_perClass: 0.6582 - acc: 0.6931\n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.4873 - f1_perRow: 0.2075 - f1_perClass: 0.6516 - acc: 0.6972\n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.4158 - f1_perRow: 0.2054 - f1_perClass: 0.6418 - acc: 0.7014\n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.6441 - f1_perRow: 0.2018 - f1_perClass: 0.6230 - acc: 0.6998\n",
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.6609 - f1_perRow: 0.2042 - f1_perClass: 0.6356 - acc: 0.7044\n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.3766 - f1_perRow: 0.2061 - f1_perClass: 0.6315 - acc: 0.7061\n",
      "Epoch 59/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.2879 - f1_perRow: 0.2043 - f1_perClass: 0.6224 - acc: 0.7080\n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 19.0608 - f1_perRow: 0.2040 - f1_perClass: 0.6172 - acc: 0.7151\n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.8748 - f1_perRow: 0.2046 - f1_perClass: 0.6088 - acc: 0.7250\n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.7436 - f1_perRow: 0.2022 - f1_perClass: 0.5884 - acc: 0.7304\n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.6658 - f1_perRow: 0.2031 - f1_perClass: 0.5875 - acc: 0.7293\n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.4735 - f1_perRow: 0.2029 - f1_perClass: 0.5822 - acc: 0.7375\n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.3581 - f1_perRow: 0.2033 - f1_perClass: 0.5854 - acc: 0.7411\n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.2633 - f1_perRow: 0.2082 - f1_perClass: 0.5972 - acc: 0.7418\n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.1938 - f1_perRow: 0.2097 - f1_perClass: 0.6079 - acc: 0.7428\n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.0776 - f1_perRow: 0.2137 - f1_perClass: 0.6208 - acc: 0.7441\n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 18.0133 - f1_perRow: 0.2173 - f1_perClass: 0.6366 - acc: 0.7442\n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.9147 - f1_perRow: 0.2208 - f1_perClass: 0.6380 - acc: 0.7450\n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.8203 - f1_perRow: 0.2233 - f1_perClass: 0.6468 - acc: 0.7452\n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.7141 - f1_perRow: 0.2272 - f1_perClass: 0.6494 - acc: 0.7455\n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.6237 - f1_perRow: 0.2326 - f1_perClass: 0.6557 - acc: 0.7456\n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.5573 - f1_perRow: 0.2346 - f1_perClass: 0.6576 - acc: 0.7454\n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.4716 - f1_perRow: 0.2384 - f1_perClass: 0.6621 - acc: 0.7458\n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.3506 - f1_perRow: 0.2429 - f1_perClass: 0.6660 - acc: 0.7458\n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.2814 - f1_perRow: 0.2469 - f1_perClass: 0.6711 - acc: 0.7457\n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.2063 - f1_perRow: 0.2493 - f1_perClass: 0.6729 - acc: 0.7459\n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.1656 - f1_perRow: 0.2508 - f1_perClass: 0.6687 - acc: 0.7456\n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 17.0475 - f1_perRow: 0.2524 - f1_perClass: 0.6772 - acc: 0.7459\n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8934 - f1_perRow: 0.2599 - f1_perClass: 0.6786 - acc: 0.7460\n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8809 - f1_perRow: 0.2609 - f1_perClass: 0.6772 - acc: 0.7459\n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8498 - f1_perRow: 0.2615 - f1_perClass: 0.6800 - acc: 0.7457\n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.7646 - f1_perRow: 0.2631 - f1_perClass: 0.6836 - acc: 0.7461\n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.7351 - f1_perRow: 0.2658 - f1_perClass: 0.6847 - acc: 0.7458\n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.8061 - f1_perRow: 0.2603 - f1_perClass: 0.6747 - acc: 0.7461\n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.6325 - f1_perRow: 0.2661 - f1_perClass: 0.6704 - acc: 0.7462\n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.5164 - f1_perRow: 0.2646 - f1_perClass: 0.6674 - acc: 0.7470\n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.4678 - f1_perRow: 0.2672 - f1_perClass: 0.6680 - acc: 0.7479\n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.4416 - f1_perRow: 0.2606 - f1_perClass: 0.6619 - acc: 0.7505\n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.3941 - f1_perRow: 0.2596 - f1_perClass: 0.6611 - acc: 0.7536\n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.2971 - f1_perRow: 0.2597 - f1_perClass: 0.6603 - acc: 0.7576\n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.2182 - f1_perRow: 0.2601 - f1_perClass: 0.6533 - acc: 0.7602\n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.0940 - f1_perRow: 0.2519 - f1_perClass: 0.6518 - acc: 0.7625\n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 16.1122 - f1_perRow: 0.2467 - f1_perClass: 0.6396 - acc: 0.7654\n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.9340 - f1_perRow: 0.2425 - f1_perClass: 0.6342 - acc: 0.7674\n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.8248 - f1_perRow: 0.2365 - f1_perClass: 0.6360 - acc: 0.7705\n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.8781 - f1_perRow: 0.2345 - f1_perClass: 0.6310 - acc: 0.7721\n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.6740 - f1_perRow: 0.2313 - f1_perClass: 0.6307 - acc: 0.7727\n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 0s 6us/step - loss: 15.7928 - f1_perRow: 0.2253 - f1_perClass: 0.6228 - acc: 0.7733\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
    "lstm_2 = LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(lstm_1)\n",
    "\n",
    "lstm_2=Flatten()(lstm_2)\n",
    "lstm_2 = Dense(256, activation='relu')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 18:07:35.342952 140236066629440 deprecation_wrapper.py:119] From /home/omid/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,16):\\n    \\n    \\n        \\n        \\n    \\n\\n\\n    inputs  = Input( ( dim_size,1 ) )\\n\\n\\n    out = Conv1D(128,3,padding=\\'same\\')(inputs)\\n    out = BatchNormalization()(out)\\n    out = Activation(\\'relu\\')(out)\\n    out = Dropout(0.2)(out)\\n    out = Conv1D(128,3,padding=\\'same\\')(out)\\n    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode=\\'concat\\') (inputs)\\n    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\\n    # lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\\n\\n    bi_d_1 =Dense(128, activation=\\'relu\\')  (lstm_1)\\n    lstm_1 =  Dense(128, activation=\\'relu\\')(bi_d_1)\\n    lstm_2 = Dense(128, activation=\\'relu\\')(lstm_1)\\n\\n\\n\\n    # td_1    = TimeDistributed(Dense(256, activation=\\'relu\\'))(lstm_2)\\n    # dout_1  = Dropout(0.1)(td_1)\\n    dout_1  = Dropout(0.1)(lstm_2)\\n    flt_1   = Flatten()(dout_1)\\n    dense_1 = Dense(128, activation=\\'relu\\')(flt_1)\\n    dout_2  = Dropout(0.2)(dense_1)\\n\\n\\n\\n\\n\\n    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode=\\'concat\\') (inputs)\\n    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\\n    # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\\n\\n    bi_d_raw_1 =Dense(128, activation=\\'relu\\')  (lstm_1)\\n    lstm_raw_1 =  Dense(128, activation=\\'relu\\')(bi_d_raw_1)\\n    lstm_raw_2 = Dense(128, activation=\\'relu\\')(lstm_raw_1)\\n\\n    dout_1  = Dropout(0.1)(lstm_raw_2)\\n    flt_1   = Flatten()(dout_1)\\n    dense_1 = Dense(128, activation=\\'relu\\')(flt_1)\\n    dout_3  = Dropout(0.2)(dense_1)\\n\\n\\n\\n\\n\\n    out = Conv1D(128,3,padding=\\'same\\')(inputs)\\n    out = BatchNormalization()(out)\\n    out = Activation(\\'relu\\')(out)\\n    out = Dropout(0.2)(out)\\n    out = Conv1D(128,3,padding=\\'same\\')(out)\\n    # out = Flatten()(out)\\n    # out = MaxPooling1D(2,padding=\\'same\\', name =\\'pooling\\')(out)\\n\\n\\n    out = Conv1D(128,3,padding=\\'same\\')(out)\\n    out = BatchNormalization()(out)\\n    out = Activation(\\'relu\\')(out)\\n    out = Dropout(0.2)(out)\\n    out = Conv1D(128,3,padding=\\'same\\')(out)\\n    # out = Flatten()(out)\\n    # out = MaxPooling1D(2,padding=\\'same\\', name =\\'pooling2\\')(out)\\n\\n\\n    out = Conv1D(128,3,padding=\\'same\\')(out)\\n    out = BatchNormalization()(out)\\n    out = Activation(\\'relu\\')(out)\\n    out = Dropout(0.2)(out)\\n    out = Conv1D(128,3,padding=\\'same\\')(out)\\n    # out = Flatten()(out)\\n    # out = MaxPooling1D(2,padding=\\'same\\', name =\\'pooling\\')(out)\\n\\n\\n\\n    # fl_out_1 = Flatten()(dout_2)\\n\\n    fl_out_cnn = Flatten()(out)\\n\\n    # out_new = concatenate( [fl_out_1, fl_out_cnn] , name=\\'mergerguy\\')\\n    out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name=\\'mergerguy\\')\\n\\n    dens_out_1 = Dense( 128, activation=\\'relu\\' )(out_new)\\n    dens_out_2 = Dense( 128, activation=\\'relu\\' )(dens_out_1)\\n    dens_out_3 = Dense( 128, activation=\\'relu\\' )(dens_out_2)\\n\\n    # fl2  = Flatten()(out_new)\\n\\n    out_put_final = Dense(len(classes), activation=\\'sigmoid\\', name=\\'Event_output\\')(dens_out_3)\\n\\n    toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\\n    toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\\n\\n    service_output = Dense(1, activation=\"sigmoid\", name = \\'service_output\\')(toService_1)\\n\\n\\n    losses = {\\n    #     \"service_output\": f1_loss_perClass ,\\n        \"service_output\": f1_loss_perRow ,\\n        \"service_output\": \"binary_crossentropy\",\\n    }\\n    lossWeights = {#\"service_output\": 20,\\n                   \"service_output\": 30.0 ,\\n        \"service_output\": 20}\\n\\n\\n\\n\\n    model2 = Model(inputs=[inputs], outputs=[service_output])\\n    model2.compile(loss=losses,loss_weights=lossWeights, optimizer=\\'adam\\', metrics=[f1_perRow,f1_perClass,\\'acc\\'])\\n    # model2.compile(loss=losses, loss_weights=lossWeights, optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\n    checkpoint = ModelCheckpoint(\\'IoTDownNet\\', monitor=\\'loss\\', verbose=0, save_best_only=True, mode=\\'min\\')\\n    callbacks_list = [checkpoint]\\n    hist2 = model2.fit(x_lstm_prossed_train2, zzzz[i], epochs=200, batch_size=12500, shuffle=True, callbacks=callbacks_list)\\n    model2.save(\\'number\\'+str(i)+\\'.h5\\')\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split model\n",
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "#splitting data\n",
    "X=x_lstm_prossed_train2\n",
    "y=y_lstm_prossed_train\n",
    "a,b,c,d,e,f,g,h,ii,jj,k,l,m,n,o,p=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "print(len(y_lstm_prossed_train[0]))\n",
    "for i in range(0,len(y_lstm_prossed_train)):\n",
    "    a.append(y_lstm_prossed_train[i][0])\n",
    "    b.append(y_lstm_prossed_train[i][1])\n",
    "    c.append(y_lstm_prossed_train[i][2])\n",
    "    d.append(y_lstm_prossed_train[i][3])\n",
    "    e.append(y_lstm_prossed_train[i][4])\n",
    "    f.append(y_lstm_prossed_train[i][5])\n",
    "    g.append(y_lstm_prossed_train[i][6])\n",
    "    h.append(y_lstm_prossed_train[i][7])\n",
    "    ii.append(y_lstm_prossed_train[i][8])\n",
    "    jj.append(y_lstm_prossed_train[i][9])\n",
    "    k.append(y_lstm_prossed_train[i][10])\n",
    "    l.append(y_lstm_prossed_train[i][11])\n",
    "    m.append(y_lstm_prossed_train[i][12])\n",
    "    n.append(y_lstm_prossed_train[i][13])\n",
    "    o.append(y_lstm_prossed_train[i][14])\n",
    "    p.append(y_lstm_prossed_train[i][15])\n",
    "    \n",
    "zzzz=[]    \n",
    "zzzz.append(np.array(a))\n",
    "zzzz.append(np.array(b))\n",
    "zzzz.append(np.array(c))\n",
    "zzzz.append(np.array(d))\n",
    "zzzz.append(np.array(e))\n",
    "zzzz.append(np.array(f))\n",
    "zzzz.append(np.array(g))\n",
    "zzzz.append(np.array(h))\n",
    "zzzz.append(np.array(ii))\n",
    "zzzz.append(np.array(jj))\n",
    "zzzz.append(np.array(k))\n",
    "zzzz.append(np.array(l))\n",
    "zzzz.append(np.array(m))\n",
    "zzzz.append(np.array(n))\n",
    "zzzz.append(np.array(o))\n",
    "zzzz.append(np.array(p))\n",
    "\n",
    "'''\n",
    "for i in range(0,16):\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "    # lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "    lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "    # td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "    # dout_1  = Dropout(0.1)(td_1)\n",
    "    dout_1  = Dropout(0.1)(lstm_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "    # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "    lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "    dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "    # fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "    fl_out_cnn = Flatten()(out)\n",
    "\n",
    "    # out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "    out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "    dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "    dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "    dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "    # fl2  = Flatten()(out_new)\n",
    "\n",
    "    out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "    toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "    toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "    service_output = Dense(1, activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "    losses = {\n",
    "    #     \"service_output\": f1_loss_perClass ,\n",
    "        \"service_output\": f1_loss_perRow ,\n",
    "        \"service_output\": \"binary_crossentropy\",\n",
    "    }\n",
    "    lossWeights = {#\"service_output\": 20,\n",
    "                   \"service_output\": 30.0 ,\n",
    "        \"service_output\": 20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "    model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "    # model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    hist2 = model2.fit(x_lstm_prossed_train2, zzzz[i], epochs=200, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "    model2.save('number'+str(i)+'.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(loss=losses,loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=5e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=16500, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=f1_loss, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=3500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM-sigmoid-withRemovedClasses\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4aa1e57ef0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "# plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=load_model( \"LSTM_withSigmoid_LargeData_F1_E100_B500_MSE_False\"  \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_muhammed_final.json =============\n",
      "(32069, 16)\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count      TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.167     0.500     0.250         6 1/32062/1/5\n",
      "                      activity     0.999      0.000       nan     0.000        48 0/32021/0/48\n",
      "                       battery     1.000        nan       nan       nan         0 0/32069/0/0\n",
      "                        button     1.000      0.714     0.625     0.667         7 5/32059/3/2\n",
      "              colorTemperature     1.000        nan     0.000     0.000         0 0/32068/1/0\n",
      "                       contact     0.999      0.603     0.810     0.691        78 47/31980/11/31\n",
      "                         level     1.000      0.444     1.000     0.615        27 12/32042/0/15\n",
      "                          lock     0.999      0.786     0.239     0.367        14 11/32020/35/3\n",
      "                        motion     0.966      0.013     1.000     0.025      1099 14/30970/0/1085\n",
      "                          ping     0.996      0.998     0.983     0.991      6975 6961/24976/118/14\n",
      "                        status     0.999      0.840     0.824     0.832        50 42/32010/9/8\n",
      "                        switch     1.000      0.783     0.900     0.837        23 18/32044/2/5\n",
      "                   temperature     0.953      0.009     0.722     0.017      1512 13/30552/5/1499\n",
      "                     threeAxis     1.000      0.500     0.500     0.500         8 4/32057/4/4\n",
      "                       unknown     0.893      0.998     0.868     0.928     22337 22284/6344/3388/53\n",
      "                         water     1.000        nan       nan       nan         0 0/32069/0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.988      0.428     0.561     0.420     32069 0/0/0/0\n",
      "Exact Match ACC : 0.88890 \n",
      "Total Records : 32069 \n",
      "Total ZXeros in True : 811 (0.025)%\n",
      "Total ZXeros in Test : 76 (0.002)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-caff6abcae7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"==================HOME Case : %s =============\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmakeReadable\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_tests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_tests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_tests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     lstm_pred= model2.predict( lstm_tests[i][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-63eb79f1f2a0>\u001b[0m in \u001b[0;36mmakeReadable\u001b[0;34m(model, data, gt, path, classes, x, confidance)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m#pred_temp = model.predict(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconfidance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfidance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpred_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mxcc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmake_readable_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_temp\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_readable_results\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_temp' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    makeReadable( classes=classes, confidance=0.5,data=lstm_tests[i][0],gt=lstm_tests[i][1],model=model2,path=test_names[i],x=lstm_tests[i][0])\n",
    "    \n",
    "#     lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ------------- do not go any further :) ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[1][0])\n",
    "lstm_pred__ = np.array(list(lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred__ = np.array(list(lstm_pred))\n",
    "print_info( lstm_tests[1][1], lstm_pred__, classes , confidance=0.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1] :\n",
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [1] :\n",
    "# for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.992)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_train, y_lstm_prossed_train, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in lstm_pred  if  np.sum(x) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM_withSigmoid_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( y_lstm_prossed_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1]), len(y_lstm_prossed_test  ) , len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1])/len(y_lstm_prossed_test  ) *1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x  in  pred if np.sum(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lstm_prossed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_for_raun( pred   ):\n",
    "    pp = pred\n",
    "    pp[pp>=0.5] = 1\n",
    "    pp[pp<0.5] = 0\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if np.sum( do_for_raun(x) )==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if  do_for_raun(x)[20] ==1 or do_for_raun(x)[21] ==1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_test) + len(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
