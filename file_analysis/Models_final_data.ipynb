{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/omid/.conda/envs/iot_new/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= True\n",
    "Mapper='F'\n",
    "IgnoreEmpty= False\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp ):\n",
    "    return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1) for x in inp ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S'):\n",
    "    cleans = [] \n",
    "    cleans = sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] )\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50358, 12590)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = {}\n",
    "y_test = {}\n",
    "\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "\n",
    "\n",
    "if loadFromMerged:\n",
    "    with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "\n",
    "    if len( y_data ) != len(x_data) :\n",
    "        print( pick )\n",
    "    #     continue\n",
    "\n",
    "    with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "        index_info = json.load(f)\n",
    "    \n",
    "    \n",
    "    for i in index_info[FoldID][\"test\"]:\n",
    "        x_test[str(i)]=( x_data[str(i)] )\n",
    "        y_test[str(i)]=(  y_data[str(i)] )\n",
    "    \n",
    "    for i in index_info[FoldID][\"train\"]:\n",
    "        x_train[str(i)]=(  x_data[str(i)] )\n",
    "        y_train[str(i)]=(  y_data[str(i)] )\n",
    "    \n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "    \n",
    "    \n",
    "    x_test,y_test= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "    x_train,y_train= clean_data( x_train, y_train, IgnoreEmpty , Mapping=Mapper )\n",
    "\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in glob.glob( '../files/train/hub_segments/*.json' ):\n",
    "        fname  = os.path.basename(pick)\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array( x )\n",
    "y= np.array(y)\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Centralite_Micro_Door_Sensor & activity & hubDisconnected',\n",
       " 'Centralite_Micro_Door_Sensor & activity & offline',\n",
       " 'Centralite_Micro_Door_Sensor & activity & online',\n",
       " 'Centralite_Micro_Door_Sensor & contact & closed',\n",
       " 'Centralite_Micro_Door_Sensor & contact & open',\n",
       " 'Centralite_Micro_Door_Sensor & temperature & XXX',\n",
       " 'Centralite_Smart_Outlet & switch & off',\n",
       " 'Centralite_Smart_Outlet & switch & on',\n",
       " 'Centralite_Water_Sensor & battery & XXX',\n",
       " 'Centralite_Water_Sensor & temperature & XXX',\n",
       " 'Centralite_Water_Sensor & water & dry',\n",
       " 'Centralite_Water_Sensor & water & wet',\n",
       " 'Iris_Smart_Water_Sensor & battery & XXX',\n",
       " 'Iris_Smart_Water_Sensor & temperature & XXX',\n",
       " 'Iris_Smart_Water_Sensor & water & dry',\n",
       " 'Iris_Smart_Water_Sensor & water & wet',\n",
       " 'Kwikset_10-Button_Deadbolt & lock & locked',\n",
       " 'Kwikset_10-Button_Deadbolt & lock & unlocked',\n",
       " 'Motion_Sensor & motion & active',\n",
       " 'Motion_Sensor & motion & inactive',\n",
       " 'Motion_Sensor & temperature & XXX',\n",
       " 'Multipurpose_Sensor & acceleration & active',\n",
       " 'Multipurpose_Sensor & acceleration & inactive',\n",
       " 'Multipurpose_Sensor & contact & closed',\n",
       " 'Multipurpose_Sensor & contact & open',\n",
       " 'Multipurpose_Sensor & status & closed',\n",
       " 'Multipurpose_Sensor & status & open',\n",
       " 'Multipurpose_Sensor & temperature & XXX',\n",
       " 'Multipurpose_Sensor & threeAxis & XXX',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch & activity & hubDisconnected',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch & activity & online',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch & button & held',\n",
       " 'OSRAM_LIGHTIFY_Dimming_Switch & button & pushed',\n",
       " 'SYLVANIA_SMART+_Smart_Plug & switch & off',\n",
       " 'SYLVANIA_SMART+_Smart_Plug & switch & on',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW & activity & offline',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW & colorTemperature & XXX',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW & level & XXX',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW & switch & off',\n",
       " 'SYLVANIA_Smart_10Y_A19_TW & switch & on',\n",
       " 'Sk_door & acceleration & active',\n",
       " 'Sk_door & acceleration & inactive',\n",
       " 'Sk_door & activity & hubDisconnected',\n",
       " 'Sk_door & activity & offline',\n",
       " 'Sk_door & activity & online',\n",
       " 'Sk_door & contact & closed',\n",
       " 'Sk_door & contact & open',\n",
       " 'Sk_door & status & closed',\n",
       " 'Sk_door & status & open',\n",
       " 'Sk_door & temperature & XXX',\n",
       " 'Sk_door & threeAxis & XXX',\n",
       " 'Sk_room2_door_sensor & acceleration & active',\n",
       " 'Sk_room2_door_sensor & acceleration & inactive',\n",
       " 'Sk_room2_door_sensor & activity & hubDisconnected',\n",
       " 'Sk_room2_door_sensor & activity & offline',\n",
       " 'Sk_room2_door_sensor & activity & online',\n",
       " 'Sk_room2_door_sensor & contact & closed',\n",
       " 'Sk_room2_door_sensor & contact & open',\n",
       " 'Sk_room2_door_sensor & status & closed',\n",
       " 'Sk_room2_door_sensor & status & open',\n",
       " 'Sk_room2_door_sensor & temperature & XXX',\n",
       " 'Sk_room2_door_sensor & threeAxis & XXX',\n",
       " 'hub & ping & ping',\n",
       " 'none']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(np.unique(  np.concatenate( y_train  ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,classes=None ):\n",
    "#  y data \n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    for x in y_data:\n",
    "        temp = np.zeros( len(classes) )\n",
    "        for y in x : \n",
    "            temp[ classes.index( y ) ] = 1\n",
    "        y_data_categorical.append( temp )\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        for x in x_data:\n",
    "            temp = [] #list(x)\n",
    "            lst = list(x)\n",
    "            while dim_size**2 - len(temp )   > len(lst):\n",
    "                temp.extend(lst)\n",
    "\n",
    "            while len(temp) < dim_size**2:\n",
    "                temp.append( 0 )\n",
    "\n",
    "            x_data_temp.append(np.array( temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "        x_data_temp = np.array( x_data_temp )\n",
    "        x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / 1500.0\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[0][0]\n",
    "    tn = inp[1][1]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "    F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "def print_info(y_test, pred , classes  ):\n",
    "    pred[pred>=0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%20s  %8s   %8s  %8s  %8s \"  %( \"Class\",\"Accuracy\",      \"Recall\",\"Precision\",\"F Score\" ))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    for index in range(len(classes)):\n",
    "        print( \"%20s  %8.3f   %8.3f  %8.3f  %8.3f \"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3]\n",
    "             )\n",
    "\n",
    "             )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def unet(dim_size , classcount):\n",
    "    l2_lambda = 0.0002\n",
    "    DropP = 0.3\n",
    "    kernel_size=3\n",
    "\n",
    "    inputs = Input((dim_size,dim_size,1))\n",
    "    \n",
    "    \n",
    "    conv1 = Conv2D( 32, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(inputs)\n",
    "    conv1 = bn()(conv1)\n",
    "    conv1 = Conv2D(32, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv1)\n",
    "    conv1 = bn()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(DropP)(pool1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    conv2 = Conv2D(64, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(pool1)\n",
    "    conv2 = bn()(conv2)\n",
    "    conv2 = Conv2D(64, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv2)\n",
    "    conv2 = bn()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(DropP)(pool2)\n",
    "\n",
    "\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(pool2)\n",
    "    conv3 = bn()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv3)\n",
    "    conv3 = bn()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(DropP)(pool3)\n",
    "\n",
    "\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(pool3)\n",
    "    conv4 = bn()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv4)\n",
    "    conv4 = bn()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(DropP)(pool4)\n",
    "\n",
    "\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(pool4)\n",
    "    conv5 = bn()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv5)\n",
    "    conv5 = bn()(conv5)\n",
    "    \n",
    "    up6 = concatenate([Conv2DTranspose(256,(2, 2), strides=(2, 2), padding='same')(conv5), conv4],name='up6', axis=3)\n",
    "    up6 = Dropout(DropP)(up6)\n",
    "    conv6 = Conv2D(256,(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(up6)\n",
    "    conv6 = bn()(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv6)\n",
    "\n",
    "    conv6 = bn()(conv6)\n",
    "    up7 = concatenate([Conv2DTranspose(128,(2, 2), strides=(2, 2), padding='same')(conv6), conv3],name='up7', axis=3)\n",
    "    up7 = Dropout(DropP)(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(up7)\n",
    "    conv7 = bn()(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv7)\n",
    "    conv7 = bn()(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64,(2, 2), strides=(2, 2), padding='same')(conv7), conv2],name='up8', axis=3)\n",
    "    up8 = Dropout(DropP)(up8)\n",
    "    conv8 = Conv2D(64, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(up8)\n",
    "    conv8 = bn()(conv8)\n",
    "    conv8 = Conv2D(64, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv8)\n",
    "    conv8 = bn()(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32,(2, 2), strides=(2, 2), padding='same')(conv8), conv1],name='up9',axis=3)\n",
    "    up9 = Dropout(DropP)(up9)\n",
    "    conv9 = Conv2D(32, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(up9)\n",
    "    conv9 = bn()(conv9)\n",
    "    conv9 = Conv2D(32, (kernel_size, kernel_size), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda) )(conv9)\n",
    "    conv9 = bn()(conv9) \n",
    "    \n",
    "    \n",
    "    \n",
    "    flatten1 = Flatten()(conv9)\n",
    "    conv7 = Dense( 256, activation='relu' )(flatten1)\n",
    "    conv8 = Dense( 128, activation='relu' )(conv7)\n",
    "    \n",
    "    \n",
    "    output = Dense(classcount,  activation='softmax',name='output')(conv8)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =64\n",
    "x_train_processed,y_train_processed, classes = pre_process_raw( x_train, y_train , dim_size)\n",
    "x_test_processed,y_test_processed, _ = pre_process_raw( x_test, y_test , dim_size, classes=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = unet(dim_size,len( y_train_processed[0]))\n",
    "# model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50358/50358 [==============================] - 78s - loss: 1.0965 - acc: 0.8828    \n",
      "Epoch 2/100\n",
      "50358/50358 [==============================] - 71s - loss: 0.8702 - acc: 0.9301    \n",
      "Epoch 3/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8408 - acc: 0.9372    \n",
      "Epoch 4/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8279 - acc: 0.9385    \n",
      "Epoch 5/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8236 - acc: 0.9394    \n",
      "Epoch 6/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8163 - acc: 0.9407    \n",
      "Epoch 7/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8151 - acc: 0.9397    \n",
      "Epoch 8/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8102 - acc: 0.9412    \n",
      "Epoch 9/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8068 - acc: 0.9413    \n",
      "Epoch 10/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8016 - acc: 0.9410    \n",
      "Epoch 11/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.8002 - acc: 0.9412    \n",
      "Epoch 12/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7980 - acc: 0.9417    \n",
      "Epoch 13/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7957 - acc: 0.9423    \n",
      "Epoch 14/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7932 - acc: 0.9424    \n",
      "Epoch 15/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7895 - acc: 0.9424    \n",
      "Epoch 16/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7859 - acc: 0.9424    \n",
      "Epoch 17/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7856 - acc: 0.9426    \n",
      "Epoch 18/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7828 - acc: 0.9431    \n",
      "Epoch 19/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7816 - acc: 0.9428    \n",
      "Epoch 20/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7750 - acc: 0.9436    \n",
      "Epoch 21/100\n",
      "50358/50358 [==============================] - 71s - loss: 0.7746 - acc: 0.9443    \n",
      "Epoch 22/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7722 - acc: 0.9437    \n",
      "Epoch 23/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7701 - acc: 0.9439    \n",
      "Epoch 24/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7667 - acc: 0.9440    \n",
      "Epoch 25/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7653 - acc: 0.9446    \n",
      "Epoch 26/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7623 - acc: 0.9444    \n",
      "Epoch 27/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7601 - acc: 0.9449    \n",
      "Epoch 28/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7582 - acc: 0.9454    \n",
      "Epoch 29/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7554 - acc: 0.9452    \n",
      "Epoch 30/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7545 - acc: 0.9452    \n",
      "Epoch 31/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7511 - acc: 0.9464    \n",
      "Epoch 32/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7493 - acc: 0.9455    \n",
      "Epoch 33/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7461 - acc: 0.9459    \n",
      "Epoch 34/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7443 - acc: 0.9459    \n",
      "Epoch 35/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7418 - acc: 0.9451    \n",
      "Epoch 36/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7411 - acc: 0.9457    \n",
      "Epoch 37/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7366 - acc: 0.9463    \n",
      "Epoch 38/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7335 - acc: 0.9463    \n",
      "Epoch 39/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7318 - acc: 0.9465    \n",
      "Epoch 40/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7281 - acc: 0.9470    \n",
      "Epoch 41/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7269 - acc: 0.9464    \n",
      "Epoch 42/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7268 - acc: 0.9466    \n",
      "Epoch 43/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7215 - acc: 0.9462    \n",
      "Epoch 44/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7182 - acc: 0.9467    \n",
      "Epoch 45/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7158 - acc: 0.9470    \n",
      "Epoch 46/100\n",
      "50358/50358 [==============================] - 71s - loss: 0.7151 - acc: 0.9473    \n",
      "Epoch 47/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7091 - acc: 0.9483    \n",
      "Epoch 48/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7069 - acc: 0.9477    \n",
      "Epoch 49/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.7021 - acc: 0.9489    \n",
      "Epoch 50/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6981 - acc: 0.9501    \n",
      "Epoch 51/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6962 - acc: 0.9483    \n",
      "Epoch 52/100\n",
      "50358/50358 [==============================] - 71s - loss: 0.6946 - acc: 0.9499    \n",
      "Epoch 53/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6893 - acc: 0.9489    \n",
      "Epoch 54/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6867 - acc: 0.9499    \n",
      "Epoch 55/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6840 - acc: 0.9496    \n",
      "Epoch 56/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6811 - acc: 0.9511    \n",
      "Epoch 57/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6819 - acc: 0.9494    \n",
      "Epoch 58/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6772 - acc: 0.9507    \n",
      "Epoch 59/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6744 - acc: 0.9511    \n",
      "Epoch 60/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6703 - acc: 0.9513    \n",
      "Epoch 61/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6693 - acc: 0.9512    \n",
      "Epoch 62/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6677 - acc: 0.9515    \n",
      "Epoch 63/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6625 - acc: 0.9518    \n",
      "Epoch 64/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6608 - acc: 0.9518    \n",
      "Epoch 65/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6592 - acc: 0.9527    \n",
      "Epoch 66/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6567 - acc: 0.9511    \n",
      "Epoch 67/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6552 - acc: 0.9507    \n",
      "Epoch 68/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6520 - acc: 0.9524    \n",
      "Epoch 69/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6481 - acc: 0.9521    \n",
      "Epoch 70/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6463 - acc: 0.9511    \n",
      "Epoch 71/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6434 - acc: 0.9527    \n",
      "Epoch 72/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6416 - acc: 0.9519    \n",
      "Epoch 73/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6383 - acc: 0.9533    \n",
      "Epoch 74/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6358 - acc: 0.9529    \n",
      "Epoch 75/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6344 - acc: 0.9529    \n",
      "Epoch 76/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6295 - acc: 0.9528    \n",
      "Epoch 77/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6298 - acc: 0.9522    \n",
      "Epoch 78/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6265 - acc: 0.9520    \n",
      "Epoch 79/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6241 - acc: 0.9536    \n",
      "Epoch 80/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6214 - acc: 0.9524    \n",
      "Epoch 81/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6201 - acc: 0.9525    \n",
      "Epoch 82/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6163 - acc: 0.9529    \n",
      "Epoch 83/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6143 - acc: 0.9529    \n",
      "Epoch 84/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6122 - acc: 0.9529    \n",
      "Epoch 85/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6094 - acc: 0.9534    \n",
      "Epoch 86/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6066 - acc: 0.9537    \n",
      "Epoch 87/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6047 - acc: 0.9531    \n",
      "Epoch 88/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.6010 - acc: 0.9533    \n",
      "Epoch 89/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5984 - acc: 0.9538    \n",
      "Epoch 90/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5979 - acc: 0.9534    \n",
      "Epoch 91/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5960 - acc: 0.9540    \n",
      "Epoch 92/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5933 - acc: 0.9536    \n",
      "Epoch 93/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5897 - acc: 0.9538    \n",
      "Epoch 94/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5873 - acc: 0.9535    \n",
      "Epoch 95/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5852 - acc: 0.9540    \n",
      "Epoch 96/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5820 - acc: 0.9548    \n",
      "Epoch 97/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5793 - acc: 0.9548    \n",
      "Epoch 98/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5776 - acc: 0.9549    \n",
      "Epoch 99/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5760 - acc: 0.9542    \n",
      "Epoch 100/100\n",
      "50358/50358 [==============================] - 72s - loss: 0.5734 - acc: 0.9546    \n"
     ]
    }
   ],
   "source": [
    "report2=  model2.fit( x=x_train_processed , y=y_train_processed , batch_size=Batch_size, epochs=Epoch_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"UNET_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2c86e36d8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(report2.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= model2.predict( x_test_processed )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26, 26)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred[0]),len( y_test_processed[0]),len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class  Accuracy     Recall  Precision   F Score \n",
      "------------------------------------------------------------------------\n",
      " acceleration-active     0.999      0.999     1.000     1.000 \n",
      "acceleration-inactive     0.999      0.999     1.000     1.000 \n",
      "activity-hubDisconnected     1.000      1.000     1.000     1.000 \n",
      "    activity-offline     1.000      1.000     1.000     1.000 \n",
      "     activity-online     1.000      1.000     1.000     1.000 \n",
      "         battery-XXX     1.000      1.000     1.000     1.000 \n",
      "         button-held     0.999      0.999     1.000     1.000 \n",
      "       button-pushed     0.996      0.996     1.000     0.998 \n",
      "colorTemperature-XXX     0.993      0.993     1.000     0.996 \n",
      "      contact-closed     0.997      0.997     1.000     0.998 \n",
      "        contact-open     0.997      0.997     1.000     0.999 \n",
      "           level-XXX     0.988      0.996     0.992     0.994 \n",
      "         lock-locked     0.997      0.997     1.000     0.998 \n",
      "       lock-unlocked     0.981      0.997     0.984     0.991 \n",
      "       motion-active     0.998      0.998     1.000     0.999 \n",
      "     motion-inactive     0.997      0.997     1.000     0.999 \n",
      "                none     0.930      0.962     0.931     0.946 \n",
      "           ping-ping     0.985      0.965     0.998     0.981 \n",
      "       status-closed     0.998      0.998     1.000     0.999 \n",
      "         status-open     0.998      0.998     1.000     0.999 \n",
      "          switch-off     0.992      0.993     1.000     0.996 \n",
      "           switch-on     0.991      0.991     1.000     0.996 \n",
      "     temperature-XXX     0.991      0.991     1.000     0.995 \n",
      "       threeAxis-XXX     0.999      0.999     1.000     0.999 \n",
      "           water-dry     0.999      0.999     1.000     1.000 \n",
      "           water-wet     0.999      0.999     1.000     1.000 \n"
     ]
    }
   ],
   "source": [
    "print_info(y_test_processed, pred, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     print(X_test is None)\n",
    "#     np.save( \"x_test.npy\", X_test )\n",
    "#     np.save(\"y_test.npy\", y_test)\n",
    "#     np.save(\"y_pred.npy\", pred )\n",
    "#     np.save(\"classes.npy\", classes)\n",
    "# except:\n",
    "#     X_test = np.load(\"x_test.npy\")\n",
    "#     y_test = np.load(\"y_test.npy\")\n",
    "#     pred   = np.load(\"y_pred.npy\")\n",
    "#     classes = np.load(\"classes.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 160\n",
    "x_random_forest_train,y_random_forest_train, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "x_random_forest_test,y_random_forest_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "# x,y, classes = pre_process_raw( x_data, y_data , dim_size, zero_pad=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=260, max_depth=200,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_random_forest_train, y_random_forest_train)\n",
    "\n",
    "rf_pred= clf.predict(x_random_forest_test  )\n",
    "\n",
    "\n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "# print(clf.predict([[0, 0, 0, 0]]))\n",
    "# from sklearn import metrics\n",
    "# scores = cross_val_score(clf, x_random_forest_train, y_random_forest_train, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class  Accuracy     Recall  Precision   F Score \n",
      "------------------------------------------------------------------------\n",
      " acceleration-active     0.999      0.999     1.000     1.000 \n",
      "acceleration-inactive     0.999      0.999     1.000     1.000 \n",
      "activity-hubDisconnected     1.000      1.000     1.000     1.000 \n",
      "    activity-offline     1.000      1.000     1.000     1.000 \n",
      "     activity-online     1.000      1.000     1.000     1.000 \n",
      "         battery-XXX     1.000      1.000     1.000     1.000 \n",
      "         button-held     0.999      1.000     1.000     1.000 \n",
      "       button-pushed     0.999      0.999     0.999     0.999 \n",
      "colorTemperature-XXX     1.000      1.000     1.000     1.000 \n",
      "      contact-closed     0.997      0.998     0.999     0.999 \n",
      "        contact-open     0.998      0.998     1.000     0.999 \n",
      "           level-XXX     0.997      0.998     0.999     0.998 \n",
      "         lock-locked     0.999      0.999     1.000     1.000 \n",
      "       lock-unlocked     0.999      0.999     1.000     0.999 \n",
      "       motion-active     0.998      0.998     1.000     0.999 \n",
      "     motion-inactive     0.998      0.998     1.000     0.999 \n",
      "                none     0.967      0.985     0.966     0.975 \n",
      "           ping-ping     1.000      0.999     1.000     1.000 \n",
      "       status-closed     0.998      0.998     0.999     0.999 \n",
      "         status-open     0.998      0.998     1.000     0.999 \n",
      "          switch-off     0.993      0.996     0.997     0.996 \n",
      "           switch-on     0.994      0.996     0.998     0.997 \n",
      "     temperature-XXX     0.991      0.991     1.000     0.995 \n",
      "       threeAxis-XXX     0.999      0.999     1.000     0.999 \n",
      "           water-dry     0.999      0.999     1.000     1.000 \n",
      "           water-wet     0.999      0.999     1.000     1.000 \n"
     ]
    }
   ],
   "source": [
    "print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_info(y_random_forest_test, rf_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( \"mean : %f \\nstd: %f\\nmax:%f\" %( scores.mean(), scores.std(), scores.max()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 160, 102)          247044    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 160, 102)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               81200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 127)               12827     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 26)                3328      \n",
      "=================================================================\n",
      "Total params: 344,399\n",
      "Trainable params: 344,399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "50358/50358 [==============================] - 29s - loss: 1.1702 - acc: 0.6835    \n",
      "Epoch 2/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.4119 - acc: 0.9225    \n",
      "Epoch 3/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.3171 - acc: 0.9370    \n",
      "Epoch 4/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.2758 - acc: 0.9426    \n",
      "Epoch 5/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.2482 - acc: 0.9520    \n",
      "Epoch 6/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.2278 - acc: 0.9560    \n",
      "Epoch 7/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.2153 - acc: 0.9567    \n",
      "Epoch 8/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.2059 - acc: 0.9570    \n",
      "Epoch 9/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1990 - acc: 0.9582    \n",
      "Epoch 10/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1943 - acc: 0.9587    \n",
      "Epoch 11/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1898 - acc: 0.9580    \n",
      "Epoch 12/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.2275 - acc: 0.9521    \n",
      "Epoch 13/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1981 - acc: 0.9571    \n",
      "Epoch 14/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1860 - acc: 0.9581    \n",
      "Epoch 15/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1837 - acc: 0.9580    \n",
      "Epoch 16/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1814 - acc: 0.9587    \n",
      "Epoch 17/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1794 - acc: 0.9584    \n",
      "Epoch 18/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1785 - acc: 0.9586    \n",
      "Epoch 19/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1778 - acc: 0.9588    \n",
      "Epoch 20/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1773 - acc: 0.9586    \n",
      "Epoch 21/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1756 - acc: 0.9586    \n",
      "Epoch 22/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1747 - acc: 0.9590    \n",
      "Epoch 23/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1736 - acc: 0.9590    \n",
      "Epoch 24/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1734 - acc: 0.9593    \n",
      "Epoch 25/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1728 - acc: 0.9593    \n",
      "Epoch 26/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1720 - acc: 0.9596    \n",
      "Epoch 27/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1717 - acc: 0.9595    \n",
      "Epoch 28/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1712 - acc: 0.9593    \n",
      "Epoch 29/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1708 - acc: 0.9596    \n",
      "Epoch 30/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1706 - acc: 0.9594    \n",
      "Epoch 31/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1696 - acc: 0.9599    \n",
      "Epoch 32/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1691 - acc: 0.9593    \n",
      "Epoch 33/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1691 - acc: 0.9597    \n",
      "Epoch 34/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1690 - acc: 0.9598    \n",
      "Epoch 35/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1676 - acc: 0.9601    \n",
      "Epoch 36/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1680 - acc: 0.9590    \n",
      "Epoch 37/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1675 - acc: 0.9598    \n",
      "Epoch 38/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1673 - acc: 0.9603    \n",
      "Epoch 39/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1667 - acc: 0.9598    \n",
      "Epoch 40/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1671 - acc: 0.9598    \n",
      "Epoch 41/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1664 - acc: 0.9601    \n",
      "Epoch 42/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1655 - acc: 0.9594    \n",
      "Epoch 43/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1654 - acc: 0.9600    \n",
      "Epoch 44/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1655 - acc: 0.9604    \n",
      "Epoch 45/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1652 - acc: 0.9602    \n",
      "Epoch 46/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1649 - acc: 0.9604    \n",
      "Epoch 47/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1642 - acc: 0.9606    \n",
      "Epoch 48/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1640 - acc: 0.9607    \n",
      "Epoch 49/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1641 - acc: 0.9598    \n",
      "Epoch 50/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1643 - acc: 0.9603    \n",
      "Epoch 51/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1634 - acc: 0.9601    \n",
      "Epoch 52/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1633 - acc: 0.9610    \n",
      "Epoch 53/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1631 - acc: 0.9608    \n",
      "Epoch 54/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1632 - acc: 0.9606    \n",
      "Epoch 55/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1626 - acc: 0.9604    \n",
      "Epoch 56/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1622 - acc: 0.9604    \n",
      "Epoch 57/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1620 - acc: 0.9608    \n",
      "Epoch 58/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1614 - acc: 0.9611    \n",
      "Epoch 59/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1621 - acc: 0.9607    \n",
      "Epoch 60/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1617 - acc: 0.9612    \n",
      "Epoch 61/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1615 - acc: 0.9606    \n",
      "Epoch 62/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1612 - acc: 0.9603    \n",
      "Epoch 63/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1610 - acc: 0.9612    \n",
      "Epoch 64/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1614 - acc: 0.9606    \n",
      "Epoch 65/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1606 - acc: 0.9605    \n",
      "Epoch 66/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1600 - acc: 0.9610    \n",
      "Epoch 67/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1608 - acc: 0.9608    \n",
      "Epoch 68/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1605 - acc: 0.9608    \n",
      "Epoch 69/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1606 - acc: 0.9610    \n",
      "Epoch 70/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1602 - acc: 0.9606    \n",
      "Epoch 71/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1602 - acc: 0.9605    \n",
      "Epoch 72/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1597 - acc: 0.9607    \n",
      "Epoch 73/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1592 - acc: 0.9609    \n",
      "Epoch 74/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1594 - acc: 0.9613    \n",
      "Epoch 75/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1592 - acc: 0.9613    \n",
      "Epoch 76/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1590 - acc: 0.9614    \n",
      "Epoch 77/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1586 - acc: 0.9608    \n",
      "Epoch 78/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1586 - acc: 0.9615    \n",
      "Epoch 79/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1589 - acc: 0.9611    \n",
      "Epoch 80/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1585 - acc: 0.9612    \n",
      "Epoch 81/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1588 - acc: 0.9614    \n",
      "Epoch 82/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1583 - acc: 0.9611    \n",
      "Epoch 83/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1581 - acc: 0.9612    \n",
      "Epoch 84/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1586 - acc: 0.9605    \n",
      "Epoch 85/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1580 - acc: 0.9610    \n",
      "Epoch 86/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1581 - acc: 0.9607    \n",
      "Epoch 87/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1581 - acc: 0.9610    \n",
      "Epoch 88/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1576 - acc: 0.9613    \n",
      "Epoch 89/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1573 - acc: 0.9611    \n",
      "Epoch 90/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1573 - acc: 0.9614    \n",
      "Epoch 91/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1572 - acc: 0.9613    \n",
      "Epoch 92/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1571 - acc: 0.9612    \n",
      "Epoch 93/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1583 - acc: 0.9610    \n",
      "Epoch 94/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1571 - acc: 0.9606    \n",
      "Epoch 95/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1572 - acc: 0.9619    \n",
      "Epoch 96/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1568 - acc: 0.9614    \n",
      "Epoch 97/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1572 - acc: 0.9613    \n",
      "Epoch 98/100\n",
      "50358/50358 [==============================] - 29s - loss: 0.1565 - acc: 0.9608    \n",
      "Epoch 99/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1565 - acc: 0.9610    \n",
      "Epoch 100/100\n",
      "50358/50358 [==============================] - 28s - loss: 0.1566 - acc: 0.9614    \n"
     ]
    }
   ],
   "source": [
    "word_count = np.max( x_lstm_prossed_train)+1 # len(np.unique( x ))\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 102\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_count, embedding_vecor_length, input_length=dim_size))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(127, activation='relu'))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "hist2 = model.fit(x_lstm_prossed_train, y_lstm_prossed_train, epochs=Epoch_count, batch_size=Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist2 = model.fit(x_lstm_prossed_train, y_lstm_prossed_train, epochs=50, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa28c773278>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save( \"LSTM_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class  Accuracy     Recall  Precision   F Score \n",
      "------------------------------------------------------------------------\n",
      " acceleration-active     0.999      0.999     1.000     1.000 \n",
      "acceleration-inactive     0.999      0.999     1.000     1.000 \n",
      "activity-hubDisconnected     1.000      1.000     1.000     1.000 \n",
      "    activity-offline     1.000      1.000     1.000     1.000 \n",
      "     activity-online     1.000      1.000     1.000     1.000 \n",
      "         battery-XXX     1.000      1.000     1.000     1.000 \n",
      "         button-held     0.999      1.000     1.000     1.000 \n",
      "       button-pushed     0.999      0.999     0.999     0.999 \n",
      "colorTemperature-XXX     1.000      1.000     1.000     1.000 \n",
      "      contact-closed     0.997      0.997     1.000     0.998 \n",
      "        contact-open     0.997      0.998     1.000     0.999 \n",
      "           level-XXX     0.996      0.996     0.999     0.998 \n",
      "         lock-locked     0.997      0.997     1.000     0.998 \n",
      "       lock-unlocked     0.999      0.999     1.000     0.999 \n",
      "       motion-active     0.998      0.998     1.000     0.999 \n",
      "     motion-inactive     0.998      0.998     1.000     0.999 \n",
      "                none     0.967      0.986     0.964     0.975 \n",
      "           ping-ping     0.999      0.998     1.000     0.999 \n",
      "       status-closed     0.998      0.998     1.000     0.999 \n",
      "         status-open     0.998      0.998     1.000     0.999 \n",
      "          switch-off     0.992      0.993     0.999     0.996 \n",
      "           switch-on     0.992      0.993     1.000     0.996 \n",
      "     temperature-XXX     0.991      0.991     1.000     0.995 \n",
      "       threeAxis-XXX     0.999      0.999     1.000     0.999 \n",
      "           water-dry     0.999      0.999     1.000     1.000 \n",
      "           water-wet     0.999      0.999     1.000     1.000 \n"
     ]
    }
   ],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(new_iot)",
   "language": "python",
   "name": "iot_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
